{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GeneralDataLoader' from 'recbole.data.dataloader.general_dataloader' (c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataloader\\general_dataloader.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# from recbole.model.general_recommender.bpr import BPR\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecbole\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecbole\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneral_dataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneralDataLoader\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GeneralDataLoader' from 'recbole.data.dataloader.general_dataloader' (c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataloader\\general_dataloader.py)"
     ]
    }
   ],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR\n",
    "from recbole.utils import init_seed, init_logger\n",
    "\n",
    "\n",
    "## Deep Seek\n",
    "# from utils.CustomTrainer import CustomTrainer\n",
    "\n",
    "\n",
    "## ChatGPT\n",
    "import torch\n",
    "import pandas as pd\n",
    "# from recbole.model.general_recommender.bpr import BPR\n",
    "from recbole.trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [1,5,10,20]\n",
    "# VALID_METRIC = 'Recall@'+str(K)\n",
    "MODEL = 'BPR'\n",
    "SEED = 2020\n",
    "USE_GPU = False\n",
    "SHUFFLE = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = MODEL\n",
    "save_path = 'processed_datasets/natural_data/goodreads/inter_dedup_coldstart_3stars_4x714k/'\n",
    "base_filename = 'more_2interQ_df'\n",
    "specs_str = '1959x98333_1.0'\n",
    "\n",
    "base_dataset_name = base_filename+'_'+specs_str\n",
    "model_versions = ['_pt1', '_pt2', '_pt3', '_pt4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeek code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code yields the error TypeError: 'NegSampleEvalDataLoader' object is not subscriptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for part in model_versions:\n",
    "#     print('\\n\\n'+part)\n",
    "#     dataset_name=base_dataset_name+part\n",
    "\n",
    "#     parameter_dict = {\n",
    "#         'dataset': dataset_name+'.inter',\n",
    "#         'data_path': save_path,\n",
    "#         'load_col': {'inter': ['user_id', 'item_id']},\n",
    "#         'use_gpu':USE_GPU,\n",
    "#         'topk':K,\n",
    "#         # 'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision'], # default\n",
    "#         # 'valid_metric':VALID_METRIC,\n",
    "#         # 'user_inter_num_interval':'[1,inf)',\n",
    "#         'checkpoint_dir':save_path+dataset_name,\n",
    "#         'seed':SEED,\n",
    "#         'shuffle': SHUFFLE,\n",
    "#         'state':'ERROR',\n",
    "#         # 'show_progress': SHOW_PROGRESS,\n",
    "#         # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "#         'eval_args': {'split': {'LS': 'test_only'}, # leave-one-out sample type\n",
    "#                     'group_by': 'user',\n",
    "#                     'order': 'RO', # random ordering\n",
    "#                     'mode': 'pop001'} #  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\n",
    "#     }\n",
    "\n",
    "\n",
    "#     # configurations initialization\n",
    "#     config = Config(model=model_name, dataset=dataset_name, config_dict=parameter_dict)\n",
    "\n",
    "#     # init random seed\n",
    "#     init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "#     # logger initialization\n",
    "#     init_logger(config)\n",
    "#     logger = getLogger()\n",
    "\n",
    "#     # write config info into log\n",
    "#     logger.info(config)\n",
    "\n",
    "#     # dataset creating and filtering\n",
    "#     dataset = create_dataset(config)\n",
    "#     logger.info(dataset)\n",
    "\n",
    "#     # dataset splitting\n",
    "#     train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "#     # model loading and initialization\n",
    "#     model = BPR(config, train_data.dataset).to(config['device'])\n",
    "#     logger.info(model)\n",
    "\n",
    "#     # trainer loading and initialization\n",
    "#     trainer = CustomTrainer(config, model)\n",
    "\n",
    "#     # model training\n",
    "#     best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "#     print('\\n\\nTraining best results')\n",
    "#     print('best_valid_score: ', best_valid_score)\n",
    "#     print('best_valid_result: ', best_valid_result)\n",
    "\n",
    "#     # model evaluation\n",
    "#     test_result = trainer.evaluate(test_data, model)\n",
    "\n",
    "#     print('\\n\\nTest results')\n",
    "#     print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in model_versions:\n",
    "    print('\\n\\n'+part)\n",
    "    dataset_name=base_dataset_name+part\n",
    "\n",
    "    parameter_dict = {\n",
    "        'dataset': dataset_name+'.inter',\n",
    "        'data_path': save_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        # 'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision'], # default\n",
    "        # 'valid_metric':VALID_METRIC,\n",
    "        # 'user_inter_num_interval':'[1,inf)',\n",
    "        'checkpoint_dir':save_path+dataset_name,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE,\n",
    "        'state':'ERROR',\n",
    "        # 'show_progress': SHOW_PROGRESS,\n",
    "        # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "        'eval_args': {'split': {'LS': 'test_only'}, # leave-one-out sample type\n",
    "                    'group_by': 'user',\n",
    "                    'order': 'RO', # random ordering\n",
    "                    'mode': 'pop001'} #  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\n",
    "    }\n",
    "\n",
    "\n",
    "    # configurations initialization\n",
    "    config = Config(model=model_name, dataset=dataset_name, config_dict=parameter_dict)\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = BPR(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = Trainer(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "    print('\\n\\nTraining best results')\n",
    "    print('best_valid_score: ', best_valid_score)\n",
    "    print('best_valid_result: ', best_valid_result)\n",
    "\n",
    "    test_dataloader = GeneralDataLoader(config, dataset=test_data, batch_size=128)\n",
    "\n",
    "    # Store recommendations\n",
    "    recommendations = []\n",
    "\n",
    "    # Generate predictions\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            user_ids = batch['user_id']\n",
    "            item_ids = batch['item_id']\n",
    "            scores = model.predict(batch)\n",
    "\n",
    "            for u, i, s in zip(user_ids.tolist(), item_ids.tolist(), scores.tolist()):\n",
    "                recommendations.append((u, i, s))\n",
    "\n",
    "    # Convert to DataFrame and save\n",
    "    df_recommendations = pd.DataFrame(recommendations, columns=['user_id', 'item_id', 'score'])\n",
    "    df_recommendations.to_csv(parameter_dict['checkpoint_dir']+'/'+'bpr_recommendations.csv', index=False)\n",
    "\n",
    "    print(\"Recommendations saved successfully!\")\n",
    "\n",
    "\n",
    "    # Extract the test set interactions\n",
    "    test_set = test_data.inter_feat[['user_id', 'item_id', 'rating']]  # Adjust column names as needed\n",
    "\n",
    "    # Save to CSV\n",
    "    test_set.to_csv(parameter_dict['checkpoint_dir']+'/'+'test_set.csv', index=False)\n",
    "\n",
    "    print(\"Test set saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just checking a little trust-issue-driven question i have, that is whether if the valid set interferes in any way or other parameter. Go back to noteb 09_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algorithms_transparency",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
