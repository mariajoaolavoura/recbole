{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_trainer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "VALID_METRIC = 'Recall@'+str(K)\n",
    "MODEL = 'BPR'\n",
    "SEED = 2020\n",
    "USE_GPU = False\n",
    "SHUFFLE = False \n",
    "SHOW_PROGRESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'sudden_drift_dataset_4000x7_0.71'\n",
    "SAVE_PATH = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepath(base_folderpath, filename, pt):\n",
    "    return base_folderpath+filename+pt+'/'+filename+pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_config_and_dataset(model_name,\n",
    "                            dataset_name,\n",
    "                            parameter_dict):\n",
    "    # configurations initialization\n",
    "    config = Config(model=model_name, dataset=dataset_name, config_dict=parameter_dict)\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    return config, logger, dataset, train_data, valid_data, test_data\n",
    "\n",
    "\n",
    "\n",
    "def resume_training_from_checkpoint_test(model_name,\n",
    "                                         dataset_name,\n",
    "                                         parameter_dict,\n",
    "                                         checkpoint_file):\n",
    "\n",
    "    config,\\\n",
    "        logger,\\\n",
    "             dataset,\\\n",
    "                 train_data, valid_data, test_data = setup_config_and_dataset(model_name,\n",
    "                                                                              dataset_name,\n",
    "                                                                              parameter_dict)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = BPR(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = Trainer(config, model)\n",
    "    \n",
    "    # resume from break point\n",
    "    # checkpoint_file is the file used to store the model.\n",
    "    checkpoint_file = dataset_name+'_checkpoint.pth'\n",
    "    # Load the model parameters information and training information.\n",
    "    trainer.resume_checkpoint(checkpoint_file)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "    print('\\n\\nTraining best results')\n",
    "    print('best_valid_score: ', best_valid_score)\n",
    "    print('best_valid_result: ', best_valid_result)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    \n",
    "    print('\\n\\nTest results')\n",
    "    print(test_result)\n",
    "\n",
    "\n",
    "\n",
    "def test_from_checkpoint(model_name,\n",
    "                         dataset_name,\n",
    "                         parameter_dict,\n",
    "                         checkpoint_file):\n",
    "\n",
    "    config,\\\n",
    "        logger,\\\n",
    "             dataset,\\\n",
    "                 train_data, valid_data, test_data = setup_config_and_dataset(model_name,\n",
    "                                                                              dataset_name,\n",
    "                                                                              parameter_dict)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = BPR(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "\n",
    "    # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "    trainer.eval_collector.data_collect(train_data)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data, model_file=checkpoint_file)\n",
    "\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime error solved in later cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current model\n",
    "base_dataset_name = 'sudden_drift_dataset_4000x7_0.71'\n",
    "dataset_name = base_dataset_name+'_pt3'\n",
    "data_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "\n",
    "# Checkpoint - \n",
    "checkpoint_ver = 'BPR-Jan-01-2025_16-20-38'\n",
    "checkpoint_dir = data_path+base_dataset_name+'_pt2'\n",
    "checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "# checkpoint_file = checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':checkpoint_dir,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "test_from_checkpoint(MODEL, dataset_name, parameter_dict, checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_on_old_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_old_data(model_name,\n",
    "                         earlier_dataset_name,\n",
    "                         current_dataset_name,\n",
    "                         parameter_dict,\n",
    "                         checkpoint_file):\n",
    "\n",
    "    earlier_config,\\\n",
    "        earlier_logger,\\\n",
    "                earlier_dataset,\\\n",
    "                    earlier_train_data, earlier_valid_data, earlier_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                earlier_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "\n",
    "    current_config,\\\n",
    "        current_logger,\\\n",
    "                current_dataset,\\\n",
    "                    current_train_data, current_valid_data, current_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                current_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "    # model loading and initialization\n",
    "    current_model = BPR(current_config, current_train_data.dataset).to(current_config['device'])\n",
    "    current_logger.info(current_model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = get_trainer(current_config['MODEL_TYPE'], current_config['model'])(current_config, current_model)\n",
    "\n",
    "    # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "    trainer.eval_collector.data_collect(earlier_train_data)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(earlier_test_data, model_file=checkpoint_file)\n",
    "\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current model\n",
    "base_dataset_name = 'sudden_drift_dataset_4000x7_0.71'\n",
    "dataset_name = base_dataset_name+'_pt2'\n",
    "data_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "\n",
    "# Checkpoint - \n",
    "checkpoint_ver = 'BPR-Jan-01-2025_16-20-40'\n",
    "checkpoint_dir = data_path+base_dataset_name+'_pt3'\n",
    "checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "# checkpoint_file = checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "\n",
    "earlier_dataset_name = base_dataset_name+'_pt2'\n",
    "current_dataset_name = base_dataset_name+'_pt3'\n",
    "\n",
    "\n",
    "parameter_dict = {\n",
    "    'dataset': current_dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':checkpoint_dir,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "test_on_old_data(MODEL,\n",
    "                 earlier_dataset_name,\n",
    "                 current_dataset_name,\n",
    "                 parameter_dict, checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currently working cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_on_earlier_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_earlier_data(model_name,\n",
    "                         earlier_datasets,\n",
    "                         current_dataset_name,\n",
    "                         parameter_dict,\n",
    "                         checkpoint_file):\n",
    "\n",
    "\n",
    "    current_config,\\\n",
    "        current_logger,\\\n",
    "                current_dataset,\\\n",
    "                    current_train_data, current_valid_data, current_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                current_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "    # model loading and initialization\n",
    "    current_model = BPR(current_config, current_train_data.dataset).to(current_config['device'])\n",
    "    current_logger.info(current_model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = get_trainer(current_config['MODEL_TYPE'], current_config['model'])(current_config, current_model)\n",
    "\n",
    "\n",
    "    # results = []\n",
    "\n",
    "    for earlier_dataset_name in earlier_datasets:\n",
    "        print('\\n\\n'+earlier_dataset_name)\n",
    "        earlier_config,\\\n",
    "        earlier_logger,\\\n",
    "                earlier_dataset,\\\n",
    "                    earlier_train_data, earlier_valid_data, earlier_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                earlier_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "\n",
    "        # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "        # trainer.eval_collector.data_collect(earlier_train_data)\n",
    "        trainer.eval_collector.data_collect(current_train_data)\n",
    "\n",
    "        # model evaluation\n",
    "        test_result = trainer.evaluate(earlier_test_data, model_file=checkpoint_file)\n",
    "        # results += [test_result]\n",
    "    \n",
    "        print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current model\n",
    "base_dataset_name = 'sudden_drift_dataset_4000x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "current_ver = '_pt3'\n",
    "current_dataset_name = base_dataset_name+current_ver\n",
    "\n",
    "earlier_datasets = [base_dataset_name+'_pt1', base_dataset_name+'_pt8'] # 1,5,6,7,8\n",
    "\n",
    "\n",
    "# Checkpoint - \n",
    "checkpoint_ver = 'BPR-Jan-01-2025_16-20-40'\n",
    "checkpoint_dir = data_path+base_dataset_name+current_ver\n",
    "checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Suppose we want to leverage random ordering, \n",
    "# ratio-based splitting and \n",
    "# full ranking with all item candidates, \n",
    "# the splitting ratio is set as 8:1:1\n",
    "\n",
    "\n",
    "\n",
    "parameter_dict = {\n",
    "    'dataset': current_dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'user_inter_num_interval':'[1,inf)',\n",
    "    'checkpoint_dir':checkpoint_dir,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE,\n",
    "    # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "    'eval_args': {'split': {'LS': 'test_only'},\n",
    "                  'group_by': 'user',\n",
    "                  'order': 'RO',\n",
    "                  'mode': 'pop001'}\n",
    "}\n",
    "\n",
    "test_on_earlier_data(MODEL,\n",
    "                 earlier_datasets,\n",
    "                 current_dataset_name,\n",
    "                 parameter_dict, \n",
    "                 checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "data_path = processed_datasets/artificial_data/sudden_drift_dataset_4000x7_0.71_pt1\n",
    "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_4000x7_0.71_pt3\n",
    "01 Jan 19:05    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_4000x7_0.71_pt3/BPR-Jan-01-2025_16-20-40.pth\n",
    "\n",
    "OrderedDict([('recall@3', 0.7214), ('mrr@3', 0.6026), ('ndcg@3', 0.633), ('hit@3', 0.7214), ('precision@3', 0.2405)])\n",
    "\n",
    "\n",
    "data_path = processed_datasets/artificial_data/sudden_drift_dataset_4000x7_0.71_pt2\n",
    "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_4000x7_0.71_pt3\n",
    "01 Jan 19:05    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_4000x7_0.71_pt3/BPR-Jan-01-2025_16-20-40.pth\n",
    "\n",
    "OrderedDict([('recall@3', 0.7414), ('mrr@3', 0.6298), ('ndcg@3', 0.6583), ('hit@3', 0.7414), ('precision@3', 0.2471)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# isolate user seen all items error trigger conditions\n",
    "\n",
    "\n",
    "in these tests, the user 0 was added only at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current model\n",
    "base_dataset_name = 'sudden_drift_dataset_4000x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_error(data_path, base_dataset_name, model_ver, checkpoint_ver, data_ver):\n",
    "    current_ver = model_ver\n",
    "    current_dataset_name = base_dataset_name+current_ver\n",
    "\n",
    "    earlier_datasets = [base_dataset_name+data_ver]#,base_dataset_name+'_pt6', base_dataset_name+'_pt7', base_dataset_name+'_pt8'] # 1,5,6,7,8\n",
    "\n",
    "\n",
    "    # Checkpoint - \n",
    "    # checkpoint_ver = 'BPR-Jan-01-2025_16-20-32'\n",
    "    checkpoint_dir = data_path+base_dataset_name+current_ver\n",
    "    checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "    parameter_dict = {\n",
    "        'dataset': current_dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        'user_inter_num_interval':'[1,inf)',\n",
    "        'checkpoint_dir':checkpoint_dir,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE,\n",
    "        'state':'ERROR',\n",
    "        # 'show_progress': SHOW_PROGRESS,\n",
    "        # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "        'eval_args': {'split': {'LS': 'test_only'}, # leave-one-out sample type\n",
    "                    'group_by': 'user',\n",
    "                    'order': 'RO', # random ordering\n",
    "                    'mode': 'pop001'} #  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\n",
    "    }\n",
    "\n",
    "    test_on_earlier_data(MODEL,\n",
    "                    earlier_datasets,\n",
    "                    current_dataset_name,\n",
    "                    parameter_dict, \n",
    "                    checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model pt1 vs data pt5 : user seen all items error (UsI Error)\n",
    "\n",
    "ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-01-2025_16-20-32', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model pt1 vs data pt6 : (UsI Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-01-2025_16-20-32', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt7') (IndexError: index out of range in self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-01-2025_16-20-32', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt8') (UsI error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-01-2025_16-20-32', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt1'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-01-2025_16-20-38', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt5'): (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-01-2025_16-20-38', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt6'): (UsI error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-01-2025_16-20-38', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt7'): (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-01-2025_16-20-38', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt8'): (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-01-2025_16-20-38', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pt3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt1'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-01-2025_16-20-40', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt2'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-01-2025_16-20-40', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3',  data_ver='_pt5'): (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-01-2025_16-20-40', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt6'): (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-01-2025_16-20-40', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt7'): (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-01-2025_16-20-40', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt8'): (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-01-2025_16-20-40', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model full (pt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='',data_ver='_pt1'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-01-2025_16-20-44', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt2'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-01-2025_16-20-44', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt3'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-01-2025_16-20-44', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt5'): (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-01-2025_16-20-44', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt6'): : (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-01-2025_16-20-44', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt7'): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-01-2025_16-20-44', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt8'): : (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-01-2025_16-20-44', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what items does pt5 does not have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepath(base_folderpath, filename, pt):\n",
    "    return base_folderpath+filename+pt+'/'+filename+pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sudden_drift_dataset_4000x7_0.71'\n",
    "save_path = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt1 = pd.read_csv(get_filepath(save_path, filename, '_pt1')+'.csv')\n",
    "df_pt1.item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt2 = pd.read_csv(get_filepath(save_path, filename, '_pt2')+'.csv')\n",
    "df_pt2.item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt3 = pd.read_csv(get_filepath(save_path, filename, '_pt3')+'.csv')\n",
    "df_pt3.item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(get_filepath(save_path, filename, '')+'.csv')\n",
    "df_full.item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[['user_id','item_id']].groupby('user_id').count().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt5 = pd.read_csv(get_filepath(save_path, filename, '_pt5')+'.csv')\n",
    "df_pt5.item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt6 = pd.read_csv(get_filepath(save_path, filename, '_pt6')+'.csv')\n",
    "df_pt6.item_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate artificial datasets\n",
    "\n",
    "code copied from notebook 04 and altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'sudden_drift_dataset_4000x7_0.71'\n",
    "# save_path = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "drifted_i_5    1288\n",
       "drifted_i_1    1288\n",
       "i_1            1284\n",
       "i_5            1284\n",
       "i_3            1000\n",
       "i_2            1000\n",
       "i_4            1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv(get_filepath(SAVE_PATH, FILENAME, '')+'.csv')\n",
    "df_full.item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "i_5            946\n",
       "i_1            940\n",
       "i_2            382\n",
       "i_3            366\n",
       "i_4            364\n",
       "drifted_i_5      1\n",
       "drifted_i_1      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[:bin_size*3].reset_index(drop=True).item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "i_5            946\n",
       "i_1            940\n",
       "i_2            382\n",
       "i_3            366\n",
       "i_4            364\n",
       "drifted_i_5      1\n",
       "drifted_i_1      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['user_id_n'] = df_full['user_id'].apply(lambda x: x[2:])\n",
    "df_full['user_id_n'] = df_full['user_id_n'].astype(int)\n",
    "df_full.sort_values(by='user_id_n', inplace=True)\n",
    "df_full.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_full[:bin_size*3].reset_index(drop=True).item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u_0</td>\n",
       "      <td>drifted_i_5</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u_0</td>\n",
       "      <td>drifted_i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u_1</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u_2</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u_2</td>\n",
       "      <td>i_3</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>u_3998</td>\n",
       "      <td>drifted_i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>3998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>u_3998</td>\n",
       "      <td>drifted_i_5</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>3998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>u_3999</td>\n",
       "      <td>i_3</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>u_3999</td>\n",
       "      <td>drifted_i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>u_4000</td>\n",
       "      <td>drifted_i_5</td>\n",
       "      <td>1.735093e+09</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8144 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id      item_id     timestamp  user_id_n\n",
       "0        u_0  drifted_i_5  1.735093e+09          0\n",
       "1        u_0  drifted_i_1  1.735093e+09          0\n",
       "2        u_1          i_1  1.735093e+09          1\n",
       "3        u_2          i_1  1.735093e+09          2\n",
       "4        u_2          i_3  1.735093e+09          2\n",
       "...      ...          ...           ...        ...\n",
       "8139  u_3998  drifted_i_1  1.735093e+09       3998\n",
       "8140  u_3998  drifted_i_5  1.735093e+09       3998\n",
       "8141  u_3999          i_3  1.735093e+09       3999\n",
       "8142  u_3999  drifted_i_1  1.735093e+09       3999\n",
       "8143  u_4000  drifted_i_5  1.735093e+09       4000\n",
       "\n",
       "[8144 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 4000 # bc of random sample, some users dont have occurrencies\n",
    "n_items = 5\n",
    "sudden_drift_start = 2000  # Starting user index for drift (1-indexed)\n",
    "bin_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = [f'u_{i+1}' for i in range(n_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u_1',\n",
       " 'u_2',\n",
       " 'u_3',\n",
       " 'u_4',\n",
       " 'u_5',\n",
       " 'u_6',\n",
       " 'u_7',\n",
       " 'u_8',\n",
       " 'u_9',\n",
       " 'u_10',\n",
       " 'u_11',\n",
       " 'u_12',\n",
       " 'u_13',\n",
       " 'u_14',\n",
       " 'u_15',\n",
       " 'u_16',\n",
       " 'u_17',\n",
       " 'u_18',\n",
       " 'u_19',\n",
       " 'u_20',\n",
       " 'u_21',\n",
       " 'u_22',\n",
       " 'u_23',\n",
       " 'u_24',\n",
       " 'u_25',\n",
       " 'u_26',\n",
       " 'u_27',\n",
       " 'u_28',\n",
       " 'u_29',\n",
       " 'u_30',\n",
       " 'u_31',\n",
       " 'u_32',\n",
       " 'u_33',\n",
       " 'u_34',\n",
       " 'u_35',\n",
       " 'u_36',\n",
       " 'u_37',\n",
       " 'u_38',\n",
       " 'u_39',\n",
       " 'u_40',\n",
       " 'u_41',\n",
       " 'u_42',\n",
       " 'u_43',\n",
       " 'u_44',\n",
       " 'u_45',\n",
       " 'u_46',\n",
       " 'u_47',\n",
       " 'u_48',\n",
       " 'u_49',\n",
       " 'u_50',\n",
       " 'u_51',\n",
       " 'u_52',\n",
       " 'u_53',\n",
       " 'u_54',\n",
       " 'u_55',\n",
       " 'u_56',\n",
       " 'u_57',\n",
       " 'u_58',\n",
       " 'u_59',\n",
       " 'u_60',\n",
       " 'u_61',\n",
       " 'u_62',\n",
       " 'u_63',\n",
       " 'u_64',\n",
       " 'u_65',\n",
       " 'u_66',\n",
       " 'u_67',\n",
       " 'u_68',\n",
       " 'u_69',\n",
       " 'u_70',\n",
       " 'u_71',\n",
       " 'u_72',\n",
       " 'u_73',\n",
       " 'u_74',\n",
       " 'u_75',\n",
       " 'u_76',\n",
       " 'u_77',\n",
       " 'u_78',\n",
       " 'u_79',\n",
       " 'u_80',\n",
       " 'u_81',\n",
       " 'u_82',\n",
       " 'u_83',\n",
       " 'u_84',\n",
       " 'u_85',\n",
       " 'u_86',\n",
       " 'u_87',\n",
       " 'u_88',\n",
       " 'u_89',\n",
       " 'u_90',\n",
       " 'u_91',\n",
       " 'u_92',\n",
       " 'u_93',\n",
       " 'u_94',\n",
       " 'u_95',\n",
       " 'u_96',\n",
       " 'u_97',\n",
       " 'u_98',\n",
       " 'u_99',\n",
       " 'u_100',\n",
       " 'u_101',\n",
       " 'u_102',\n",
       " 'u_103',\n",
       " 'u_104',\n",
       " 'u_105',\n",
       " 'u_106',\n",
       " 'u_107',\n",
       " 'u_108',\n",
       " 'u_109',\n",
       " 'u_110',\n",
       " 'u_111',\n",
       " 'u_112',\n",
       " 'u_113',\n",
       " 'u_114',\n",
       " 'u_115',\n",
       " 'u_116',\n",
       " 'u_117',\n",
       " 'u_118',\n",
       " 'u_119',\n",
       " 'u_120',\n",
       " 'u_121',\n",
       " 'u_122',\n",
       " 'u_123',\n",
       " 'u_124',\n",
       " 'u_125',\n",
       " 'u_126',\n",
       " 'u_127',\n",
       " 'u_128',\n",
       " 'u_129',\n",
       " 'u_130',\n",
       " 'u_131',\n",
       " 'u_132',\n",
       " 'u_133',\n",
       " 'u_134',\n",
       " 'u_135',\n",
       " 'u_136',\n",
       " 'u_137',\n",
       " 'u_138',\n",
       " 'u_139',\n",
       " 'u_140',\n",
       " 'u_141',\n",
       " 'u_142',\n",
       " 'u_143',\n",
       " 'u_144',\n",
       " 'u_145',\n",
       " 'u_146',\n",
       " 'u_147',\n",
       " 'u_148',\n",
       " 'u_149',\n",
       " 'u_150',\n",
       " 'u_151',\n",
       " 'u_152',\n",
       " 'u_153',\n",
       " 'u_154',\n",
       " 'u_155',\n",
       " 'u_156',\n",
       " 'u_157',\n",
       " 'u_158',\n",
       " 'u_159',\n",
       " 'u_160',\n",
       " 'u_161',\n",
       " 'u_162',\n",
       " 'u_163',\n",
       " 'u_164',\n",
       " 'u_165',\n",
       " 'u_166',\n",
       " 'u_167',\n",
       " 'u_168',\n",
       " 'u_169',\n",
       " 'u_170',\n",
       " 'u_171',\n",
       " 'u_172',\n",
       " 'u_173',\n",
       " 'u_174',\n",
       " 'u_175',\n",
       " 'u_176',\n",
       " 'u_177',\n",
       " 'u_178',\n",
       " 'u_179',\n",
       " 'u_180',\n",
       " 'u_181',\n",
       " 'u_182',\n",
       " 'u_183',\n",
       " 'u_184',\n",
       " 'u_185',\n",
       " 'u_186',\n",
       " 'u_187',\n",
       " 'u_188',\n",
       " 'u_189',\n",
       " 'u_190',\n",
       " 'u_191',\n",
       " 'u_192',\n",
       " 'u_193',\n",
       " 'u_194',\n",
       " 'u_195',\n",
       " 'u_196',\n",
       " 'u_197',\n",
       " 'u_198',\n",
       " 'u_199',\n",
       " 'u_200',\n",
       " 'u_201',\n",
       " 'u_202',\n",
       " 'u_203',\n",
       " 'u_204',\n",
       " 'u_205',\n",
       " 'u_206',\n",
       " 'u_207',\n",
       " 'u_208',\n",
       " 'u_209',\n",
       " 'u_210',\n",
       " 'u_211',\n",
       " 'u_212',\n",
       " 'u_213',\n",
       " 'u_214',\n",
       " 'u_215',\n",
       " 'u_216',\n",
       " 'u_217',\n",
       " 'u_218',\n",
       " 'u_219',\n",
       " 'u_220',\n",
       " 'u_221',\n",
       " 'u_222',\n",
       " 'u_223',\n",
       " 'u_224',\n",
       " 'u_225',\n",
       " 'u_226',\n",
       " 'u_227',\n",
       " 'u_228',\n",
       " 'u_229',\n",
       " 'u_230',\n",
       " 'u_231',\n",
       " 'u_232',\n",
       " 'u_233',\n",
       " 'u_234',\n",
       " 'u_235',\n",
       " 'u_236',\n",
       " 'u_237',\n",
       " 'u_238',\n",
       " 'u_239',\n",
       " 'u_240',\n",
       " 'u_241',\n",
       " 'u_242',\n",
       " 'u_243',\n",
       " 'u_244',\n",
       " 'u_245',\n",
       " 'u_246',\n",
       " 'u_247',\n",
       " 'u_248',\n",
       " 'u_249',\n",
       " 'u_250',\n",
       " 'u_251',\n",
       " 'u_252',\n",
       " 'u_253',\n",
       " 'u_254',\n",
       " 'u_255',\n",
       " 'u_256',\n",
       " 'u_257',\n",
       " 'u_258',\n",
       " 'u_259',\n",
       " 'u_260',\n",
       " 'u_261',\n",
       " 'u_262',\n",
       " 'u_263',\n",
       " 'u_264',\n",
       " 'u_265',\n",
       " 'u_266',\n",
       " 'u_267',\n",
       " 'u_268',\n",
       " 'u_269',\n",
       " 'u_270',\n",
       " 'u_271',\n",
       " 'u_272',\n",
       " 'u_273',\n",
       " 'u_274',\n",
       " 'u_275',\n",
       " 'u_276',\n",
       " 'u_277',\n",
       " 'u_278',\n",
       " 'u_279',\n",
       " 'u_280',\n",
       " 'u_281',\n",
       " 'u_282',\n",
       " 'u_283',\n",
       " 'u_284',\n",
       " 'u_285',\n",
       " 'u_286',\n",
       " 'u_287',\n",
       " 'u_288',\n",
       " 'u_289',\n",
       " 'u_290',\n",
       " 'u_291',\n",
       " 'u_292',\n",
       " 'u_293',\n",
       " 'u_294',\n",
       " 'u_295',\n",
       " 'u_296',\n",
       " 'u_297',\n",
       " 'u_298',\n",
       " 'u_299',\n",
       " 'u_300',\n",
       " 'u_301',\n",
       " 'u_302',\n",
       " 'u_303',\n",
       " 'u_304',\n",
       " 'u_305',\n",
       " 'u_306',\n",
       " 'u_307',\n",
       " 'u_308',\n",
       " 'u_309',\n",
       " 'u_310',\n",
       " 'u_311',\n",
       " 'u_312',\n",
       " 'u_313',\n",
       " 'u_314',\n",
       " 'u_315',\n",
       " 'u_316',\n",
       " 'u_317',\n",
       " 'u_318',\n",
       " 'u_319',\n",
       " 'u_320',\n",
       " 'u_321',\n",
       " 'u_322',\n",
       " 'u_323',\n",
       " 'u_324',\n",
       " 'u_325',\n",
       " 'u_326',\n",
       " 'u_327',\n",
       " 'u_328',\n",
       " 'u_329',\n",
       " 'u_330',\n",
       " 'u_331',\n",
       " 'u_332',\n",
       " 'u_333',\n",
       " 'u_334',\n",
       " 'u_335',\n",
       " 'u_336',\n",
       " 'u_337',\n",
       " 'u_338',\n",
       " 'u_339',\n",
       " 'u_340',\n",
       " 'u_341',\n",
       " 'u_342',\n",
       " 'u_343',\n",
       " 'u_344',\n",
       " 'u_345',\n",
       " 'u_346',\n",
       " 'u_347',\n",
       " 'u_348',\n",
       " 'u_349',\n",
       " 'u_350',\n",
       " 'u_351',\n",
       " 'u_352',\n",
       " 'u_353',\n",
       " 'u_354',\n",
       " 'u_355',\n",
       " 'u_356',\n",
       " 'u_357',\n",
       " 'u_358',\n",
       " 'u_359',\n",
       " 'u_360',\n",
       " 'u_361',\n",
       " 'u_362',\n",
       " 'u_363',\n",
       " 'u_364',\n",
       " 'u_365',\n",
       " 'u_366',\n",
       " 'u_367',\n",
       " 'u_368',\n",
       " 'u_369',\n",
       " 'u_370',\n",
       " 'u_371',\n",
       " 'u_372',\n",
       " 'u_373',\n",
       " 'u_374',\n",
       " 'u_375',\n",
       " 'u_376',\n",
       " 'u_377',\n",
       " 'u_378',\n",
       " 'u_379',\n",
       " 'u_380',\n",
       " 'u_381',\n",
       " 'u_382',\n",
       " 'u_383',\n",
       " 'u_384',\n",
       " 'u_385',\n",
       " 'u_386',\n",
       " 'u_387',\n",
       " 'u_388',\n",
       " 'u_389',\n",
       " 'u_390',\n",
       " 'u_391',\n",
       " 'u_392',\n",
       " 'u_393',\n",
       " 'u_394',\n",
       " 'u_395',\n",
       " 'u_396',\n",
       " 'u_397',\n",
       " 'u_398',\n",
       " 'u_399',\n",
       " 'u_400',\n",
       " 'u_401',\n",
       " 'u_402',\n",
       " 'u_403',\n",
       " 'u_404',\n",
       " 'u_405',\n",
       " 'u_406',\n",
       " 'u_407',\n",
       " 'u_408',\n",
       " 'u_409',\n",
       " 'u_410',\n",
       " 'u_411',\n",
       " 'u_412',\n",
       " 'u_413',\n",
       " 'u_414',\n",
       " 'u_415',\n",
       " 'u_416',\n",
       " 'u_417',\n",
       " 'u_418',\n",
       " 'u_419',\n",
       " 'u_420',\n",
       " 'u_421',\n",
       " 'u_422',\n",
       " 'u_423',\n",
       " 'u_424',\n",
       " 'u_425',\n",
       " 'u_426',\n",
       " 'u_427',\n",
       " 'u_428',\n",
       " 'u_429',\n",
       " 'u_430',\n",
       " 'u_431',\n",
       " 'u_432',\n",
       " 'u_433',\n",
       " 'u_434',\n",
       " 'u_435',\n",
       " 'u_436',\n",
       " 'u_437',\n",
       " 'u_438',\n",
       " 'u_439',\n",
       " 'u_440',\n",
       " 'u_441',\n",
       " 'u_442',\n",
       " 'u_443',\n",
       " 'u_444',\n",
       " 'u_445',\n",
       " 'u_446',\n",
       " 'u_447',\n",
       " 'u_448',\n",
       " 'u_449',\n",
       " 'u_450',\n",
       " 'u_451',\n",
       " 'u_452',\n",
       " 'u_453',\n",
       " 'u_454',\n",
       " 'u_455',\n",
       " 'u_456',\n",
       " 'u_457',\n",
       " 'u_458',\n",
       " 'u_459',\n",
       " 'u_460',\n",
       " 'u_461',\n",
       " 'u_462',\n",
       " 'u_463',\n",
       " 'u_464',\n",
       " 'u_465',\n",
       " 'u_466',\n",
       " 'u_467',\n",
       " 'u_468',\n",
       " 'u_469',\n",
       " 'u_470',\n",
       " 'u_471',\n",
       " 'u_472',\n",
       " 'u_473',\n",
       " 'u_474',\n",
       " 'u_475',\n",
       " 'u_476',\n",
       " 'u_477',\n",
       " 'u_478',\n",
       " 'u_479',\n",
       " 'u_480',\n",
       " 'u_481',\n",
       " 'u_482',\n",
       " 'u_483',\n",
       " 'u_484',\n",
       " 'u_485',\n",
       " 'u_486',\n",
       " 'u_487',\n",
       " 'u_488',\n",
       " 'u_489',\n",
       " 'u_490',\n",
       " 'u_491',\n",
       " 'u_492',\n",
       " 'u_493',\n",
       " 'u_494',\n",
       " 'u_495',\n",
       " 'u_496',\n",
       " 'u_497',\n",
       " 'u_498',\n",
       " 'u_499',\n",
       " 'u_500',\n",
       " 'u_501',\n",
       " 'u_502',\n",
       " 'u_503',\n",
       " 'u_504',\n",
       " 'u_505',\n",
       " 'u_506',\n",
       " 'u_507',\n",
       " 'u_508',\n",
       " 'u_509',\n",
       " 'u_510',\n",
       " 'u_511',\n",
       " 'u_512',\n",
       " 'u_513',\n",
       " 'u_514',\n",
       " 'u_515',\n",
       " 'u_516',\n",
       " 'u_517',\n",
       " 'u_518',\n",
       " 'u_519',\n",
       " 'u_520',\n",
       " 'u_521',\n",
       " 'u_522',\n",
       " 'u_523',\n",
       " 'u_524',\n",
       " 'u_525',\n",
       " 'u_526',\n",
       " 'u_527',\n",
       " 'u_528',\n",
       " 'u_529',\n",
       " 'u_530',\n",
       " 'u_531',\n",
       " 'u_532',\n",
       " 'u_533',\n",
       " 'u_534',\n",
       " 'u_535',\n",
       " 'u_536',\n",
       " 'u_537',\n",
       " 'u_538',\n",
       " 'u_539',\n",
       " 'u_540',\n",
       " 'u_541',\n",
       " 'u_542',\n",
       " 'u_543',\n",
       " 'u_544',\n",
       " 'u_545',\n",
       " 'u_546',\n",
       " 'u_547',\n",
       " 'u_548',\n",
       " 'u_549',\n",
       " 'u_550',\n",
       " 'u_551',\n",
       " 'u_552',\n",
       " 'u_553',\n",
       " 'u_554',\n",
       " 'u_555',\n",
       " 'u_556',\n",
       " 'u_557',\n",
       " 'u_558',\n",
       " 'u_559',\n",
       " 'u_560',\n",
       " 'u_561',\n",
       " 'u_562',\n",
       " 'u_563',\n",
       " 'u_564',\n",
       " 'u_565',\n",
       " 'u_566',\n",
       " 'u_567',\n",
       " 'u_568',\n",
       " 'u_569',\n",
       " 'u_570',\n",
       " 'u_571',\n",
       " 'u_572',\n",
       " 'u_573',\n",
       " 'u_574',\n",
       " 'u_575',\n",
       " 'u_576',\n",
       " 'u_577',\n",
       " 'u_578',\n",
       " 'u_579',\n",
       " 'u_580',\n",
       " 'u_581',\n",
       " 'u_582',\n",
       " 'u_583',\n",
       " 'u_584',\n",
       " 'u_585',\n",
       " 'u_586',\n",
       " 'u_587',\n",
       " 'u_588',\n",
       " 'u_589',\n",
       " 'u_590',\n",
       " 'u_591',\n",
       " 'u_592',\n",
       " 'u_593',\n",
       " 'u_594',\n",
       " 'u_595',\n",
       " 'u_596',\n",
       " 'u_597',\n",
       " 'u_598',\n",
       " 'u_599',\n",
       " 'u_600',\n",
       " 'u_601',\n",
       " 'u_602',\n",
       " 'u_603',\n",
       " 'u_604',\n",
       " 'u_605',\n",
       " 'u_606',\n",
       " 'u_607',\n",
       " 'u_608',\n",
       " 'u_609',\n",
       " 'u_610',\n",
       " 'u_611',\n",
       " 'u_612',\n",
       " 'u_613',\n",
       " 'u_614',\n",
       " 'u_615',\n",
       " 'u_616',\n",
       " 'u_617',\n",
       " 'u_618',\n",
       " 'u_619',\n",
       " 'u_620',\n",
       " 'u_621',\n",
       " 'u_622',\n",
       " 'u_623',\n",
       " 'u_624',\n",
       " 'u_625',\n",
       " 'u_626',\n",
       " 'u_627',\n",
       " 'u_628',\n",
       " 'u_629',\n",
       " 'u_630',\n",
       " 'u_631',\n",
       " 'u_632',\n",
       " 'u_633',\n",
       " 'u_634',\n",
       " 'u_635',\n",
       " 'u_636',\n",
       " 'u_637',\n",
       " 'u_638',\n",
       " 'u_639',\n",
       " 'u_640',\n",
       " 'u_641',\n",
       " 'u_642',\n",
       " 'u_643',\n",
       " 'u_644',\n",
       " 'u_645',\n",
       " 'u_646',\n",
       " 'u_647',\n",
       " 'u_648',\n",
       " 'u_649',\n",
       " 'u_650',\n",
       " 'u_651',\n",
       " 'u_652',\n",
       " 'u_653',\n",
       " 'u_654',\n",
       " 'u_655',\n",
       " 'u_656',\n",
       " 'u_657',\n",
       " 'u_658',\n",
       " 'u_659',\n",
       " 'u_660',\n",
       " 'u_661',\n",
       " 'u_662',\n",
       " 'u_663',\n",
       " 'u_664',\n",
       " 'u_665',\n",
       " 'u_666',\n",
       " 'u_667',\n",
       " 'u_668',\n",
       " 'u_669',\n",
       " 'u_670',\n",
       " 'u_671',\n",
       " 'u_672',\n",
       " 'u_673',\n",
       " 'u_674',\n",
       " 'u_675',\n",
       " 'u_676',\n",
       " 'u_677',\n",
       " 'u_678',\n",
       " 'u_679',\n",
       " 'u_680',\n",
       " 'u_681',\n",
       " 'u_682',\n",
       " 'u_683',\n",
       " 'u_684',\n",
       " 'u_685',\n",
       " 'u_686',\n",
       " 'u_687',\n",
       " 'u_688',\n",
       " 'u_689',\n",
       " 'u_690',\n",
       " 'u_691',\n",
       " 'u_692',\n",
       " 'u_693',\n",
       " 'u_694',\n",
       " 'u_695',\n",
       " 'u_696',\n",
       " 'u_697',\n",
       " 'u_698',\n",
       " 'u_699',\n",
       " 'u_700',\n",
       " 'u_701',\n",
       " 'u_702',\n",
       " 'u_703',\n",
       " 'u_704',\n",
       " 'u_705',\n",
       " 'u_706',\n",
       " 'u_707',\n",
       " 'u_708',\n",
       " 'u_709',\n",
       " 'u_710',\n",
       " 'u_711',\n",
       " 'u_712',\n",
       " 'u_713',\n",
       " 'u_714',\n",
       " 'u_715',\n",
       " 'u_716',\n",
       " 'u_717',\n",
       " 'u_718',\n",
       " 'u_719',\n",
       " 'u_720',\n",
       " 'u_721',\n",
       " 'u_722',\n",
       " 'u_723',\n",
       " 'u_724',\n",
       " 'u_725',\n",
       " 'u_726',\n",
       " 'u_727',\n",
       " 'u_728',\n",
       " 'u_729',\n",
       " 'u_730',\n",
       " 'u_731',\n",
       " 'u_732',\n",
       " 'u_733',\n",
       " 'u_734',\n",
       " 'u_735',\n",
       " 'u_736',\n",
       " 'u_737',\n",
       " 'u_738',\n",
       " 'u_739',\n",
       " 'u_740',\n",
       " 'u_741',\n",
       " 'u_742',\n",
       " 'u_743',\n",
       " 'u_744',\n",
       " 'u_745',\n",
       " 'u_746',\n",
       " 'u_747',\n",
       " 'u_748',\n",
       " 'u_749',\n",
       " 'u_750',\n",
       " 'u_751',\n",
       " 'u_752',\n",
       " 'u_753',\n",
       " 'u_754',\n",
       " 'u_755',\n",
       " 'u_756',\n",
       " 'u_757',\n",
       " 'u_758',\n",
       " 'u_759',\n",
       " 'u_760',\n",
       " 'u_761',\n",
       " 'u_762',\n",
       " 'u_763',\n",
       " 'u_764',\n",
       " 'u_765',\n",
       " 'u_766',\n",
       " 'u_767',\n",
       " 'u_768',\n",
       " 'u_769',\n",
       " 'u_770',\n",
       " 'u_771',\n",
       " 'u_772',\n",
       " 'u_773',\n",
       " 'u_774',\n",
       " 'u_775',\n",
       " 'u_776',\n",
       " 'u_777',\n",
       " 'u_778',\n",
       " 'u_779',\n",
       " 'u_780',\n",
       " 'u_781',\n",
       " 'u_782',\n",
       " 'u_783',\n",
       " 'u_784',\n",
       " 'u_785',\n",
       " 'u_786',\n",
       " 'u_787',\n",
       " 'u_788',\n",
       " 'u_789',\n",
       " 'u_790',\n",
       " 'u_791',\n",
       " 'u_792',\n",
       " 'u_793',\n",
       " 'u_794',\n",
       " 'u_795',\n",
       " 'u_796',\n",
       " 'u_797',\n",
       " 'u_798',\n",
       " 'u_799',\n",
       " 'u_800',\n",
       " 'u_801',\n",
       " 'u_802',\n",
       " 'u_803',\n",
       " 'u_804',\n",
       " 'u_805',\n",
       " 'u_806',\n",
       " 'u_807',\n",
       " 'u_808',\n",
       " 'u_809',\n",
       " 'u_810',\n",
       " 'u_811',\n",
       " 'u_812',\n",
       " 'u_813',\n",
       " 'u_814',\n",
       " 'u_815',\n",
       " 'u_816',\n",
       " 'u_817',\n",
       " 'u_818',\n",
       " 'u_819',\n",
       " 'u_820',\n",
       " 'u_821',\n",
       " 'u_822',\n",
       " 'u_823',\n",
       " 'u_824',\n",
       " 'u_825',\n",
       " 'u_826',\n",
       " 'u_827',\n",
       " 'u_828',\n",
       " 'u_829',\n",
       " 'u_830',\n",
       " 'u_831',\n",
       " 'u_832',\n",
       " 'u_833',\n",
       " 'u_834',\n",
       " 'u_835',\n",
       " 'u_836',\n",
       " 'u_837',\n",
       " 'u_838',\n",
       " 'u_839',\n",
       " 'u_840',\n",
       " 'u_841',\n",
       " 'u_842',\n",
       " 'u_843',\n",
       " 'u_844',\n",
       " 'u_845',\n",
       " 'u_846',\n",
       " 'u_847',\n",
       " 'u_848',\n",
       " 'u_849',\n",
       " 'u_850',\n",
       " 'u_851',\n",
       " 'u_852',\n",
       " 'u_853',\n",
       " 'u_854',\n",
       " 'u_855',\n",
       " 'u_856',\n",
       " 'u_857',\n",
       " 'u_858',\n",
       " 'u_859',\n",
       " 'u_860',\n",
       " 'u_861',\n",
       " 'u_862',\n",
       " 'u_863',\n",
       " 'u_864',\n",
       " 'u_865',\n",
       " 'u_866',\n",
       " 'u_867',\n",
       " 'u_868',\n",
       " 'u_869',\n",
       " 'u_870',\n",
       " 'u_871',\n",
       " 'u_872',\n",
       " 'u_873',\n",
       " 'u_874',\n",
       " 'u_875',\n",
       " 'u_876',\n",
       " 'u_877',\n",
       " 'u_878',\n",
       " 'u_879',\n",
       " 'u_880',\n",
       " 'u_881',\n",
       " 'u_882',\n",
       " 'u_883',\n",
       " 'u_884',\n",
       " 'u_885',\n",
       " 'u_886',\n",
       " 'u_887',\n",
       " 'u_888',\n",
       " 'u_889',\n",
       " 'u_890',\n",
       " 'u_891',\n",
       " 'u_892',\n",
       " 'u_893',\n",
       " 'u_894',\n",
       " 'u_895',\n",
       " 'u_896',\n",
       " 'u_897',\n",
       " 'u_898',\n",
       " 'u_899',\n",
       " 'u_900',\n",
       " 'u_901',\n",
       " 'u_902',\n",
       " 'u_903',\n",
       " 'u_904',\n",
       " 'u_905',\n",
       " 'u_906',\n",
       " 'u_907',\n",
       " 'u_908',\n",
       " 'u_909',\n",
       " 'u_910',\n",
       " 'u_911',\n",
       " 'u_912',\n",
       " 'u_913',\n",
       " 'u_914',\n",
       " 'u_915',\n",
       " 'u_916',\n",
       " 'u_917',\n",
       " 'u_918',\n",
       " 'u_919',\n",
       " 'u_920',\n",
       " 'u_921',\n",
       " 'u_922',\n",
       " 'u_923',\n",
       " 'u_924',\n",
       " 'u_925',\n",
       " 'u_926',\n",
       " 'u_927',\n",
       " 'u_928',\n",
       " 'u_929',\n",
       " 'u_930',\n",
       " 'u_931',\n",
       " 'u_932',\n",
       " 'u_933',\n",
       " 'u_934',\n",
       " 'u_935',\n",
       " 'u_936',\n",
       " 'u_937',\n",
       " 'u_938',\n",
       " 'u_939',\n",
       " 'u_940',\n",
       " 'u_941',\n",
       " 'u_942',\n",
       " 'u_943',\n",
       " 'u_944',\n",
       " 'u_945',\n",
       " 'u_946',\n",
       " 'u_947',\n",
       " 'u_948',\n",
       " 'u_949',\n",
       " 'u_950',\n",
       " 'u_951',\n",
       " 'u_952',\n",
       " 'u_953',\n",
       " 'u_954',\n",
       " 'u_955',\n",
       " 'u_956',\n",
       " 'u_957',\n",
       " 'u_958',\n",
       " 'u_959',\n",
       " 'u_960',\n",
       " 'u_961',\n",
       " 'u_962',\n",
       " 'u_963',\n",
       " 'u_964',\n",
       " 'u_965',\n",
       " 'u_966',\n",
       " 'u_967',\n",
       " 'u_968',\n",
       " 'u_969',\n",
       " 'u_970',\n",
       " 'u_971',\n",
       " 'u_972',\n",
       " 'u_973',\n",
       " 'u_974',\n",
       " 'u_975',\n",
       " 'u_976',\n",
       " 'u_977',\n",
       " 'u_978',\n",
       " 'u_979',\n",
       " 'u_980',\n",
       " 'u_981',\n",
       " 'u_982',\n",
       " 'u_983',\n",
       " 'u_984',\n",
       " 'u_985',\n",
       " 'u_986',\n",
       " 'u_987',\n",
       " 'u_988',\n",
       " 'u_989',\n",
       " 'u_990',\n",
       " 'u_991',\n",
       " 'u_992',\n",
       " 'u_993',\n",
       " 'u_994',\n",
       " 'u_995',\n",
       " 'u_996',\n",
       " 'u_997',\n",
       " 'u_998',\n",
       " 'u_999',\n",
       " 'u_1000']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_list[:bin_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u_1',\n",
       " 'u_2',\n",
       " 'u_3',\n",
       " 'u_4',\n",
       " 'u_5',\n",
       " 'u_6',\n",
       " 'u_7',\n",
       " 'u_8',\n",
       " 'u_9',\n",
       " 'u_10',\n",
       " 'u_11',\n",
       " 'u_12',\n",
       " 'u_13',\n",
       " 'u_14',\n",
       " 'u_15',\n",
       " 'u_16',\n",
       " 'u_17',\n",
       " 'u_18',\n",
       " 'u_19',\n",
       " 'u_20',\n",
       " 'u_21',\n",
       " 'u_22',\n",
       " 'u_23',\n",
       " 'u_24',\n",
       " 'u_25',\n",
       " 'u_26',\n",
       " 'u_27',\n",
       " 'u_28',\n",
       " 'u_29',\n",
       " 'u_30',\n",
       " 'u_31',\n",
       " 'u_32',\n",
       " 'u_33',\n",
       " 'u_34',\n",
       " 'u_35',\n",
       " 'u_36',\n",
       " 'u_37',\n",
       " 'u_38',\n",
       " 'u_39',\n",
       " 'u_40',\n",
       " 'u_41',\n",
       " 'u_42',\n",
       " 'u_43',\n",
       " 'u_44',\n",
       " 'u_45',\n",
       " 'u_46',\n",
       " 'u_47',\n",
       " 'u_48',\n",
       " 'u_49',\n",
       " 'u_50',\n",
       " 'u_51',\n",
       " 'u_52',\n",
       " 'u_53',\n",
       " 'u_54',\n",
       " 'u_55',\n",
       " 'u_56',\n",
       " 'u_57',\n",
       " 'u_58',\n",
       " 'u_59',\n",
       " 'u_60',\n",
       " 'u_61',\n",
       " 'u_62',\n",
       " 'u_63',\n",
       " 'u_64',\n",
       " 'u_65',\n",
       " 'u_66',\n",
       " 'u_67',\n",
       " 'u_68',\n",
       " 'u_69',\n",
       " 'u_70',\n",
       " 'u_71',\n",
       " 'u_72',\n",
       " 'u_73',\n",
       " 'u_74',\n",
       " 'u_75',\n",
       " 'u_76',\n",
       " 'u_77',\n",
       " 'u_78',\n",
       " 'u_79',\n",
       " 'u_80',\n",
       " 'u_81',\n",
       " 'u_82',\n",
       " 'u_83',\n",
       " 'u_84',\n",
       " 'u_85',\n",
       " 'u_86',\n",
       " 'u_87',\n",
       " 'u_88',\n",
       " 'u_89',\n",
       " 'u_90',\n",
       " 'u_91',\n",
       " 'u_92',\n",
       " 'u_93',\n",
       " 'u_94',\n",
       " 'u_95',\n",
       " 'u_96',\n",
       " 'u_97',\n",
       " 'u_98',\n",
       " 'u_99',\n",
       " 'u_100',\n",
       " 'u_101',\n",
       " 'u_102',\n",
       " 'u_103',\n",
       " 'u_104',\n",
       " 'u_105',\n",
       " 'u_106',\n",
       " 'u_107',\n",
       " 'u_108',\n",
       " 'u_109',\n",
       " 'u_110',\n",
       " 'u_111',\n",
       " 'u_112',\n",
       " 'u_113',\n",
       " 'u_114',\n",
       " 'u_115',\n",
       " 'u_116',\n",
       " 'u_117',\n",
       " 'u_118',\n",
       " 'u_119',\n",
       " 'u_120',\n",
       " 'u_121',\n",
       " 'u_122',\n",
       " 'u_123',\n",
       " 'u_124',\n",
       " 'u_125',\n",
       " 'u_126',\n",
       " 'u_127',\n",
       " 'u_128',\n",
       " 'u_129',\n",
       " 'u_130',\n",
       " 'u_131',\n",
       " 'u_132',\n",
       " 'u_133',\n",
       " 'u_134',\n",
       " 'u_135',\n",
       " 'u_136',\n",
       " 'u_137',\n",
       " 'u_138',\n",
       " 'u_139',\n",
       " 'u_140',\n",
       " 'u_141',\n",
       " 'u_142',\n",
       " 'u_143',\n",
       " 'u_144',\n",
       " 'u_145',\n",
       " 'u_146',\n",
       " 'u_147',\n",
       " 'u_148',\n",
       " 'u_149',\n",
       " 'u_150',\n",
       " 'u_151',\n",
       " 'u_152',\n",
       " 'u_153',\n",
       " 'u_154',\n",
       " 'u_155',\n",
       " 'u_156',\n",
       " 'u_157',\n",
       " 'u_158',\n",
       " 'u_159',\n",
       " 'u_160',\n",
       " 'u_161',\n",
       " 'u_162',\n",
       " 'u_163',\n",
       " 'u_164',\n",
       " 'u_165',\n",
       " 'u_166',\n",
       " 'u_167',\n",
       " 'u_168',\n",
       " 'u_169',\n",
       " 'u_170',\n",
       " 'u_171',\n",
       " 'u_172',\n",
       " 'u_173',\n",
       " 'u_174',\n",
       " 'u_175',\n",
       " 'u_176',\n",
       " 'u_177',\n",
       " 'u_178',\n",
       " 'u_179',\n",
       " 'u_180',\n",
       " 'u_181',\n",
       " 'u_182',\n",
       " 'u_183',\n",
       " 'u_184',\n",
       " 'u_185',\n",
       " 'u_186',\n",
       " 'u_187',\n",
       " 'u_188',\n",
       " 'u_189',\n",
       " 'u_190',\n",
       " 'u_191',\n",
       " 'u_192',\n",
       " 'u_193',\n",
       " 'u_194',\n",
       " 'u_195',\n",
       " 'u_196',\n",
       " 'u_197',\n",
       " 'u_198',\n",
       " 'u_199',\n",
       " 'u_200',\n",
       " 'u_201',\n",
       " 'u_202',\n",
       " 'u_203',\n",
       " 'u_204',\n",
       " 'u_205',\n",
       " 'u_206',\n",
       " 'u_207',\n",
       " 'u_208',\n",
       " 'u_209',\n",
       " 'u_210',\n",
       " 'u_211',\n",
       " 'u_212',\n",
       " 'u_213',\n",
       " 'u_214',\n",
       " 'u_215',\n",
       " 'u_216',\n",
       " 'u_217',\n",
       " 'u_218',\n",
       " 'u_219',\n",
       " 'u_220',\n",
       " 'u_221',\n",
       " 'u_222',\n",
       " 'u_223',\n",
       " 'u_224',\n",
       " 'u_225',\n",
       " 'u_226',\n",
       " 'u_227',\n",
       " 'u_228',\n",
       " 'u_229',\n",
       " 'u_230',\n",
       " 'u_231',\n",
       " 'u_232',\n",
       " 'u_233',\n",
       " 'u_234',\n",
       " 'u_235',\n",
       " 'u_236',\n",
       " 'u_237',\n",
       " 'u_238',\n",
       " 'u_239',\n",
       " 'u_240',\n",
       " 'u_241',\n",
       " 'u_242',\n",
       " 'u_243',\n",
       " 'u_244',\n",
       " 'u_245',\n",
       " 'u_246',\n",
       " 'u_247',\n",
       " 'u_248',\n",
       " 'u_249',\n",
       " 'u_250',\n",
       " 'u_251',\n",
       " 'u_252',\n",
       " 'u_253',\n",
       " 'u_254',\n",
       " 'u_255',\n",
       " 'u_256',\n",
       " 'u_257',\n",
       " 'u_258',\n",
       " 'u_259',\n",
       " 'u_260',\n",
       " 'u_261',\n",
       " 'u_262',\n",
       " 'u_263',\n",
       " 'u_264',\n",
       " 'u_265',\n",
       " 'u_266',\n",
       " 'u_267',\n",
       " 'u_268',\n",
       " 'u_269',\n",
       " 'u_270',\n",
       " 'u_271',\n",
       " 'u_272',\n",
       " 'u_273',\n",
       " 'u_274',\n",
       " 'u_275',\n",
       " 'u_276',\n",
       " 'u_277',\n",
       " 'u_278',\n",
       " 'u_279',\n",
       " 'u_280',\n",
       " 'u_281',\n",
       " 'u_282',\n",
       " 'u_283',\n",
       " 'u_284',\n",
       " 'u_285',\n",
       " 'u_286',\n",
       " 'u_287',\n",
       " 'u_288',\n",
       " 'u_289',\n",
       " 'u_290',\n",
       " 'u_291',\n",
       " 'u_292',\n",
       " 'u_293',\n",
       " 'u_294',\n",
       " 'u_295',\n",
       " 'u_296',\n",
       " 'u_297',\n",
       " 'u_298',\n",
       " 'u_299',\n",
       " 'u_300',\n",
       " 'u_301',\n",
       " 'u_302',\n",
       " 'u_303',\n",
       " 'u_304',\n",
       " 'u_305',\n",
       " 'u_306',\n",
       " 'u_307',\n",
       " 'u_308',\n",
       " 'u_309',\n",
       " 'u_310',\n",
       " 'u_311',\n",
       " 'u_312',\n",
       " 'u_313',\n",
       " 'u_314',\n",
       " 'u_315',\n",
       " 'u_316',\n",
       " 'u_317',\n",
       " 'u_318',\n",
       " 'u_319',\n",
       " 'u_320',\n",
       " 'u_321',\n",
       " 'u_322',\n",
       " 'u_323',\n",
       " 'u_324',\n",
       " 'u_325',\n",
       " 'u_326',\n",
       " 'u_327',\n",
       " 'u_328',\n",
       " 'u_329',\n",
       " 'u_330',\n",
       " 'u_331',\n",
       " 'u_332',\n",
       " 'u_333',\n",
       " 'u_334',\n",
       " 'u_335',\n",
       " 'u_336',\n",
       " 'u_337',\n",
       " 'u_338',\n",
       " 'u_339',\n",
       " 'u_340',\n",
       " 'u_341',\n",
       " 'u_342',\n",
       " 'u_343',\n",
       " 'u_344',\n",
       " 'u_345',\n",
       " 'u_346',\n",
       " 'u_347',\n",
       " 'u_348',\n",
       " 'u_349',\n",
       " 'u_350',\n",
       " 'u_351',\n",
       " 'u_352',\n",
       " 'u_353',\n",
       " 'u_354',\n",
       " 'u_355',\n",
       " 'u_356',\n",
       " 'u_357',\n",
       " 'u_358',\n",
       " 'u_359',\n",
       " 'u_360',\n",
       " 'u_361',\n",
       " 'u_362',\n",
       " 'u_363',\n",
       " 'u_364',\n",
       " 'u_365',\n",
       " 'u_366',\n",
       " 'u_367',\n",
       " 'u_368',\n",
       " 'u_369',\n",
       " 'u_370',\n",
       " 'u_371',\n",
       " 'u_372',\n",
       " 'u_373',\n",
       " 'u_374',\n",
       " 'u_375',\n",
       " 'u_376',\n",
       " 'u_377',\n",
       " 'u_378',\n",
       " 'u_379',\n",
       " 'u_380',\n",
       " 'u_381',\n",
       " 'u_382',\n",
       " 'u_383',\n",
       " 'u_384',\n",
       " 'u_385',\n",
       " 'u_386',\n",
       " 'u_387',\n",
       " 'u_388',\n",
       " 'u_389',\n",
       " 'u_390',\n",
       " 'u_391',\n",
       " 'u_392',\n",
       " 'u_393',\n",
       " 'u_394',\n",
       " 'u_395',\n",
       " 'u_396',\n",
       " 'u_397',\n",
       " 'u_398',\n",
       " 'u_399',\n",
       " 'u_400',\n",
       " 'u_401',\n",
       " 'u_402',\n",
       " 'u_403',\n",
       " 'u_404',\n",
       " 'u_405',\n",
       " 'u_406',\n",
       " 'u_407',\n",
       " 'u_408',\n",
       " 'u_409',\n",
       " 'u_410',\n",
       " 'u_411',\n",
       " 'u_412',\n",
       " 'u_413',\n",
       " 'u_414',\n",
       " 'u_415',\n",
       " 'u_416',\n",
       " 'u_417',\n",
       " 'u_418',\n",
       " 'u_419',\n",
       " 'u_420',\n",
       " 'u_421',\n",
       " 'u_422',\n",
       " 'u_423',\n",
       " 'u_424',\n",
       " 'u_425',\n",
       " 'u_426',\n",
       " 'u_427',\n",
       " 'u_428',\n",
       " 'u_429',\n",
       " 'u_430',\n",
       " 'u_431',\n",
       " 'u_432',\n",
       " 'u_433',\n",
       " 'u_434',\n",
       " 'u_435',\n",
       " 'u_436',\n",
       " 'u_437',\n",
       " 'u_438',\n",
       " 'u_439',\n",
       " 'u_440',\n",
       " 'u_441',\n",
       " 'u_442',\n",
       " 'u_443',\n",
       " 'u_444',\n",
       " 'u_445',\n",
       " 'u_446',\n",
       " 'u_447',\n",
       " 'u_448',\n",
       " 'u_449',\n",
       " 'u_450',\n",
       " 'u_451',\n",
       " 'u_452',\n",
       " 'u_453',\n",
       " 'u_454',\n",
       " 'u_455',\n",
       " 'u_456',\n",
       " 'u_457',\n",
       " 'u_458',\n",
       " 'u_459',\n",
       " 'u_460',\n",
       " 'u_461',\n",
       " 'u_462',\n",
       " 'u_463',\n",
       " 'u_464',\n",
       " 'u_465',\n",
       " 'u_466',\n",
       " 'u_467',\n",
       " 'u_468',\n",
       " 'u_469',\n",
       " 'u_470',\n",
       " 'u_471',\n",
       " 'u_472',\n",
       " 'u_473',\n",
       " 'u_474',\n",
       " 'u_475',\n",
       " 'u_476',\n",
       " 'u_477',\n",
       " 'u_478',\n",
       " 'u_479',\n",
       " 'u_480',\n",
       " 'u_481',\n",
       " 'u_482',\n",
       " 'u_483',\n",
       " 'u_484',\n",
       " 'u_485',\n",
       " 'u_486',\n",
       " 'u_487',\n",
       " 'u_488',\n",
       " 'u_489',\n",
       " 'u_490',\n",
       " 'u_491',\n",
       " 'u_492',\n",
       " 'u_493',\n",
       " 'u_494',\n",
       " 'u_495',\n",
       " 'u_496',\n",
       " 'u_497',\n",
       " 'u_498',\n",
       " 'u_499',\n",
       " 'u_500',\n",
       " 'u_501',\n",
       " 'u_502',\n",
       " 'u_503',\n",
       " 'u_504',\n",
       " 'u_505',\n",
       " 'u_506',\n",
       " 'u_507',\n",
       " 'u_508',\n",
       " 'u_509',\n",
       " 'u_510',\n",
       " 'u_511',\n",
       " 'u_512',\n",
       " 'u_513',\n",
       " 'u_514',\n",
       " 'u_515',\n",
       " 'u_516',\n",
       " 'u_517',\n",
       " 'u_518',\n",
       " 'u_519',\n",
       " 'u_520',\n",
       " 'u_521',\n",
       " 'u_522',\n",
       " 'u_523',\n",
       " 'u_524',\n",
       " 'u_525',\n",
       " 'u_526',\n",
       " 'u_527',\n",
       " 'u_528',\n",
       " 'u_529',\n",
       " 'u_530',\n",
       " 'u_531',\n",
       " 'u_532',\n",
       " 'u_533',\n",
       " 'u_534',\n",
       " 'u_535',\n",
       " 'u_536',\n",
       " 'u_537',\n",
       " 'u_538',\n",
       " 'u_539',\n",
       " 'u_540',\n",
       " 'u_541',\n",
       " 'u_542',\n",
       " 'u_543',\n",
       " 'u_544',\n",
       " 'u_545',\n",
       " 'u_546',\n",
       " 'u_547',\n",
       " 'u_548',\n",
       " 'u_549',\n",
       " 'u_550',\n",
       " 'u_551',\n",
       " 'u_552',\n",
       " 'u_553',\n",
       " 'u_554',\n",
       " 'u_555',\n",
       " 'u_556',\n",
       " 'u_557',\n",
       " 'u_558',\n",
       " 'u_559',\n",
       " 'u_560',\n",
       " 'u_561',\n",
       " 'u_562',\n",
       " 'u_563',\n",
       " 'u_564',\n",
       " 'u_565',\n",
       " 'u_566',\n",
       " 'u_567',\n",
       " 'u_568',\n",
       " 'u_569',\n",
       " 'u_570',\n",
       " 'u_571',\n",
       " 'u_572',\n",
       " 'u_573',\n",
       " 'u_574',\n",
       " 'u_575',\n",
       " 'u_576',\n",
       " 'u_577',\n",
       " 'u_578',\n",
       " 'u_579',\n",
       " 'u_580',\n",
       " 'u_581',\n",
       " 'u_582',\n",
       " 'u_583',\n",
       " 'u_584',\n",
       " 'u_585',\n",
       " 'u_586',\n",
       " 'u_587',\n",
       " 'u_588',\n",
       " 'u_589',\n",
       " 'u_590',\n",
       " 'u_591',\n",
       " 'u_592',\n",
       " 'u_593',\n",
       " 'u_594',\n",
       " 'u_595',\n",
       " 'u_596',\n",
       " 'u_597',\n",
       " 'u_598',\n",
       " 'u_599',\n",
       " 'u_600',\n",
       " 'u_601',\n",
       " 'u_602',\n",
       " 'u_603',\n",
       " 'u_604',\n",
       " 'u_605',\n",
       " 'u_606',\n",
       " 'u_607',\n",
       " 'u_608',\n",
       " 'u_609',\n",
       " 'u_610',\n",
       " 'u_611',\n",
       " 'u_612',\n",
       " 'u_613',\n",
       " 'u_614',\n",
       " 'u_615',\n",
       " 'u_616',\n",
       " 'u_617',\n",
       " 'u_618',\n",
       " 'u_619',\n",
       " 'u_620',\n",
       " 'u_621',\n",
       " 'u_622',\n",
       " 'u_623',\n",
       " 'u_624',\n",
       " 'u_625',\n",
       " 'u_626',\n",
       " 'u_627',\n",
       " 'u_628',\n",
       " 'u_629',\n",
       " 'u_630',\n",
       " 'u_631',\n",
       " 'u_632',\n",
       " 'u_633',\n",
       " 'u_634',\n",
       " 'u_635',\n",
       " 'u_636',\n",
       " 'u_637',\n",
       " 'u_638',\n",
       " 'u_639',\n",
       " 'u_640',\n",
       " 'u_641',\n",
       " 'u_642',\n",
       " 'u_643',\n",
       " 'u_644',\n",
       " 'u_645',\n",
       " 'u_646',\n",
       " 'u_647',\n",
       " 'u_648',\n",
       " 'u_649',\n",
       " 'u_650',\n",
       " 'u_651',\n",
       " 'u_652',\n",
       " 'u_653',\n",
       " 'u_654',\n",
       " 'u_655',\n",
       " 'u_656',\n",
       " 'u_657',\n",
       " 'u_658',\n",
       " 'u_659',\n",
       " 'u_660',\n",
       " 'u_661',\n",
       " 'u_662',\n",
       " 'u_663',\n",
       " 'u_664',\n",
       " 'u_665',\n",
       " 'u_666',\n",
       " 'u_667',\n",
       " 'u_668',\n",
       " 'u_669',\n",
       " 'u_670',\n",
       " 'u_671',\n",
       " 'u_672',\n",
       " 'u_673',\n",
       " 'u_674',\n",
       " 'u_675',\n",
       " 'u_676',\n",
       " 'u_677',\n",
       " 'u_678',\n",
       " 'u_679',\n",
       " 'u_680',\n",
       " 'u_681',\n",
       " 'u_682',\n",
       " 'u_683',\n",
       " 'u_684',\n",
       " 'u_685',\n",
       " 'u_686',\n",
       " 'u_687',\n",
       " 'u_688',\n",
       " 'u_689',\n",
       " 'u_690',\n",
       " 'u_691',\n",
       " 'u_692',\n",
       " 'u_693',\n",
       " 'u_694',\n",
       " 'u_695',\n",
       " 'u_696',\n",
       " 'u_697',\n",
       " 'u_698',\n",
       " 'u_699',\n",
       " 'u_700',\n",
       " 'u_701',\n",
       " 'u_702',\n",
       " 'u_703',\n",
       " 'u_704',\n",
       " 'u_705',\n",
       " 'u_706',\n",
       " 'u_707',\n",
       " 'u_708',\n",
       " 'u_709',\n",
       " 'u_710',\n",
       " 'u_711',\n",
       " 'u_712',\n",
       " 'u_713',\n",
       " 'u_714',\n",
       " 'u_715',\n",
       " 'u_716',\n",
       " 'u_717',\n",
       " 'u_718',\n",
       " 'u_719',\n",
       " 'u_720',\n",
       " 'u_721',\n",
       " 'u_722',\n",
       " 'u_723',\n",
       " 'u_724',\n",
       " 'u_725',\n",
       " 'u_726',\n",
       " 'u_727',\n",
       " 'u_728',\n",
       " 'u_729',\n",
       " 'u_730',\n",
       " 'u_731',\n",
       " 'u_732',\n",
       " 'u_733',\n",
       " 'u_734',\n",
       " 'u_735',\n",
       " 'u_736',\n",
       " 'u_737',\n",
       " 'u_738',\n",
       " 'u_739',\n",
       " 'u_740',\n",
       " 'u_741',\n",
       " 'u_742',\n",
       " 'u_743',\n",
       " 'u_744',\n",
       " 'u_745',\n",
       " 'u_746',\n",
       " 'u_747',\n",
       " 'u_748',\n",
       " 'u_749',\n",
       " 'u_750',\n",
       " 'u_751',\n",
       " 'u_752',\n",
       " 'u_753',\n",
       " 'u_754',\n",
       " 'u_755',\n",
       " 'u_756',\n",
       " 'u_757',\n",
       " 'u_758',\n",
       " 'u_759',\n",
       " 'u_760',\n",
       " 'u_761',\n",
       " 'u_762',\n",
       " 'u_763',\n",
       " 'u_764',\n",
       " 'u_765',\n",
       " 'u_766',\n",
       " 'u_767',\n",
       " 'u_768',\n",
       " 'u_769',\n",
       " 'u_770',\n",
       " 'u_771',\n",
       " 'u_772',\n",
       " 'u_773',\n",
       " 'u_774',\n",
       " 'u_775',\n",
       " 'u_776',\n",
       " 'u_777',\n",
       " 'u_778',\n",
       " 'u_779',\n",
       " 'u_780',\n",
       " 'u_781',\n",
       " 'u_782',\n",
       " 'u_783',\n",
       " 'u_784',\n",
       " 'u_785',\n",
       " 'u_786',\n",
       " 'u_787',\n",
       " 'u_788',\n",
       " 'u_789',\n",
       " 'u_790',\n",
       " 'u_791',\n",
       " 'u_792',\n",
       " 'u_793',\n",
       " 'u_794',\n",
       " 'u_795',\n",
       " 'u_796',\n",
       " 'u_797',\n",
       " 'u_798',\n",
       " 'u_799',\n",
       " 'u_800',\n",
       " 'u_801',\n",
       " 'u_802',\n",
       " 'u_803',\n",
       " 'u_804',\n",
       " 'u_805',\n",
       " 'u_806',\n",
       " 'u_807',\n",
       " 'u_808',\n",
       " 'u_809',\n",
       " 'u_810',\n",
       " 'u_811',\n",
       " 'u_812',\n",
       " 'u_813',\n",
       " 'u_814',\n",
       " 'u_815',\n",
       " 'u_816',\n",
       " 'u_817',\n",
       " 'u_818',\n",
       " 'u_819',\n",
       " 'u_820',\n",
       " 'u_821',\n",
       " 'u_822',\n",
       " 'u_823',\n",
       " 'u_824',\n",
       " 'u_825',\n",
       " 'u_826',\n",
       " 'u_827',\n",
       " 'u_828',\n",
       " 'u_829',\n",
       " 'u_830',\n",
       " 'u_831',\n",
       " 'u_832',\n",
       " 'u_833',\n",
       " 'u_834',\n",
       " 'u_835',\n",
       " 'u_836',\n",
       " 'u_837',\n",
       " 'u_838',\n",
       " 'u_839',\n",
       " 'u_840',\n",
       " 'u_841',\n",
       " 'u_842',\n",
       " 'u_843',\n",
       " 'u_844',\n",
       " 'u_845',\n",
       " 'u_846',\n",
       " 'u_847',\n",
       " 'u_848',\n",
       " 'u_849',\n",
       " 'u_850',\n",
       " 'u_851',\n",
       " 'u_852',\n",
       " 'u_853',\n",
       " 'u_854',\n",
       " 'u_855',\n",
       " 'u_856',\n",
       " 'u_857',\n",
       " 'u_858',\n",
       " 'u_859',\n",
       " 'u_860',\n",
       " 'u_861',\n",
       " 'u_862',\n",
       " 'u_863',\n",
       " 'u_864',\n",
       " 'u_865',\n",
       " 'u_866',\n",
       " 'u_867',\n",
       " 'u_868',\n",
       " 'u_869',\n",
       " 'u_870',\n",
       " 'u_871',\n",
       " 'u_872',\n",
       " 'u_873',\n",
       " 'u_874',\n",
       " 'u_875',\n",
       " 'u_876',\n",
       " 'u_877',\n",
       " 'u_878',\n",
       " 'u_879',\n",
       " 'u_880',\n",
       " 'u_881',\n",
       " 'u_882',\n",
       " 'u_883',\n",
       " 'u_884',\n",
       " 'u_885',\n",
       " 'u_886',\n",
       " 'u_887',\n",
       " 'u_888',\n",
       " 'u_889',\n",
       " 'u_890',\n",
       " 'u_891',\n",
       " 'u_892',\n",
       " 'u_893',\n",
       " 'u_894',\n",
       " 'u_895',\n",
       " 'u_896',\n",
       " 'u_897',\n",
       " 'u_898',\n",
       " 'u_899',\n",
       " 'u_900',\n",
       " 'u_901',\n",
       " 'u_902',\n",
       " 'u_903',\n",
       " 'u_904',\n",
       " 'u_905',\n",
       " 'u_906',\n",
       " 'u_907',\n",
       " 'u_908',\n",
       " 'u_909',\n",
       " 'u_910',\n",
       " 'u_911',\n",
       " 'u_912',\n",
       " 'u_913',\n",
       " 'u_914',\n",
       " 'u_915',\n",
       " 'u_916',\n",
       " 'u_917',\n",
       " 'u_918',\n",
       " 'u_919',\n",
       " 'u_920',\n",
       " 'u_921',\n",
       " 'u_922',\n",
       " 'u_923',\n",
       " 'u_924',\n",
       " 'u_925',\n",
       " 'u_926',\n",
       " 'u_927',\n",
       " 'u_928',\n",
       " 'u_929',\n",
       " 'u_930',\n",
       " 'u_931',\n",
       " 'u_932',\n",
       " 'u_933',\n",
       " 'u_934',\n",
       " 'u_935',\n",
       " 'u_936',\n",
       " 'u_937',\n",
       " 'u_938',\n",
       " 'u_939',\n",
       " 'u_940',\n",
       " 'u_941',\n",
       " 'u_942',\n",
       " 'u_943',\n",
       " 'u_944',\n",
       " 'u_945',\n",
       " 'u_946',\n",
       " 'u_947',\n",
       " 'u_948',\n",
       " 'u_949',\n",
       " 'u_950',\n",
       " 'u_951',\n",
       " 'u_952',\n",
       " 'u_953',\n",
       " 'u_954',\n",
       " 'u_955',\n",
       " 'u_956',\n",
       " 'u_957',\n",
       " 'u_958',\n",
       " 'u_959',\n",
       " 'u_960',\n",
       " 'u_961',\n",
       " 'u_962',\n",
       " 'u_963',\n",
       " 'u_964',\n",
       " 'u_965',\n",
       " 'u_966',\n",
       " 'u_967',\n",
       " 'u_968',\n",
       " 'u_969',\n",
       " 'u_970',\n",
       " 'u_971',\n",
       " 'u_972',\n",
       " 'u_973',\n",
       " 'u_974',\n",
       " 'u_975',\n",
       " 'u_976',\n",
       " 'u_977',\n",
       " 'u_978',\n",
       " 'u_979',\n",
       " 'u_980',\n",
       " 'u_981',\n",
       " 'u_982',\n",
       " 'u_983',\n",
       " 'u_984',\n",
       " 'u_985',\n",
       " 'u_986',\n",
       " 'u_987',\n",
       " 'u_988',\n",
       " 'u_989',\n",
       " 'u_990',\n",
       " 'u_991',\n",
       " 'u_992',\n",
       " 'u_993',\n",
       " 'u_994',\n",
       " 'u_995',\n",
       " 'u_996',\n",
       " 'u_997',\n",
       " 'u_998',\n",
       " 'u_999',\n",
       " 'u_1000',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_list[:bin_size*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "drifted_i_1    661\n",
       "drifted_i_5    651\n",
       "i_5            640\n",
       "i_1            622\n",
       "i_3            500\n",
       "i_4            500\n",
       "i_2            493\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full[df_full.user_id.isin(users_list[bin_size:bin_size*3])].reset_index(drop=True).item_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def validate_folderpath(folderpath):\n",
    "    # print('im validating')\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "        print('Folder created: ', folderpath)\n",
    "\n",
    "\n",
    "def save_picklefile(d, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "\n",
    "    print('Saved file at '+filepath)\n",
    "\n",
    "def load_picklefile(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "    return loaded_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def generate_artificial_random_dataset(n_users,\n",
    "                                       n_items, \n",
    "                                       ts,\n",
    "                                       all_items_seen,\n",
    "                                       random_seed,\n",
    "                                       n_items_to_drift,\n",
    "                                       sudden_drift_start,\n",
    "                                       drift_items_freq_list,\n",
    "                                       non_drift_items_freq_list,\n",
    "                                       save_path,\n",
    "                                       base_filename,\n",
    "                                       bin_size):\n",
    "    \n",
    "    def add_zero_user(df):\n",
    "\n",
    "        df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "        df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "        # df.loc[-1] = ['u_-1', 'i_1', ts, 0]\n",
    "        # df.loc[-2] = ['u_-1', 'i_2', ts, 0]\n",
    "        # df.loc[-3] = ['u_-1', 'i_3', ts, 0]\n",
    "        # df.loc[-4] = ['u_-1', 'i_5', ts, 0]\n",
    "        # df.loc[-5] = ['u_0', 'i_4', ts, 0]\n",
    "        df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "        df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        df.sort_values(by='user_id_n', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "        # print('added zero user\\n', df.head())\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def create_folderpath(save_path, base_filename, specs_str):\n",
    "        return save_path+base_filename+'_'+specs_str+'/'\n",
    "    \n",
    "\n",
    "    def save_items_frequencies(n_items_to_drift,\n",
    "                               sudden_drift_start,\n",
    "                               drift_items_freq_list,\n",
    "                               non_drift_items_freq_list,\n",
    "                               save_path, \n",
    "                               base_filename,\n",
    "                               specs_str):\n",
    "        \n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "\n",
    "        d = {'n_items_to_drift': n_items_to_drift,\n",
    "             'sudden_drift_start': sudden_drift_start,\n",
    "             'drift_items_freq_list': drift_items_freq_list,\n",
    "             'non_drift_items_freq_list': non_drift_items_freq_list}\n",
    "\n",
    "        save_picklefile(d, folderpath+'saved_dictionary.pkl')\n",
    "       \n",
    "\n",
    "    \n",
    "    def save_dataset_atomic_file(df, user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "    def add_user0_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "            df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "        \n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_add_user0_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        add_user0_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_sparsity(df):\n",
    "        # df.item_id.groupby([df.user_id, df.item_id]).count().sum() == df.user_id.count()\n",
    "        sparsity = 1 - df.user_id.count()/(df.user_id.nunique()*df.item_id.nunique())\n",
    "        specs_str = str(df.user_id.nunique())+'x'+str(df.item_id.nunique())+'_'+str(round(sparsity, 2))\n",
    "        print('specs_str', specs_str)\n",
    "        return sparsity, specs_str\n",
    "    \n",
    "\n",
    "    def rename_item(row):\n",
    "        if int(row['user_id'].split('_')[1]) > sudden_drift_start and row['item_id'] in renamed_items:\n",
    "            return renamed_items[row['item_id']]\n",
    "        return row['item_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    users_list = [f'u_{i+1}' for i in range(n_users)]\n",
    "    items_list = [f'i_{j+1}' for j in range(n_items)]\n",
    "\n",
    "\n",
    "    if all_items_seen:\n",
    "\n",
    "        data = []\n",
    "        for user in users_list:\n",
    "            for item in items_list:\n",
    "                data.append({'user_id': user, 'item_id': item, 'timestamp':ts})\n",
    "\n",
    "        all_items_seen_df = pd.DataFrame(data)\n",
    "\n",
    "        # Introduce sudden drift\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}       \n",
    "        \n",
    "\n",
    "        all_items_seen_df['item_id'] = all_items_seen_df.apply(rename_item, axis=1)\n",
    "        # print(all_items_seen_df.item_id.groupby([all_items_seen_df.user_id, all_items_seen_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        \n",
    "        sparsity , specs_str = calculate_sparsity(all_items_seen_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "\n",
    "        sampled_df = add_zero_user(sampled_df)\n",
    "        users_list.insert(0, 'u_0')\n",
    "        \n",
    "\n",
    "        split_dataset_into_4_and_save_atomic_file(all_items_seen_df,users_list, bin_size, save_path, specs_str)\n",
    "        # save_dataset_atomic_file(all_items_seen_df, save_path, specs_str)\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(drift_items_freq_list) != n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "        elif len(non_drift_items_freq_list) != len(items_list)-n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "\n",
    "\n",
    "        def sample_with_repetition_of_pattern(users_list, items_list, items_freq_list):\n",
    "            random.seed(random_seed)\n",
    "            sampled_df = pd.DataFrame({})\n",
    "            for i, freq in enumerate(items_freq_list):\n",
    "                # print('k ',k)\n",
    "                user_sample = random.sample(users_list[:sudden_drift_start], k=freq) +\\\n",
    "                                random.sample(users_list[sudden_drift_start:], k=freq)\n",
    "                temp_df = pd.DataFrame({'user_id': user_sample, \n",
    "                                        'item_id': items_list[i]})\n",
    "                # print(temp_df.item_id.groupby([temp_df.user_id, temp_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "                sampled_df = pd.concat([sampled_df, temp_df])\n",
    "            \n",
    "            return sampled_df\n",
    "        \n",
    "\n",
    "        # Introduce sudden drift\n",
    "        # No need to random sample, bc the list will have the frequencies for each item\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        # drift_items_list = [items_list[i] for i,x in enumerate(items_freq_list) if x == sudden_drift_start]\n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}\n",
    "        non_drift_items_list = list(set(items_list) - set(drift_items_list))\n",
    "        \n",
    "        print('drift_items_list', drift_items_list)\n",
    "        print('renamed_items', renamed_items)\n",
    "        print('non_drift_items_list', non_drift_items_list)\n",
    "\n",
    "        \n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        sampled_df = sample_with_repetition_of_pattern(users_list,\n",
    "                                                       non_drift_items_list,\n",
    "                                                       non_drift_items_freq_list)\n",
    "        \n",
    "        sampled_df = pd.concat([sampled_df,\n",
    "                                sample_with_repetition_of_pattern(users_list,\n",
    "                                                                    drift_items_list,\n",
    "                                                                    drift_items_freq_list)])\n",
    "\n",
    "        if sampled_df.user_id.nunique() < n_users:\n",
    "            # print(sampled_df.head())\n",
    "            users_not_sampled = list(set(users_list) - set(sampled_df.user_id))\n",
    "            print('users_not_sampled', len(users_not_sampled))\n",
    "            # print('drift_items_list', drift_items_list)\n",
    "            for user in users_not_sampled:\n",
    "                for item in drift_items_list:\n",
    "                    # print(sampled_df.loc[sampled_df['user_id']==user, 'item_id'].count())\n",
    "                    sampled_df.loc[len(sampled_df)] = [user, item]\n",
    "\n",
    "\n",
    "        sampled_df['item_id'] = sampled_df.apply(rename_item, axis=1)\n",
    "        # print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        sampled_df['timestamp'] = ts\n",
    "\n",
    "\n",
    "\n",
    "        sparsity, specs_str = calculate_sparsity(sampled_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "        # print(specs_str)\n",
    "        print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "        # print(sampled_df.head())\n",
    "\n",
    "\n",
    "        # when trainning on pt1, yield ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users.\n",
    "        sampled_df = add_zero_user(sampled_df) # to solve the error \n",
    "        users_list.insert(0, 'u_0')\n",
    "\n",
    "        # save_dataset_atomic_file(sampled_df, save_path, specs_str)\n",
    "        # split_dataset_into_4_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        split_dataset_into_4_add_user0_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "        return sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corrected data splittage, with user0 added at the beginning (note that the function needs to be edited to run this one 1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_items_list ['i_1', 'i_5']\n",
      "renamed_items {'i_1': 'drifted_i_1', 'i_5': 'drifted_i_5'}\n",
      "non_drift_items_list ['i_2', 'i_3', 'i_4']\n",
      "users_not_sampled 571\n",
      "specs_str 4000x7_0.71\n",
      "sparsity:  0.7092142857142858\n",
      "item_id  drifted_i_1  drifted_i_5  i_1  i_2  i_3  i_4  i_5\n",
      "user_id                                                   \n",
      "u_1                0            0    1    0    0    0    0\n",
      "u_10               0            0    1    0    0    0    1\n",
      "u_100              0            0    0    0    0    0    1\n",
      "u_1000             0            0    1    0    1    0    0\n",
      "u_1001             0            0    1    1    1    0    1\n",
      "...              ...          ...  ...  ...  ...  ...  ...\n",
      "u_995              0            0    1    1    0    0    0\n",
      "u_996              0            0    1    1    0    1    0\n",
      "u_997              0            0    1    1    0    0    0\n",
      "u_998              0            0    1    0    0    0    1\n",
      "u_999              0            0    1    0    1    0    0\n",
      "\n",
      "[4000 rows x 7 columns]\n",
      "  user_id      item_id     timestamp\n",
      "0     u_0  drifted_i_5  1.735093e+09\n",
      "1     u_0  drifted_i_1  1.735093e+09\n",
      "2     u_1          i_1  1.735093e+09\n",
      "3     u_2          i_2  1.735093e+09\n",
      "4     u_2          i_1  1.735093e+09\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71/sudden_drift_dataset_updated_4000x7_0.71.\n",
      "item_id\n",
      "drifted_i_5    1288\n",
      "drifted_i_1    1288\n",
      "i_1            1284\n",
      "i_5            1284\n",
      "i_2            1000\n",
      "i_3            1000\n",
      "i_4            1000\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1/sudden_drift_dataset_updated_4000x7_0.71_pt1.\n",
      "item_id\n",
      "i_1            661\n",
      "i_5            644\n",
      "i_3            256\n",
      "i_4            252\n",
      "i_2            248\n",
      "drifted_i_5      1\n",
      "drifted_i_1      1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2/sudden_drift_dataset_updated_4000x7_0.71_pt2.\n",
      "item_id\n",
      "i_1            1284\n",
      "i_5            1283\n",
      "i_2             500\n",
      "i_3             500\n",
      "i_4             499\n",
      "drifted_i_5       1\n",
      "drifted_i_1       1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt3/sudden_drift_dataset_updated_4000x7_0.71_pt3.\n",
      "item_id\n",
      "i_1            1284\n",
      "i_5            1284\n",
      "i_4             752\n",
      "i_3             750\n",
      "i_2             747\n",
      "drifted_i_1     661\n",
      "drifted_i_5     651\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt5/sudden_drift_dataset_updated_4000x7_0.71_pt5.\n",
      "item_id\n",
      "i_5    639\n",
      "i_1    623\n",
      "i_2    252\n",
      "i_4    247\n",
      "i_3    244\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt6/sudden_drift_dataset_updated_4000x7_0.71_pt6.\n",
      "item_id\n",
      "drifted_i_1    660\n",
      "drifted_i_5    650\n",
      "i_4            253\n",
      "i_3            250\n",
      "i_2            247\n",
      "i_5              1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt7/sudden_drift_dataset_updated_4000x7_0.71_pt7.\n",
      "item_id\n",
      "drifted_i_5    637\n",
      "drifted_i_1    627\n",
      "i_2            253\n",
      "i_3            250\n",
      "i_4            248\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt8/sudden_drift_dataset_updated_4000x7_0.71_pt8.\n",
      "item_id\n",
      "drifted_i_1    660\n",
      "drifted_i_5    650\n",
      "i_5            640\n",
      "i_1            623\n",
      "i_4            500\n",
      "i_2            499\n",
      "i_3            494\n",
      "Name: count, dtype: int64\n",
      "Saved file at processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71/saved_dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def validate_folderpath(folderpath):\n",
    "    # print('im validating')\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "        print('Folder created: ', folderpath)\n",
    "\n",
    "\n",
    "def save_picklefile(d, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "\n",
    "    print('Saved file at '+filepath)\n",
    "\n",
    "def load_picklefile(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "    return loaded_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def generate_artificial_random_dataset(n_users,\n",
    "                                       n_items, \n",
    "                                       ts,\n",
    "                                       all_items_seen,\n",
    "                                       random_seed,\n",
    "                                       n_items_to_drift,\n",
    "                                       sudden_drift_start,\n",
    "                                       drift_items_freq_list,\n",
    "                                       non_drift_items_freq_list,\n",
    "                                       save_path,\n",
    "                                       base_filename,\n",
    "                                       bin_size):\n",
    "    \n",
    "    def add_zero_user(df):\n",
    "\n",
    "        df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "        df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "        # df.loc[-1] = ['u_-1', 'i_1', ts, 0]\n",
    "        # df.loc[-2] = ['u_-1', 'i_2', ts, 0]\n",
    "        # df.loc[-3] = ['u_-1', 'i_3', ts, 0]\n",
    "        # df.loc[-4] = ['u_-1', 'i_5', ts, 0]\n",
    "        # df.loc[-5] = ['u_0', 'i_4', ts, 0]\n",
    "        df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "        df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        df.sort_values(by='user_id_n', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "        # print('added zero user\\n', df.head())\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def create_folderpath(save_path, base_filename, specs_str):\n",
    "        return save_path+base_filename+'_'+specs_str+'/'\n",
    "    \n",
    "\n",
    "    def save_items_frequencies(n_items_to_drift,\n",
    "                               sudden_drift_start,\n",
    "                               drift_items_freq_list,\n",
    "                               non_drift_items_freq_list,\n",
    "                               save_path, \n",
    "                               base_filename,\n",
    "                               specs_str):\n",
    "        \n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "\n",
    "        d = {'n_items_to_drift': n_items_to_drift,\n",
    "             'sudden_drift_start': sudden_drift_start,\n",
    "             'drift_items_freq_list': drift_items_freq_list,\n",
    "             'non_drift_items_freq_list': non_drift_items_freq_list}\n",
    "\n",
    "        save_picklefile(d, folderpath+'saved_dictionary.pkl')\n",
    "       \n",
    "\n",
    "    \n",
    "    def save_dataset_atomic_file(df, user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "    def add_user0_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "            df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "        \n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_add_user0_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        add_user0_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_sparsity(df):\n",
    "        # df.item_id.groupby([df.user_id, df.item_id]).count().sum() == df.user_id.count()\n",
    "        sparsity = 1 - df.user_id.count()/(df.user_id.nunique()*df.item_id.nunique())\n",
    "        specs_str = str(df.user_id.nunique())+'x'+str(df.item_id.nunique())+'_'+str(round(sparsity, 2))\n",
    "        print('specs_str', specs_str)\n",
    "        return sparsity, specs_str\n",
    "    \n",
    "\n",
    "    def rename_item(row):\n",
    "        if int(row['user_id'].split('_')[1]) > sudden_drift_start and row['item_id'] in renamed_items:\n",
    "            return renamed_items[row['item_id']]\n",
    "        return row['item_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    users_list = [f'u_{i+1}' for i in range(n_users)]\n",
    "    items_list = [f'i_{j+1}' for j in range(n_items)]\n",
    "\n",
    "\n",
    "    if all_items_seen:\n",
    "\n",
    "        data = []\n",
    "        for user in users_list:\n",
    "            for item in items_list:\n",
    "                data.append({'user_id': user, 'item_id': item, 'timestamp':ts})\n",
    "\n",
    "        all_items_seen_df = pd.DataFrame(data)\n",
    "\n",
    "        # Introduce sudden drift\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}       \n",
    "        \n",
    "\n",
    "        all_items_seen_df['item_id'] = all_items_seen_df.apply(rename_item, axis=1)\n",
    "        # print(all_items_seen_df.item_id.groupby([all_items_seen_df.user_id, all_items_seen_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        \n",
    "        sparsity , specs_str = calculate_sparsity(all_items_seen_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "\n",
    "        sampled_df = add_zero_user(sampled_df)\n",
    "        users_list.insert(0, 'u_0')\n",
    "        \n",
    "\n",
    "        split_dataset_into_4_and_save_atomic_file(all_items_seen_df,users_list, bin_size, save_path, specs_str)\n",
    "        # save_dataset_atomic_file(all_items_seen_df, save_path, specs_str)\n",
    "        # split_dataset_into_4_add_user0_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(drift_items_freq_list) != n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "        elif len(non_drift_items_freq_list) != len(items_list)-n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "\n",
    "\n",
    "        def sample_with_repetition_of_pattern(users_list, items_list, items_freq_list):\n",
    "            random.seed(random_seed)\n",
    "            sampled_df = pd.DataFrame({})\n",
    "            for i, freq in enumerate(items_freq_list):\n",
    "                # print('k ',k)\n",
    "                user_sample = random.sample(users_list[:sudden_drift_start], k=freq) +\\\n",
    "                                random.sample(users_list[sudden_drift_start:], k=freq)\n",
    "                temp_df = pd.DataFrame({'user_id': user_sample, \n",
    "                                        'item_id': items_list[i]})\n",
    "                # print(temp_df.item_id.groupby([temp_df.user_id, temp_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "                sampled_df = pd.concat([sampled_df, temp_df])\n",
    "            \n",
    "            return sampled_df\n",
    "        \n",
    "\n",
    "        # Introduce sudden drift\n",
    "        # No need to random sample, bc the list will have the frequencies for each item\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        # drift_items_list = [items_list[i] for i,x in enumerate(items_freq_list) if x == sudden_drift_start]\n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}\n",
    "        non_drift_items_list = list(set(items_list) - set(drift_items_list))\n",
    "        \n",
    "        print('drift_items_list', drift_items_list)\n",
    "        print('renamed_items', renamed_items)\n",
    "        print('non_drift_items_list', non_drift_items_list)\n",
    "\n",
    "        \n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        sampled_df = sample_with_repetition_of_pattern(users_list,\n",
    "                                                       non_drift_items_list,\n",
    "                                                       non_drift_items_freq_list)\n",
    "        \n",
    "        sampled_df = pd.concat([sampled_df,\n",
    "                                sample_with_repetition_of_pattern(users_list,\n",
    "                                                                    drift_items_list,\n",
    "                                                                    drift_items_freq_list)])\n",
    "\n",
    "        if sampled_df.user_id.nunique() < n_users:\n",
    "            # print(sampled_df.head())\n",
    "            users_not_sampled = list(set(users_list) - set(sampled_df.user_id))\n",
    "            print('users_not_sampled', len(users_not_sampled))\n",
    "            # print('drift_items_list', drift_items_list)\n",
    "            for user in users_not_sampled:\n",
    "                for item in drift_items_list:\n",
    "                    # print(sampled_df.loc[sampled_df['user_id']==user, 'item_id'].count())\n",
    "                    sampled_df.loc[len(sampled_df)] = [user, item]\n",
    "\n",
    "\n",
    "        sampled_df['item_id'] = sampled_df.apply(rename_item, axis=1)\n",
    "        # print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        sampled_df['timestamp'] = ts\n",
    "\n",
    "\n",
    "\n",
    "        sparsity, specs_str = calculate_sparsity(sampled_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "        # print(specs_str)\n",
    "        print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "        # print(sampled_df.head())\n",
    "\n",
    "\n",
    "        # when trainning on pt1, yield ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users.\n",
    "        sampled_df = add_zero_user(sampled_df) # to solve the error \n",
    "        users_list.insert(0, 'u_0')\n",
    "\n",
    "        # save_dataset_atomic_file(sampled_df, save_path, specs_str)\n",
    "        split_dataset_into_4_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        # split_dataset_into_4_add_user0_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "        return sampled_df\n",
    "\n",
    "# Parameters\n",
    "n_users = 4000 # bc of random sample, some users dont have occurrencies\n",
    "n_items = 5\n",
    "sudden_drift_start = 2000  # Starting user index for drift (1-indexed)\n",
    "bin_size = 1000\n",
    "\n",
    "string = \"24/12/2024 21:12:24\"\n",
    "ts = time.mktime(datetime.strptime(string, \"%d/%m/%Y %H:%M:%S\").timetuple())\n",
    "\n",
    "all_items_seen = False\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "ratio_to_drift = 2 # Select 50% of items to rename\n",
    "n_items_to_drift = n_items // ratio_to_drift\n",
    "\n",
    "base_filename = 'sudden_drift_dataset_updated'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "drift_items_freq_list = [sudden_drift_start//2, sudden_drift_start//2]\n",
    "non_drift_items_freq_list = [sudden_drift_start//4, sudden_drift_start//4, sudden_drift_start//4]\n",
    "\n",
    "df = generate_artificial_random_dataset(n_users=n_users,\n",
    "                                    n_items=n_items, \n",
    "                                    ts=ts,\n",
    "                                    all_items_seen=all_items_seen,\n",
    "                                    n_items_to_drift=n_items_to_drift,\n",
    "                                    random_seed=random_seed,\n",
    "                                    sudden_drift_start=sudden_drift_start,\n",
    "                                    drift_items_freq_list=drift_items_freq_list,\n",
    "                                    non_drift_items_freq_list=non_drift_items_freq_list,\n",
    "                                    save_path=save_path,\n",
    "                                    base_filename=base_filename,\n",
    "                                    bin_size=bin_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corrected data splittage, with user0 added in all parts (note that the function needs to be edited to run this one 1st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_items_list ['i_1', 'i_5']\n",
      "renamed_items {'i_1': 'drifted_i_1', 'i_5': 'drifted_i_5'}\n",
      "non_drift_items_list ['i_2', 'i_3', 'i_4']\n",
      "users_not_sampled 571\n",
      "specs_str 4000x7_0.71\n",
      "sparsity:  0.7092142857142858\n",
      "item_id  drifted_i_1  drifted_i_5  i_1  i_2  i_3  i_4  i_5\n",
      "user_id                                                   \n",
      "u_1                0            0    1    0    0    0    0\n",
      "u_10               0            0    1    0    0    0    1\n",
      "u_100              0            0    0    0    0    0    1\n",
      "u_1000             0            0    1    0    1    0    0\n",
      "u_1001             0            0    1    1    1    0    1\n",
      "...              ...          ...  ...  ...  ...  ...  ...\n",
      "u_995              0            0    1    1    0    0    0\n",
      "u_996              0            0    1    1    0    1    0\n",
      "u_997              0            0    1    1    0    0    0\n",
      "u_998              0            0    1    0    0    0    1\n",
      "u_999              0            0    1    0    1    0    0\n",
      "\n",
      "[4000 rows x 7 columns]\n",
      "  user_id      item_id     timestamp\n",
      "0     u_0  drifted_i_5  1.735093e+09\n",
      "1     u_0  drifted_i_1  1.735093e+09\n",
      "2     u_1          i_1  1.735093e+09\n",
      "3     u_2          i_2  1.735093e+09\n",
      "4     u_2          i_1  1.735093e+09\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71/sudden_drift_dataset_u0_all_parts_4000x7_0.71.\n",
      "item_id\n",
      "drifted_i_5    1289\n",
      "drifted_i_1    1289\n",
      "i_1            1284\n",
      "i_5            1284\n",
      "i_2            1000\n",
      "i_3            1000\n",
      "i_4            1000\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1.\n",
      "item_id\n",
      "i_1            661\n",
      "i_5            644\n",
      "i_3            256\n",
      "i_4            252\n",
      "i_2            248\n",
      "drifted_i_5      2\n",
      "drifted_i_1      2\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt2/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt2.\n",
      "item_id\n",
      "i_1            1284\n",
      "i_5            1283\n",
      "i_2             500\n",
      "i_3             500\n",
      "i_4             499\n",
      "drifted_i_5       2\n",
      "drifted_i_1       2\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt3/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt3.\n",
      "item_id\n",
      "i_1            1284\n",
      "i_5            1284\n",
      "i_4             752\n",
      "i_3             750\n",
      "i_2             747\n",
      "drifted_i_1     662\n",
      "drifted_i_5     652\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt5/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt5.\n",
      "item_id\n",
      "i_5            639\n",
      "i_1            623\n",
      "i_2            252\n",
      "i_4            247\n",
      "i_3            244\n",
      "drifted_i_5      1\n",
      "drifted_i_1      1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt6/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt6.\n",
      "item_id\n",
      "drifted_i_1    661\n",
      "drifted_i_5    651\n",
      "i_4            253\n",
      "i_3            250\n",
      "i_2            247\n",
      "i_5              1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt7/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt7.\n",
      "item_id\n",
      "drifted_i_5    638\n",
      "drifted_i_1    628\n",
      "i_2            253\n",
      "i_3            250\n",
      "i_4            248\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt8/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt8.\n",
      "item_id\n",
      "drifted_i_1    661\n",
      "drifted_i_5    651\n",
      "i_5            640\n",
      "i_1            623\n",
      "i_4            500\n",
      "i_2            499\n",
      "i_3            494\n",
      "Name: count, dtype: int64\n",
      "Saved file at processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71/saved_dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def validate_folderpath(folderpath):\n",
    "    # print('im validating')\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "        print('Folder created: ', folderpath)\n",
    "\n",
    "\n",
    "def save_picklefile(d, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "\n",
    "    print('Saved file at '+filepath)\n",
    "\n",
    "def load_picklefile(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "    return loaded_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def generate_artificial_random_dataset(n_users,\n",
    "                                       n_items, \n",
    "                                       ts,\n",
    "                                       all_items_seen,\n",
    "                                       random_seed,\n",
    "                                       n_items_to_drift,\n",
    "                                       sudden_drift_start,\n",
    "                                       drift_items_freq_list,\n",
    "                                       non_drift_items_freq_list,\n",
    "                                       save_path,\n",
    "                                       base_filename,\n",
    "                                       bin_size):\n",
    "    \n",
    "    def add_zero_user(df):\n",
    "\n",
    "        df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "        df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "        # df.loc[-1] = ['u_-1', 'i_1', ts, 0]\n",
    "        # df.loc[-2] = ['u_-1', 'i_2', ts, 0]\n",
    "        # df.loc[-3] = ['u_-1', 'i_3', ts, 0]\n",
    "        # df.loc[-4] = ['u_-1', 'i_5', ts, 0]\n",
    "        # df.loc[-5] = ['u_0', 'i_4', ts, 0]\n",
    "        df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "        df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        df.sort_values(by='user_id_n', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "        # print('added zero user\\n', df.head())\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def create_folderpath(save_path, base_filename, specs_str):\n",
    "        return save_path+base_filename+'_'+specs_str+'/'\n",
    "    \n",
    "\n",
    "    def save_items_frequencies(n_items_to_drift,\n",
    "                               sudden_drift_start,\n",
    "                               drift_items_freq_list,\n",
    "                               non_drift_items_freq_list,\n",
    "                               save_path, \n",
    "                               base_filename,\n",
    "                               specs_str):\n",
    "        \n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "\n",
    "        d = {'n_items_to_drift': n_items_to_drift,\n",
    "             'sudden_drift_start': sudden_drift_start,\n",
    "             'drift_items_freq_list': drift_items_freq_list,\n",
    "             'non_drift_items_freq_list': non_drift_items_freq_list}\n",
    "\n",
    "        save_picklefile(d, folderpath+'saved_dictionary.pkl')\n",
    "       \n",
    "\n",
    "    \n",
    "    def save_dataset_atomic_file(df, user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "    def add_user0_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "            df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "        \n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_add_user0_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        add_user0_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_sparsity(df):\n",
    "        # df.item_id.groupby([df.user_id, df.item_id]).count().sum() == df.user_id.count()\n",
    "        sparsity = 1 - df.user_id.count()/(df.user_id.nunique()*df.item_id.nunique())\n",
    "        specs_str = str(df.user_id.nunique())+'x'+str(df.item_id.nunique())+'_'+str(round(sparsity, 2))\n",
    "        print('specs_str', specs_str)\n",
    "        return sparsity, specs_str\n",
    "    \n",
    "\n",
    "    def rename_item(row):\n",
    "        if int(row['user_id'].split('_')[1]) > sudden_drift_start and row['item_id'] in renamed_items:\n",
    "            return renamed_items[row['item_id']]\n",
    "        return row['item_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    users_list = [f'u_{i+1}' for i in range(n_users)]\n",
    "    items_list = [f'i_{j+1}' for j in range(n_items)]\n",
    "\n",
    "\n",
    "    if all_items_seen:\n",
    "\n",
    "        data = []\n",
    "        for user in users_list:\n",
    "            for item in items_list:\n",
    "                data.append({'user_id': user, 'item_id': item, 'timestamp':ts})\n",
    "\n",
    "        all_items_seen_df = pd.DataFrame(data)\n",
    "\n",
    "        # Introduce sudden drift\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}       \n",
    "        \n",
    "\n",
    "        all_items_seen_df['item_id'] = all_items_seen_df.apply(rename_item, axis=1)\n",
    "        # print(all_items_seen_df.item_id.groupby([all_items_seen_df.user_id, all_items_seen_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        \n",
    "        sparsity , specs_str = calculate_sparsity(all_items_seen_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "\n",
    "        sampled_df = add_zero_user(sampled_df)\n",
    "        users_list.insert(0, 'u_0')\n",
    "        \n",
    "\n",
    "        split_dataset_into_4_and_save_atomic_file(all_items_seen_df,users_list, bin_size, save_path, specs_str)\n",
    "        # save_dataset_atomic_file(all_items_seen_df, save_path, specs_str)\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(drift_items_freq_list) != n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "        elif len(non_drift_items_freq_list) != len(items_list)-n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "\n",
    "\n",
    "        def sample_with_repetition_of_pattern(users_list, items_list, items_freq_list):\n",
    "            random.seed(random_seed)\n",
    "            sampled_df = pd.DataFrame({})\n",
    "            for i, freq in enumerate(items_freq_list):\n",
    "                # print('k ',k)\n",
    "                user_sample = random.sample(users_list[:sudden_drift_start], k=freq) +\\\n",
    "                                random.sample(users_list[sudden_drift_start:], k=freq)\n",
    "                temp_df = pd.DataFrame({'user_id': user_sample, \n",
    "                                        'item_id': items_list[i]})\n",
    "                # print(temp_df.item_id.groupby([temp_df.user_id, temp_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "                sampled_df = pd.concat([sampled_df, temp_df])\n",
    "            \n",
    "            return sampled_df\n",
    "        \n",
    "\n",
    "        # Introduce sudden drift\n",
    "        # No need to random sample, bc the list will have the frequencies for each item\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        # drift_items_list = [items_list[i] for i,x in enumerate(items_freq_list) if x == sudden_drift_start]\n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}\n",
    "        non_drift_items_list = list(set(items_list) - set(drift_items_list))\n",
    "        \n",
    "        print('drift_items_list', drift_items_list)\n",
    "        print('renamed_items', renamed_items)\n",
    "        print('non_drift_items_list', non_drift_items_list)\n",
    "\n",
    "        \n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        sampled_df = sample_with_repetition_of_pattern(users_list,\n",
    "                                                       non_drift_items_list,\n",
    "                                                       non_drift_items_freq_list)\n",
    "        \n",
    "        sampled_df = pd.concat([sampled_df,\n",
    "                                sample_with_repetition_of_pattern(users_list,\n",
    "                                                                    drift_items_list,\n",
    "                                                                    drift_items_freq_list)])\n",
    "\n",
    "        if sampled_df.user_id.nunique() < n_users:\n",
    "            # print(sampled_df.head())\n",
    "            users_not_sampled = list(set(users_list) - set(sampled_df.user_id))\n",
    "            print('users_not_sampled', len(users_not_sampled))\n",
    "            # print('drift_items_list', drift_items_list)\n",
    "            for user in users_not_sampled:\n",
    "                for item in drift_items_list:\n",
    "                    # print(sampled_df.loc[sampled_df['user_id']==user, 'item_id'].count())\n",
    "                    sampled_df.loc[len(sampled_df)] = [user, item]\n",
    "\n",
    "\n",
    "        sampled_df['item_id'] = sampled_df.apply(rename_item, axis=1)\n",
    "        # print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        sampled_df['timestamp'] = ts\n",
    "\n",
    "\n",
    "\n",
    "        sparsity, specs_str = calculate_sparsity(sampled_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "        # print(specs_str)\n",
    "        print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "        # print(sampled_df.head())\n",
    "\n",
    "\n",
    "        # when trainning on pt1, yield ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users.\n",
    "        sampled_df = add_zero_user(sampled_df) # to solve the error \n",
    "        users_list.insert(0, 'u_0')\n",
    "\n",
    "        # save_dataset_atomic_file(sampled_df, save_path, specs_str)\n",
    "        # split_dataset_into_4_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        split_dataset_into_4_add_user0_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "        return sampled_df\n",
    "\n",
    "# Parameters\n",
    "n_users = 4000 # bc of random sample, some users dont have occurrencies\n",
    "n_items = 5\n",
    "sudden_drift_start = 2000  # Starting user index for drift (1-indexed)\n",
    "bin_size = 1000\n",
    "\n",
    "string = \"24/12/2024 21:12:24\"\n",
    "ts = time.mktime(datetime.strptime(string, \"%d/%m/%Y %H:%M:%S\").timetuple())\n",
    "\n",
    "all_items_seen = False\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "ratio_to_drift = 2 # Select 50% of items to rename\n",
    "n_items_to_drift = n_items // ratio_to_drift\n",
    "\n",
    "base_filename = 'sudden_drift_dataset_u0_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "drift_items_freq_list = [sudden_drift_start//2, sudden_drift_start//2]\n",
    "non_drift_items_freq_list = [sudden_drift_start//4, sudden_drift_start//4, sudden_drift_start//4]\n",
    "\n",
    "df = generate_artificial_random_dataset(n_users=n_users,\n",
    "                                    n_items=n_items, \n",
    "                                    ts=ts,\n",
    "                                    all_items_seen=all_items_seen,\n",
    "                                    n_items_to_drift=n_items_to_drift,\n",
    "                                    random_seed=random_seed,\n",
    "                                    sudden_drift_start=sudden_drift_start,\n",
    "                                    drift_items_freq_list=drift_items_freq_list,\n",
    "                                    non_drift_items_freq_list=non_drift_items_freq_list,\n",
    "                                    save_path=save_path,\n",
    "                                    base_filename=base_filename,\n",
    "                                    bin_size=bin_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-do trigger error now with updated sampliing of df (properly separated items drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 3\n",
    "# VALID_METRIC = 'Recall@'+str(K)\n",
    "# MODEL = 'BPR'\n",
    "# SEED = 2020\n",
    "# USE_GPU = False\n",
    "# SHUFFLE = False \n",
    "# SHOW_PROGRESS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "\n",
    "\n",
    "def train_test(model_name,\n",
    "               dataset_name,\n",
    "               parameter_dict):\n",
    "\n",
    "    # configurations initialization\n",
    "    config = Config(model=model_name, dataset=dataset_name, config_dict=parameter_dict)\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = BPR(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = Trainer(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "    print('\\n\\nTraining best results')\n",
    "    print('best_valid_score: ', best_valid_score)\n",
    "    print('best_valid_result: ', best_valid_result)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    \n",
    "    print('\\n\\nTest results')\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated splittage version (user0 only in 1st part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test Updated splittage version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = 'sudden_drift_dataset_updated'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "\n",
    "# Current model\n",
    "base_dataset_name = base_filename+'_4000x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09 Jan 11:28    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\n",
      "show_progress ="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "09 Jan 11:28    INFO  sudden_drift_dataset_updated_4000x7_0.71_pt1\n",
      "The number of users: 1001\n",
      "Average actions of users: 2.063\n",
      "The number of items: 8\n",
      "Average actions of items: 294.7142857142857\n",
      "The number of inters: 2063\n",
      "The sparsity of the dataset: 74.23826173826174%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "09 Jan 11:28    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "09 Jan 11:28    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "09 Jan 11:28    INFO  BPR(\n",
      "  (user_embedding): Embedding(1001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 64576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "09 Jan 11:28    INFO  epoch 0 training [time: 0.13s, train loss: 0.6946]\n",
      "09 Jan 11:28    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.503700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5037    mrr@3 : 0.3191    ndcg@3 : 0.3663    hit@3 : 0.5037    precision@3 : 0.1679\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 1 training [time: 0.01s, train loss: 0.6920]\n",
      "09 Jan 11:28    INFO  epoch 1 evaluating [time: 0.02s, valid_score: 0.500000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5    mrr@3 : 0.3185    ndcg@3 : 0.3649    hit@3 : 0.5    precision@3 : 0.1667\n",
      "09 Jan 11:28    INFO  epoch 2 training [time: 0.04s, train loss: 0.6862]\n",
      "09 Jan 11:28    INFO  epoch 2 evaluating [time: 0.02s, valid_score: 0.496300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4963    mrr@3 : 0.316    ndcg@3 : 0.3622    hit@3 : 0.4963    precision@3 : 0.1654\n",
      "09 Jan 11:28    INFO  epoch 3 training [time: 0.01s, train loss: 0.6839]\n",
      "09 Jan 11:28    INFO  epoch 3 evaluating [time: 0.02s, valid_score: 0.500000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5    mrr@3 : 0.3222    ndcg@3 : 0.3676    hit@3 : 0.5    precision@3 : 0.1667\n",
      "09 Jan 11:28    INFO  epoch 4 training [time: 0.02s, train loss: 0.6779]\n",
      "09 Jan 11:28    INFO  epoch 4 evaluating [time: 0.02s, valid_score: 0.496300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4963    mrr@3 : 0.3228    ndcg@3 : 0.3671    hit@3 : 0.4963    precision@3 : 0.1654\n",
      "09 Jan 11:28    INFO  epoch 5 training [time: 0.01s, train loss: 0.6736]\n",
      "09 Jan 11:28    INFO  epoch 5 evaluating [time: 0.02s, valid_score: 0.496300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4963    mrr@3 : 0.3228    ndcg@3 : 0.3671    hit@3 : 0.4963    precision@3 : 0.1654\n",
      "09 Jan 11:28    INFO  epoch 6 training [time: 0.06s, train loss: 0.6699]\n",
      "09 Jan 11:28    INFO  epoch 6 evaluating [time: 0.02s, valid_score: 0.503700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5037    mrr@3 : 0.3235    ndcg@3 : 0.3695    hit@3 : 0.5037    precision@3 : 0.1679\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 7 training [time: 0.01s, train loss: 0.6663]\n",
      "09 Jan 11:28    INFO  epoch 7 evaluating [time: 0.02s, valid_score: 0.514800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5148    mrr@3 : 0.3247    ndcg@3 : 0.3732    hit@3 : 0.5148    precision@3 : 0.1716\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 8 training [time: 0.01s, train loss: 0.6645]\n",
      "09 Jan 11:28    INFO  epoch 8 evaluating [time: 0.02s, valid_score: 0.514800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5148    mrr@3 : 0.321    ndcg@3 : 0.3705    hit@3 : 0.5148    precision@3 : 0.1716\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 9 training [time: 0.01s, train loss: 0.6594]\n",
      "09 Jan 11:28    INFO  epoch 9 evaluating [time: 0.03s, valid_score: 0.511100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5111    mrr@3 : 0.3204    ndcg@3 : 0.369    hit@3 : 0.5111    precision@3 : 0.1704\n",
      "09 Jan 11:28    INFO  epoch 10 training [time: 0.02s, train loss: 0.6570]\n",
      "09 Jan 11:28    INFO  epoch 10 evaluating [time: 0.04s, valid_score: 0.511100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5111    mrr@3 : 0.3198    ndcg@3 : 0.3685    hit@3 : 0.5111    precision@3 : 0.1704\n",
      "09 Jan 11:28    INFO  epoch 11 training [time: 0.08s, train loss: 0.6513]\n",
      "09 Jan 11:28    INFO  epoch 11 evaluating [time: 0.03s, valid_score: 0.518500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5185    mrr@3 : 0.3228    ndcg@3 : 0.3727    hit@3 : 0.5185    precision@3 : 0.1728\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 12 training [time: 0.01s, train loss: 0.6473]\n",
      "09 Jan 11:28    INFO  epoch 12 evaluating [time: 0.03s, valid_score: 0.522200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5222    mrr@3 : 0.3241    ndcg@3 : 0.3746    hit@3 : 0.5222    precision@3 : 0.1741\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 13 training [time: 0.01s, train loss: 0.6440]\n",
      "09 Jan 11:28    INFO  epoch 13 evaluating [time: 0.03s, valid_score: 0.525900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5259    mrr@3 : 0.3253    ndcg@3 : 0.3764    hit@3 : 0.5259    precision@3 : 0.1753\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 14 training [time: 0.02s, train loss: 0.6400]\n",
      "09 Jan 11:28    INFO  epoch 14 evaluating [time: 0.03s, valid_score: 0.522200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5222    mrr@3 : 0.3241    ndcg@3 : 0.3746    hit@3 : 0.5222    precision@3 : 0.1741\n",
      "09 Jan 11:28    INFO  epoch 15 training [time: 0.02s, train loss: 0.6352]\n",
      "09 Jan 11:28    INFO  epoch 15 evaluating [time: 0.03s, valid_score: 0.529600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5296    mrr@3 : 0.3259    ndcg@3 : 0.3778    hit@3 : 0.5296    precision@3 : 0.1765\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 16 training [time: 0.11s, train loss: 0.6306]\n",
      "09 Jan 11:28    INFO  epoch 16 evaluating [time: 0.02s, valid_score: 0.533300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3272    ndcg@3 : 0.3796    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 17 training [time: 0.02s, train loss: 0.6261]\n",
      "09 Jan 11:28    INFO  epoch 17 evaluating [time: 0.03s, valid_score: 0.533300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3284    ndcg@3 : 0.3805    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 18 training [time: 0.02s, train loss: 0.6220]\n",
      "09 Jan 11:28    INFO  epoch 18 evaluating [time: 0.03s, valid_score: 0.525900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5259    mrr@3 : 0.329    ndcg@3 : 0.3791    hit@3 : 0.5259    precision@3 : 0.1753\n",
      "09 Jan 11:28    INFO  epoch 19 training [time: 0.02s, train loss: 0.6192]\n",
      "09 Jan 11:28    INFO  epoch 19 evaluating [time: 0.03s, valid_score: 0.525900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5259    mrr@3 : 0.3259    ndcg@3 : 0.3769    hit@3 : 0.5259    precision@3 : 0.1753\n",
      "09 Jan 11:28    INFO  epoch 20 training [time: 0.01s, train loss: 0.6152]\n",
      "09 Jan 11:28    INFO  epoch 20 evaluating [time: 0.03s, valid_score: 0.518500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5185    mrr@3 : 0.3241    ndcg@3 : 0.3737    hit@3 : 0.5185    precision@3 : 0.1728\n",
      "09 Jan 11:28    INFO  epoch 21 training [time: 0.11s, train loss: 0.6108]\n",
      "09 Jan 11:28    INFO  epoch 21 evaluating [time: 0.02s, valid_score: 0.522200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5222    mrr@3 : 0.3259    ndcg@3 : 0.376    hit@3 : 0.5222    precision@3 : 0.1741\n",
      "09 Jan 11:28    INFO  epoch 22 training [time: 0.02s, train loss: 0.6066]\n",
      "09 Jan 11:28    INFO  epoch 22 evaluating [time: 0.03s, valid_score: 0.525900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5259    mrr@3 : 0.3321    ndcg@3 : 0.3815    hit@3 : 0.5259    precision@3 : 0.1753\n",
      "09 Jan 11:28    INFO  epoch 23 training [time: 0.02s, train loss: 0.6012]\n",
      "09 Jan 11:28    INFO  epoch 23 evaluating [time: 0.03s, valid_score: 0.525900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5259    mrr@3 : 0.3321    ndcg@3 : 0.3815    hit@3 : 0.5259    precision@3 : 0.1753\n",
      "09 Jan 11:28    INFO  epoch 24 training [time: 0.05s, train loss: 0.5976]\n",
      "09 Jan 11:28    INFO  epoch 24 evaluating [time: 0.03s, valid_score: 0.525900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5259    mrr@3 : 0.3321    ndcg@3 : 0.3815    hit@3 : 0.5259    precision@3 : 0.1753\n",
      "09 Jan 11:28    INFO  epoch 25 training [time: 0.02s, train loss: 0.5943]\n",
      "09 Jan 11:28    INFO  epoch 25 evaluating [time: 0.03s, valid_score: 0.525900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5259    mrr@3 : 0.3346    ndcg@3 : 0.3833    hit@3 : 0.5259    precision@3 : 0.1753\n",
      "09 Jan 11:28    INFO  epoch 26 training [time: 0.08s, train loss: 0.5884]\n",
      "09 Jan 11:28    INFO  epoch 26 evaluating [time: 0.03s, valid_score: 0.529600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5296    mrr@3 : 0.3346    ndcg@3 : 0.3842    hit@3 : 0.5296    precision@3 : 0.1765\n",
      "09 Jan 11:28    INFO  epoch 27 training [time: 0.02s, train loss: 0.5847]\n",
      "09 Jan 11:28    INFO  epoch 27 evaluating [time: 0.02s, valid_score: 0.533300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3321    ndcg@3 : 0.3833    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 28 training [time: 0.01s, train loss: 0.5796]\n",
      "09 Jan 11:28    INFO  epoch 28 evaluating [time: 0.03s, valid_score: 0.537000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.537    mrr@3 : 0.3333    ndcg@3 : 0.3852    hit@3 : 0.537    precision@3 : 0.179\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 29 training [time: 0.01s, train loss: 0.5762]\n",
      "09 Jan 11:28    INFO  epoch 29 evaluating [time: 0.03s, valid_score: 0.537000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.537    mrr@3 : 0.3327    ndcg@3 : 0.3847    hit@3 : 0.537    precision@3 : 0.179\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 30 training [time: 0.11s, train loss: 0.5695]\n",
      "09 Jan 11:28    INFO  epoch 30 evaluating [time: 0.04s, valid_score: 0.529600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5296    mrr@3 : 0.3333    ndcg@3 : 0.3833    hit@3 : 0.5296    precision@3 : 0.1765\n",
      "09 Jan 11:28    INFO  epoch 31 training [time: 0.02s, train loss: 0.5654]\n",
      "09 Jan 11:28    INFO  epoch 31 evaluating [time: 0.03s, valid_score: 0.533300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3346    ndcg@3 : 0.3852    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "09 Jan 11:28    INFO  epoch 32 training [time: 0.01s, train loss: 0.5593]\n",
      "09 Jan 11:28    INFO  epoch 32 evaluating [time: 0.03s, valid_score: 0.540700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5407    mrr@3 : 0.3389    ndcg@3 : 0.3903    hit@3 : 0.5407    precision@3 : 0.1802\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 33 training [time: 0.02s, train loss: 0.5557]\n",
      "09 Jan 11:28    INFO  epoch 33 evaluating [time: 0.02s, valid_score: 0.544400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5444    mrr@3 : 0.3426    ndcg@3 : 0.394    hit@3 : 0.5444    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 34 training [time: 0.11s, train loss: 0.5529]\n",
      "09 Jan 11:28    INFO  epoch 34 evaluating [time: 0.04s, valid_score: 0.548100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5481    mrr@3 : 0.3463    ndcg@3 : 0.3977    hit@3 : 0.5481    precision@3 : 0.1827\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 35 training [time: 0.01s, train loss: 0.5469]\n",
      "09 Jan 11:28    INFO  epoch 35 evaluating [time: 0.03s, valid_score: 0.548100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5481    mrr@3 : 0.3438    ndcg@3 : 0.3958    hit@3 : 0.5481    precision@3 : 0.1827\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 36 training [time: 0.02s, train loss: 0.5427]\n",
      "09 Jan 11:28    INFO  epoch 36 evaluating [time: 0.03s, valid_score: 0.551900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5519    mrr@3 : 0.3463    ndcg@3 : 0.3985    hit@3 : 0.5519    precision@3 : 0.184\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 37 training [time: 0.02s, train loss: 0.5377]\n",
      "09 Jan 11:28    INFO  epoch 37 evaluating [time: 0.06s, valid_score: 0.551900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5519    mrr@3 : 0.3438    ndcg@3 : 0.3967    hit@3 : 0.5519    precision@3 : 0.184\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 38 training [time: 0.03s, train loss: 0.5360]\n",
      "09 Jan 11:28    INFO  epoch 38 evaluating [time: 0.04s, valid_score: 0.555600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5556    mrr@3 : 0.3494    ndcg@3 : 0.4018    hit@3 : 0.5556    precision@3 : 0.1852\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n",
      "09 Jan 11:28    INFO  epoch 39 training [time: 0.01s, train loss: 0.5282]\n",
      "09 Jan 11:28    INFO  epoch 39 evaluating [time: 0.03s, valid_score: 0.551900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5519    mrr@3 : 0.3488    ndcg@3 : 0.4005    hit@3 : 0.5519    precision@3 : 0.184\n",
      "09 Jan 11:28    INFO  epoch 40 training [time: 0.02s, train loss: 0.5236]\n",
      "09 Jan 11:28    INFO  epoch 40 evaluating [time: 0.02s, valid_score: 0.551900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5519    mrr@3 : 0.3488    ndcg@3 : 0.4005    hit@3 : 0.5519    precision@3 : 0.184\n",
      "09 Jan 11:28    INFO  epoch 41 training [time: 0.01s, train loss: 0.5199]\n",
      "09 Jan 11:28    INFO  epoch 41 evaluating [time: 0.02s, valid_score: 0.551900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5519    mrr@3 : 0.3506    ndcg@3 : 0.4018    hit@3 : 0.5519    precision@3 : 0.184\n",
      "09 Jan 11:28    INFO  epoch 42 training [time: 0.07s, train loss: 0.5145]\n",
      "09 Jan 11:28    INFO  epoch 42 evaluating [time: 0.02s, valid_score: 0.548100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5481    mrr@3 : 0.3512    ndcg@3 : 0.4014    hit@3 : 0.5481    precision@3 : 0.1827\n",
      "09 Jan 11:28    INFO  epoch 43 training [time: 0.01s, train loss: 0.5106]\n",
      "09 Jan 11:28    INFO  epoch 43 evaluating [time: 0.03s, valid_score: 0.544400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5444    mrr@3 : 0.3512    ndcg@3 : 0.4005    hit@3 : 0.5444    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  epoch 44 training [time: 0.01s, train loss: 0.5043]\n",
      "09 Jan 11:28    INFO  epoch 44 evaluating [time: 0.02s, valid_score: 0.544400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5444    mrr@3 : 0.3488    ndcg@3 : 0.3986    hit@3 : 0.5444    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  epoch 45 training [time: 0.01s, train loss: 0.4973]\n",
      "09 Jan 11:28    INFO  epoch 45 evaluating [time: 0.02s, valid_score: 0.544400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5444    mrr@3 : 0.35    ndcg@3 : 0.3996    hit@3 : 0.5444    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  epoch 46 training [time: 0.01s, train loss: 0.4930]\n",
      "09 Jan 11:28    INFO  epoch 46 evaluating [time: 0.02s, valid_score: 0.544400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5444    mrr@3 : 0.3519    ndcg@3 : 0.4011    hit@3 : 0.5444    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  epoch 47 training [time: 0.01s, train loss: 0.4887]\n",
      "09 Jan 11:28    INFO  epoch 47 evaluating [time: 0.02s, valid_score: 0.544400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5444    mrr@3 : 0.3488    ndcg@3 : 0.3987    hit@3 : 0.5444    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  epoch 48 training [time: 0.04s, train loss: 0.4858]\n",
      "09 Jan 11:28    INFO  epoch 48 evaluating [time: 0.05s, valid_score: 0.544400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5444    mrr@3 : 0.3469    ndcg@3 : 0.3974    hit@3 : 0.5444    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  epoch 49 training [time: 0.04s, train loss: 0.4802]\n",
      "09 Jan 11:28    INFO  epoch 49 evaluating [time: 0.03s, valid_score: 0.544400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5444    mrr@3 : 0.3481    ndcg@3 : 0.3983    hit@3 : 0.5444    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  Finished training, best eval result in epoch 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5556\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5556), ('mrr@3', 0.3494), ('ndcg@3', 0.4018), ('hit@3', 0.5556), ('precision@3', 0.1852)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "09 Jan 11:28    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt1\\BPR-Jan-09-2025_11-28-25.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.6332), ('mrr@3', 0.4412), ('ndcg@3', 0.4903), ('hit@3', 0.6332), ('precision@3', 0.2111)])\n"
     ]
    }
   ],
   "source": [
    "dataset_name=base_dataset_name+'_pt1'\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':data_path+dataset_name,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "\n",
    "train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09 Jan 11:28    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "09 Jan 11:28    INFO  sudden_drift_dataset_updated_4000x7_0.71_pt2\n",
      "The number of users: 2001\n",
      "Average actions of users: 2.034\n",
      "The number of items: 8\n",
      "Average actions of items: 581.1428571428571\n",
      "The number of inters: 4068\n",
      "The sparsity of the dataset: 74.58770614692654%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "09 Jan 11:28    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "09 Jan 11:28    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "09 Jan 11:28    INFO  BPR(\n",
      "  (user_embedding): Embedding(2001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 128576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "09 Jan 11:28    INFO  epoch 0 training [time: 0.03s, train loss: 1.3863]\n",
      "09 Jan 11:28    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.519500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5195    mrr@3 : 0.3123    ndcg@3 : 0.3651    hit@3 : 0.5195    precision@3 : 0.1732\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\\BPR-Jan-09-2025_11-28-37.pth\n",
      "09 Jan 11:28    INFO  epoch 1 training [time: 0.02s, train loss: 1.3765]\n",
      "09 Jan 11:28    INFO  epoch 1 evaluating [time: 0.04s, valid_score: 0.511700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5117    mrr@3 : 0.3051    ndcg@3 : 0.3578    hit@3 : 0.5117    precision@3 : 0.1706\n",
      "09 Jan 11:28    INFO  epoch 2 training [time: 0.02s, train loss: 1.3671]\n",
      "09 Jan 11:28    INFO  epoch 2 evaluating [time: 0.04s, valid_score: 0.505800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5058    mrr@3 : 0.3038    ndcg@3 : 0.3554    hit@3 : 0.5058    precision@3 : 0.1686\n",
      "09 Jan 11:28    INFO  epoch 3 training [time: 0.01s, train loss: 1.3612]\n",
      "09 Jan 11:28    INFO  epoch 3 evaluating [time: 0.03s, valid_score: 0.505800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5058    mrr@3 : 0.3051    ndcg@3 : 0.3562    hit@3 : 0.5058    precision@3 : 0.1686\n",
      "09 Jan 11:28    INFO  epoch 4 training [time: 0.02s, train loss: 1.3537]\n",
      "09 Jan 11:28    INFO  epoch 4 evaluating [time: 0.03s, valid_score: 0.517500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5175    mrr@3 : 0.3093    ndcg@3 : 0.3624    hit@3 : 0.5175    precision@3 : 0.1725\n",
      "09 Jan 11:28    INFO  epoch 5 training [time: 0.02s, train loss: 1.3389]\n",
      "09 Jan 11:28    INFO  epoch 5 evaluating [time: 0.07s, valid_score: 0.517500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5175    mrr@3 : 0.3113    ndcg@3 : 0.3638    hit@3 : 0.5175    precision@3 : 0.1725\n",
      "09 Jan 11:28    INFO  epoch 6 training [time: 0.05s, train loss: 1.3301]\n",
      "09 Jan 11:28    INFO  epoch 6 evaluating [time: 0.04s, valid_score: 0.505800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5058    mrr@3 : 0.3048    ndcg@3 : 0.3561    hit@3 : 0.5058    precision@3 : 0.1686\n",
      "09 Jan 11:28    INFO  epoch 7 training [time: 0.02s, train loss: 1.3227]\n",
      "09 Jan 11:28    INFO  epoch 7 evaluating [time: 0.04s, valid_score: 0.517500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5175    mrr@3 : 0.3071    ndcg@3 : 0.3607    hit@3 : 0.5175    precision@3 : 0.1725\n",
      "09 Jan 11:28    INFO  epoch 8 training [time: 0.02s, train loss: 1.3082]\n",
      "09 Jan 11:28    INFO  epoch 8 evaluating [time: 0.03s, valid_score: 0.519500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5195    mrr@3 : 0.3087    ndcg@3 : 0.3624    hit@3 : 0.5195    precision@3 : 0.1732\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\\BPR-Jan-09-2025_11-28-37.pth\n",
      "09 Jan 11:28    INFO  epoch 9 training [time: 0.02s, train loss: 1.3000]\n",
      "09 Jan 11:28    INFO  epoch 9 evaluating [time: 0.03s, valid_score: 0.519500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5195    mrr@3 : 0.3097    ndcg@3 : 0.3631    hit@3 : 0.5195    precision@3 : 0.1732\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\\BPR-Jan-09-2025_11-28-37.pth\n",
      "09 Jan 11:28    INFO  epoch 10 training [time: 0.02s, train loss: 1.2929]\n",
      "09 Jan 11:28    INFO  epoch 10 evaluating [time: 0.05s, valid_score: 0.521400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5214    mrr@3 : 0.3084    ndcg@3 : 0.3626    hit@3 : 0.5214    precision@3 : 0.1738\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\\BPR-Jan-09-2025_11-28-37.pth\n",
      "09 Jan 11:28    INFO  epoch 11 training [time: 0.03s, train loss: 1.2826]\n",
      "09 Jan 11:28    INFO  epoch 11 evaluating [time: 0.06s, valid_score: 0.521400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5214    mrr@3 : 0.31    ndcg@3 : 0.3638    hit@3 : 0.5214    precision@3 : 0.1738\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\\BPR-Jan-09-2025_11-28-37.pth\n",
      "09 Jan 11:28    INFO  epoch 12 training [time: 0.03s, train loss: 1.2663]\n",
      "09 Jan 11:28    INFO  epoch 12 evaluating [time: 0.05s, valid_score: 0.515600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5156    mrr@3 : 0.3074    ndcg@3 : 0.3604    hit@3 : 0.5156    precision@3 : 0.1719\n",
      "09 Jan 11:28    INFO  epoch 13 training [time: 0.03s, train loss: 1.2558]\n",
      "09 Jan 11:28    INFO  epoch 13 evaluating [time: 0.06s, valid_score: 0.511700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5117    mrr@3 : 0.3093    ndcg@3 : 0.3608    hit@3 : 0.5117    precision@3 : 0.1706\n",
      "09 Jan 11:28    INFO  epoch 14 training [time: 0.03s, train loss: 1.2453]\n",
      "09 Jan 11:28    INFO  epoch 14 evaluating [time: 0.05s, valid_score: 0.519500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5195    mrr@3 : 0.3132    ndcg@3 : 0.3657    hit@3 : 0.5195    precision@3 : 0.1732\n",
      "09 Jan 11:28    INFO  epoch 15 training [time: 0.03s, train loss: 1.2357]\n",
      "09 Jan 11:28    INFO  epoch 15 evaluating [time: 0.05s, valid_score: 0.521400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5214    mrr@3 : 0.3149    ndcg@3 : 0.3674    hit@3 : 0.5214    precision@3 : 0.1738\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\\BPR-Jan-09-2025_11-28-37.pth\n",
      "09 Jan 11:28    INFO  epoch 16 training [time: 0.02s, train loss: 1.2232]\n",
      "09 Jan 11:28    INFO  epoch 16 evaluating [time: 0.04s, valid_score: 0.525300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5253    mrr@3 : 0.3161    ndcg@3 : 0.3694    hit@3 : 0.5253    precision@3 : 0.1751\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\\BPR-Jan-09-2025_11-28-37.pth\n",
      "09 Jan 11:28    INFO  epoch 17 training [time: 0.03s, train loss: 1.2140]\n",
      "09 Jan 11:28    INFO  epoch 17 evaluating [time: 0.05s, valid_score: 0.513600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5136    mrr@3 : 0.3165    ndcg@3 : 0.3667    hit@3 : 0.5136    precision@3 : 0.1712\n",
      "09 Jan 11:28    INFO  epoch 18 training [time: 0.03s, train loss: 1.2017]\n",
      "09 Jan 11:28    INFO  epoch 18 evaluating [time: 0.04s, valid_score: 0.519500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5195    mrr@3 : 0.3213    ndcg@3 : 0.3719    hit@3 : 0.5195    precision@3 : 0.1732\n",
      "09 Jan 11:28    INFO  epoch 19 training [time: 0.04s, train loss: 1.1838]\n",
      "09 Jan 11:28    INFO  epoch 19 evaluating [time: 0.04s, valid_score: 0.519500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5195    mrr@3 : 0.3213    ndcg@3 : 0.3719    hit@3 : 0.5195    precision@3 : 0.1732\n",
      "09 Jan 11:28    INFO  epoch 20 training [time: 0.02s, train loss: 1.1697]\n",
      "09 Jan 11:28    INFO  epoch 20 evaluating [time: 0.05s, valid_score: 0.521400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5214    mrr@3 : 0.3239    ndcg@3 : 0.3744    hit@3 : 0.5214    precision@3 : 0.1738\n",
      "09 Jan 11:28    INFO  epoch 21 training [time: 0.03s, train loss: 1.1620]\n",
      "09 Jan 11:28    INFO  epoch 21 evaluating [time: 0.05s, valid_score: 0.519500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5195    mrr@3 : 0.3252    ndcg@3 : 0.3749    hit@3 : 0.5195    precision@3 : 0.1732\n",
      "09 Jan 11:28    INFO  epoch 22 training [time: 0.02s, train loss: 1.1491]\n",
      "09 Jan 11:28    INFO  epoch 22 evaluating [time: 0.05s, valid_score: 0.517500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5175    mrr@3 : 0.3278    ndcg@3 : 0.3763    hit@3 : 0.5175    precision@3 : 0.1725\n",
      "09 Jan 11:28    INFO  epoch 23 training [time: 0.02s, train loss: 1.1344]\n",
      "09 Jan 11:28    INFO  epoch 23 evaluating [time: 0.05s, valid_score: 0.513600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5136    mrr@3 : 0.3291    ndcg@3 : 0.3763    hit@3 : 0.5136    precision@3 : 0.1712\n",
      "09 Jan 11:28    INFO  epoch 24 training [time: 0.03s, train loss: 1.1205]\n",
      "09 Jan 11:28    INFO  epoch 24 evaluating [time: 0.05s, valid_score: 0.515600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5156    mrr@3 : 0.3317    ndcg@3 : 0.3787    hit@3 : 0.5156    precision@3 : 0.1719\n",
      "09 Jan 11:28    INFO  epoch 25 training [time: 0.02s, train loss: 1.1077]\n",
      "09 Jan 11:28    INFO  epoch 25 evaluating [time: 0.05s, valid_score: 0.511700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5117    mrr@3 : 0.3307    ndcg@3 : 0.377    hit@3 : 0.5117    precision@3 : 0.1706\n",
      "09 Jan 11:28    INFO  epoch 26 training [time: 0.07s, train loss: 1.0924]\n",
      "09 Jan 11:28    INFO  epoch 26 evaluating [time: 0.04s, valid_score: 0.515600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5156    mrr@3 : 0.333    ndcg@3 : 0.3797    hit@3 : 0.5156    precision@3 : 0.1719\n",
      "09 Jan 11:28    INFO  epoch 27 training [time: 0.03s, train loss: 1.0781]\n",
      "09 Jan 11:28    INFO  epoch 27 evaluating [time: 0.04s, valid_score: 0.515600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5156    mrr@3 : 0.3356    ndcg@3 : 0.3816    hit@3 : 0.5156    precision@3 : 0.1719\n",
      "09 Jan 11:28    INFO  Finished training, best eval result in epoch 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5253\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5253), ('mrr@3', 0.3161), ('ndcg@3', 0.3694), ('hit@3', 0.5253), ('precision@3', 0.1751)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "09 Jan 11:28    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt2\\BPR-Jan-09-2025_11-28-37.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5726), ('mrr@3', 0.3619), ('ndcg@3', 0.4157), ('hit@3', 0.5726), ('precision@3', 0.1909)])\n"
     ]
    }
   ],
   "source": [
    "dataset_name=base_dataset_name+'_pt2'\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':data_path+dataset_name,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "\n",
    "train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09 Jan 11:28    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt3\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt3\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "09 Jan 11:28    INFO  sudden_drift_dataset_updated_4000x7_0.71_pt3\n",
      "The number of users: 3001\n",
      "Average actions of users: 2.043\n",
      "The number of items: 8\n",
      "Average actions of items: 875.5714285714286\n",
      "The number of inters: 6129\n",
      "The sparsity of the dataset: 74.47100966344551%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "09 Jan 11:28    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "09 Jan 11:28    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "09 Jan 11:28    INFO  BPR(\n",
      "  (user_embedding): Embedding(3001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 192576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "09 Jan 11:28    INFO  epoch 0 training [time: 0.07s, train loss: 1.3876]\n",
      "09 Jan 11:28    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.508300]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5083    mrr@3 : 0.316    ndcg@3 : 0.365    hit@3 : 0.5083    precision@3 : 0.1694\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt3\\BPR-Jan-09-2025_11-28-42.pth\n",
      "09 Jan 11:28    INFO  epoch 1 training [time: 0.02s, train loss: 1.3761]\n",
      "09 Jan 11:28    INFO  epoch 1 evaluating [time: 0.05s, valid_score: 0.504500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5045    mrr@3 : 0.3171    ndcg@3 : 0.3648    hit@3 : 0.5045    precision@3 : 0.1682\n",
      "09 Jan 11:28    INFO  epoch 2 training [time: 0.03s, train loss: 1.3657]\n",
      "09 Jan 11:28    INFO  epoch 2 evaluating [time: 0.06s, valid_score: 0.510900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5109    mrr@3 : 0.3186    ndcg@3 : 0.3676    hit@3 : 0.5109    precision@3 : 0.1703\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt3\\BPR-Jan-09-2025_11-28-42.pth\n",
      "09 Jan 11:28    INFO  epoch 3 training [time: 0.03s, train loss: 1.3554]\n",
      "09 Jan 11:28    INFO  epoch 3 evaluating [time: 0.07s, valid_score: 0.512200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5122    mrr@3 : 0.3181    ndcg@3 : 0.3676    hit@3 : 0.5122    precision@3 : 0.1707\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt3\\BPR-Jan-09-2025_11-28-42.pth\n",
      "09 Jan 11:28    INFO  epoch 4 training [time: 0.03s, train loss: 1.3444]\n",
      "09 Jan 11:28    INFO  epoch 4 evaluating [time: 0.06s, valid_score: 0.507100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5071    mrr@3 : 0.3156    ndcg@3 : 0.3644    hit@3 : 0.5071    precision@3 : 0.169\n",
      "09 Jan 11:28    INFO  epoch 5 training [time: 0.03s, train loss: 1.3353]\n",
      "09 Jan 11:28    INFO  epoch 5 evaluating [time: 0.06s, valid_score: 0.507100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5071    mrr@3 : 0.3166    ndcg@3 : 0.3652    hit@3 : 0.5071    precision@3 : 0.169\n",
      "09 Jan 11:28    INFO  epoch 6 training [time: 0.04s, train loss: 1.3242]\n",
      "09 Jan 11:28    INFO  epoch 6 evaluating [time: 0.05s, valid_score: 0.505800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5058    mrr@3 : 0.3175    ndcg@3 : 0.3655    hit@3 : 0.5058    precision@3 : 0.1686\n",
      "09 Jan 11:28    INFO  epoch 7 training [time: 0.03s, train loss: 1.3137]\n",
      "09 Jan 11:28    INFO  epoch 7 evaluating [time: 0.18s, valid_score: 0.503200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5032    mrr@3 : 0.3156    ndcg@3 : 0.3635    hit@3 : 0.5032    precision@3 : 0.1677\n",
      "09 Jan 11:28    INFO  epoch 8 training [time: 0.20s, train loss: 1.3027]\n",
      "09 Jan 11:28    INFO  epoch 8 evaluating [time: 0.11s, valid_score: 0.499400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4994    mrr@3 : 0.3154    ndcg@3 : 0.3624    hit@3 : 0.4994    precision@3 : 0.1665\n",
      "09 Jan 11:28    INFO  epoch 9 training [time: 0.05s, train loss: 1.2914]\n",
      "09 Jan 11:28    INFO  epoch 9 evaluating [time: 0.10s, valid_score: 0.494200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4942    mrr@3 : 0.3158    ndcg@3 : 0.3614    hit@3 : 0.4942    precision@3 : 0.1647\n",
      "09 Jan 11:28    INFO  epoch 10 training [time: 0.04s, train loss: 1.2804]\n",
      "09 Jan 11:28    INFO  epoch 10 evaluating [time: 0.05s, valid_score: 0.489100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4891    mrr@3 : 0.3126    ndcg@3 : 0.3576    hit@3 : 0.4891    precision@3 : 0.163\n",
      "09 Jan 11:28    INFO  epoch 11 training [time: 0.03s, train loss: 1.2687]\n",
      "09 Jan 11:28    INFO  epoch 11 evaluating [time: 0.07s, valid_score: 0.494200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4942    mrr@3 : 0.3136    ndcg@3 : 0.3597    hit@3 : 0.4942    precision@3 : 0.1647\n",
      "09 Jan 11:28    INFO  epoch 12 training [time: 0.04s, train loss: 1.2580]\n",
      "09 Jan 11:28    INFO  epoch 12 evaluating [time: 0.06s, valid_score: 0.491700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4917    mrr@3 : 0.3156    ndcg@3 : 0.3605    hit@3 : 0.4917    precision@3 : 0.1639\n",
      "09 Jan 11:28    INFO  epoch 13 training [time: 0.04s, train loss: 1.2450]\n",
      "09 Jan 11:28    INFO  epoch 13 evaluating [time: 0.06s, valid_score: 0.491700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4917    mrr@3 : 0.31    ndcg@3 : 0.3564    hit@3 : 0.4917    precision@3 : 0.1639\n",
      "09 Jan 11:28    INFO  epoch 14 training [time: 0.04s, train loss: 1.2321]\n",
      "09 Jan 11:28    INFO  epoch 14 evaluating [time: 0.12s, valid_score: 0.499400]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.4994    mrr@3 : 0.3119    ndcg@3 : 0.3597    hit@3 : 0.4994    precision@3 : 0.1665\n",
      "09 Jan 11:28    INFO  Finished training, best eval result in epoch 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5122\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5122), ('mrr@3', 0.3181), ('ndcg@3', 0.3676), ('hit@3', 0.5122), ('precision@3', 0.1707)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "09 Jan 11:28    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71_pt3\\BPR-Jan-09-2025_11-28-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5517), ('mrr@3', 0.3444), ('ndcg@3', 0.3974), ('hit@3', 0.5517), ('precision@3', 0.1839)])\n"
     ]
    }
   ],
   "source": [
    "dataset_name=base_dataset_name+'_pt3'\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':data_path+dataset_name,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "\n",
    "train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09 Jan 11:28    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "09 Jan 11:28    INFO  sudden_drift_dataset_updated_4000x7_0.71\n",
      "The number of users: 4002\n",
      "Average actions of users: 2.0354911272181955\n",
      "The number of items: 8\n",
      "Average actions of items: 1163.4285714285713\n",
      "The number of inters: 8144\n",
      "The sparsity of the dataset: 74.56271864067966%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "09 Jan 11:28    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "09 Jan 11:28    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "09 Jan 11:28    INFO  BPR(\n",
      "  (user_embedding): Embedding(4002, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 256640\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "09 Jan 11:28    INFO  epoch 0 training [time: 0.04s, train loss: 2.0811]\n",
      "09 Jan 11:28    INFO  epoch 0 evaluating [time: 0.06s, valid_score: 0.519100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5191    mrr@3 : 0.3195    ndcg@3 : 0.3704    hit@3 : 0.5191    precision@3 : 0.173\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 1 training [time: 0.06s, train loss: 2.0623]\n",
      "09 Jan 11:28    INFO  epoch 1 evaluating [time: 0.06s, valid_score: 0.518100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5181    mrr@3 : 0.3174    ndcg@3 : 0.3686    hit@3 : 0.5181    precision@3 : 0.1727\n",
      "09 Jan 11:28    INFO  epoch 2 training [time: 0.03s, train loss: 2.0413]\n",
      "09 Jan 11:28    INFO  epoch 2 evaluating [time: 0.06s, valid_score: 0.511200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5112    mrr@3 : 0.3138    ndcg@3 : 0.3642    hit@3 : 0.5112    precision@3 : 0.1704\n",
      "09 Jan 11:28    INFO  epoch 3 training [time: 0.04s, train loss: 2.0221]\n",
      "09 Jan 11:28    INFO  epoch 3 evaluating [time: 0.06s, valid_score: 0.513200]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5132    mrr@3 : 0.3122    ndcg@3 : 0.3635    hit@3 : 0.5132    precision@3 : 0.1711\n",
      "09 Jan 11:28    INFO  epoch 4 training [time: 0.03s, train loss: 2.0049]\n",
      "09 Jan 11:28    INFO  epoch 4 evaluating [time: 0.06s, valid_score: 0.520000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.52    mrr@3 : 0.3136    ndcg@3 : 0.3663    hit@3 : 0.52    precision@3 : 0.1733\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 5 training [time: 0.12s, train loss: 1.9853]\n",
      "09 Jan 11:28    INFO  epoch 5 evaluating [time: 0.10s, valid_score: 0.527900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5279    mrr@3 : 0.3156    ndcg@3 : 0.3697    hit@3 : 0.5279    precision@3 : 0.176\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 6 training [time: 0.05s, train loss: 1.9628]\n",
      "09 Jan 11:28    INFO  epoch 6 evaluating [time: 0.14s, valid_score: 0.524900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5249    mrr@3 : 0.3128    ndcg@3 : 0.3669    hit@3 : 0.5249    precision@3 : 0.175\n",
      "09 Jan 11:28    INFO  epoch 7 training [time: 0.07s, train loss: 1.9431]\n",
      "09 Jan 11:28    INFO  epoch 7 evaluating [time: 0.10s, valid_score: 0.520000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.52    mrr@3 : 0.3122    ndcg@3 : 0.3652    hit@3 : 0.52    precision@3 : 0.1733\n",
      "09 Jan 11:28    INFO  epoch 8 training [time: 0.06s, train loss: 1.9211]\n",
      "09 Jan 11:28    INFO  epoch 8 evaluating [time: 0.09s, valid_score: 0.520000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.52    mrr@3 : 0.3143    ndcg@3 : 0.3668    hit@3 : 0.52    precision@3 : 0.1733\n",
      "09 Jan 11:28    INFO  epoch 9 training [time: 0.07s, train loss: 1.8988]\n",
      "09 Jan 11:28    INFO  epoch 9 evaluating [time: 0.09s, valid_score: 0.523900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5239    mrr@3 : 0.317    ndcg@3 : 0.3698    hit@3 : 0.5239    precision@3 : 0.1746\n",
      "09 Jan 11:28    INFO  epoch 10 training [time: 0.04s, train loss: 1.8787]\n",
      "09 Jan 11:28    INFO  epoch 10 evaluating [time: 0.08s, valid_score: 0.520000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.52    mrr@3 : 0.3159    ndcg@3 : 0.368    hit@3 : 0.52    precision@3 : 0.1733\n",
      "09 Jan 11:28    INFO  epoch 11 training [time: 0.04s, train loss: 1.8550]\n",
      "09 Jan 11:28    INFO  epoch 11 evaluating [time: 0.14s, valid_score: 0.520000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.52    mrr@3 : 0.3152    ndcg@3 : 0.3675    hit@3 : 0.52    precision@3 : 0.1733\n",
      "09 Jan 11:28    INFO  epoch 12 training [time: 0.04s, train loss: 1.8284]\n",
      "09 Jan 11:28    INFO  epoch 12 evaluating [time: 0.08s, valid_score: 0.526900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5269    mrr@3 : 0.3164    ndcg@3 : 0.3701    hit@3 : 0.5269    precision@3 : 0.1756\n",
      "09 Jan 11:28    INFO  epoch 13 training [time: 0.04s, train loss: 1.8088]\n",
      "09 Jan 11:28    INFO  epoch 13 evaluating [time: 0.06s, valid_score: 0.529800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5298    mrr@3 : 0.3154    ndcg@3 : 0.3701    hit@3 : 0.5298    precision@3 : 0.1766\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 14 training [time: 0.04s, train loss: 1.7811]\n",
      "09 Jan 11:28    INFO  epoch 14 evaluating [time: 0.06s, valid_score: 0.529800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5298    mrr@3 : 0.3139    ndcg@3 : 0.369    hit@3 : 0.5298    precision@3 : 0.1766\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 15 training [time: 0.05s, train loss: 1.7519]\n",
      "09 Jan 11:28    INFO  epoch 15 evaluating [time: 0.13s, valid_score: 0.522000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.522    mrr@3 : 0.3131    ndcg@3 : 0.3664    hit@3 : 0.522    precision@3 : 0.174\n",
      "09 Jan 11:28    INFO  epoch 16 training [time: 0.07s, train loss: 1.7265]\n",
      "09 Jan 11:28    INFO  epoch 16 evaluating [time: 0.06s, valid_score: 0.520000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.52    mrr@3 : 0.311    ndcg@3 : 0.3642    hit@3 : 0.52    precision@3 : 0.1733\n",
      "09 Jan 11:28    INFO  epoch 17 training [time: 0.04s, train loss: 1.7018]\n",
      "09 Jan 11:28    INFO  epoch 17 evaluating [time: 0.08s, valid_score: 0.527900]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5279    mrr@3 : 0.311    ndcg@3 : 0.3662    hit@3 : 0.5279    precision@3 : 0.176\n",
      "09 Jan 11:28    INFO  epoch 18 training [time: 0.03s, train loss: 1.6729]\n",
      "09 Jan 11:28    INFO  epoch 18 evaluating [time: 0.06s, valid_score: 0.532700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5327    mrr@3 : 0.3172    ndcg@3 : 0.3721    hit@3 : 0.5327    precision@3 : 0.1776\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 19 training [time: 0.03s, train loss: 1.6420]\n",
      "09 Jan 11:28    INFO  epoch 19 evaluating [time: 0.07s, valid_score: 0.544500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5445    mrr@3 : 0.321    ndcg@3 : 0.3779    hit@3 : 0.5445    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 20 training [time: 0.03s, train loss: 1.6155]\n",
      "09 Jan 11:28    INFO  epoch 20 evaluating [time: 0.11s, valid_score: 0.544500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5445    mrr@3 : 0.3214    ndcg@3 : 0.3781    hit@3 : 0.5445    precision@3 : 0.1815\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 21 training [time: 0.03s, train loss: 1.5814]\n",
      "09 Jan 11:28    INFO  epoch 21 evaluating [time: 0.07s, valid_score: 0.545500]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5455    mrr@3 : 0.3223    ndcg@3 : 0.379    hit@3 : 0.5455    precision@3 : 0.1818\n",
      "09 Jan 11:28    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n",
      "09 Jan 11:28    INFO  epoch 22 training [time: 0.03s, train loss: 1.5540]\n",
      "09 Jan 11:28    INFO  epoch 22 evaluating [time: 0.09s, valid_score: 0.540600]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5406    mrr@3 : 0.3203    ndcg@3 : 0.3763    hit@3 : 0.5406    precision@3 : 0.1802\n",
      "09 Jan 11:28    INFO  epoch 23 training [time: 0.04s, train loss: 1.5238]\n",
      "09 Jan 11:28    INFO  epoch 23 evaluating [time: 0.06s, valid_score: 0.536700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5367    mrr@3 : 0.3195    ndcg@3 : 0.3747    hit@3 : 0.5367    precision@3 : 0.1789\n",
      "09 Jan 11:28    INFO  epoch 24 training [time: 0.08s, train loss: 1.4932]\n",
      "09 Jan 11:28    INFO  epoch 24 evaluating [time: 0.05s, valid_score: 0.533700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5337    mrr@3 : 0.317    ndcg@3 : 0.3722    hit@3 : 0.5337    precision@3 : 0.1779\n",
      "09 Jan 11:28    INFO  epoch 25 training [time: 0.09s, train loss: 1.4649]\n",
      "09 Jan 11:28    INFO  epoch 25 evaluating [time: 0.09s, valid_score: 0.529800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5298    mrr@3 : 0.3201    ndcg@3 : 0.3735    hit@3 : 0.5298    precision@3 : 0.1766\n",
      "09 Jan 11:28    INFO  epoch 26 training [time: 0.04s, train loss: 1.4294]\n",
      "09 Jan 11:28    INFO  epoch 26 evaluating [time: 0.07s, valid_score: 0.518100]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5181    mrr@3 : 0.3143    ndcg@3 : 0.3662    hit@3 : 0.5181    precision@3 : 0.1727\n",
      "09 Jan 11:28    INFO  epoch 27 training [time: 0.05s, train loss: 1.3982]\n",
      "09 Jan 11:28    INFO  epoch 27 evaluating [time: 0.08s, valid_score: 0.522000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.522    mrr@3 : 0.3141    ndcg@3 : 0.367    hit@3 : 0.522    precision@3 : 0.174\n",
      "09 Jan 11:28    INFO  epoch 28 training [time: 0.04s, train loss: 1.3691]\n",
      "09 Jan 11:28    INFO  epoch 28 evaluating [time: 0.07s, valid_score: 0.523000]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.523    mrr@3 : 0.3135    ndcg@3 : 0.3668    hit@3 : 0.523    precision@3 : 0.1743\n",
      "09 Jan 11:28    INFO  epoch 29 training [time: 0.04s, train loss: 1.3319]\n",
      "09 Jan 11:28    INFO  epoch 29 evaluating [time: 0.08s, valid_score: 0.528800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5288    mrr@3 : 0.3144    ndcg@3 : 0.369    hit@3 : 0.5288    precision@3 : 0.1763\n",
      "09 Jan 11:28    INFO  epoch 30 training [time: 0.17s, train loss: 1.3000]\n",
      "09 Jan 11:28    INFO  epoch 30 evaluating [time: 0.07s, valid_score: 0.530800]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5308    mrr@3 : 0.3152    ndcg@3 : 0.3701    hit@3 : 0.5308    precision@3 : 0.1769\n",
      "09 Jan 11:28    INFO  epoch 31 training [time: 0.04s, train loss: 1.2720]\n",
      "09 Jan 11:28    INFO  epoch 31 evaluating [time: 0.07s, valid_score: 0.533700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5337    mrr@3 : 0.3166    ndcg@3 : 0.3718    hit@3 : 0.5337    precision@3 : 0.1779\n",
      "09 Jan 11:28    INFO  epoch 32 training [time: 0.04s, train loss: 1.2396]\n",
      "09 Jan 11:28    INFO  epoch 32 evaluating [time: 0.10s, valid_score: 0.533700]\n",
      "09 Jan 11:28    INFO  valid result: \n",
      "recall@3 : 0.5337    mrr@3 : 0.3135    ndcg@3 : 0.3695    hit@3 : 0.5337    precision@3 : 0.1779\n",
      "09 Jan 11:28    INFO  Finished training, best eval result in epoch 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5455\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5455), ('mrr@3', 0.3223), ('ndcg@3', 0.379), ('hit@3', 0.5455), ('precision@3', 0.1818)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "09 Jan 11:28    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_updated_4000x7_0.71\\BPR-Jan-09-2025_11-28-47.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5476), ('mrr@3', 0.3279), ('ndcg@3', 0.3838), ('hit@3', 0.5476), ('precision@3', 0.1825)])\n"
     ]
    }
   ],
   "source": [
    "dataset_name=base_dataset_name+''\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':data_path+dataset_name,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "\n",
    "train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger error in Updated splittage version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt2') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_11-28-25', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt3') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_11-28-25', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt5') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_11-28-25', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_11-28-25', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt7') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_11-28-25', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt8') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_11-28-25', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_11-28-25', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_11-28-37', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt3') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_11-28-37', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt5') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_11-28-37', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_11-28-37', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt7') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_11-28-37', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt8') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_11-28-37', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_11-28-37', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_11-28-42', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt2') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_11-28-42', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='pt5') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_11-28-42', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_11-28-42', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt7') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_11-28-42', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt8') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_11-28-42', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_11-28-42', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_11-28-47', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt2') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_11-28-47', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt3') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_11-28-47', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt5') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_11-28-47', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_11-28-47', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt7') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_11-28-47', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt8') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_11-28-47', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated (user0 ALL part) splittage version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = 'sudden_drift_dataset_u0_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "\n",
    "# Current model\n",
    "base_dataset_name = base_filename+'_4000x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train test Updated user0 all parts version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09 Jan 16:25    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "09 Jan 16:25    INFO  sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1\n",
      "The number of users: 1001\n",
      "Average actions of users: 2.065\n",
      "The number of items: 8\n",
      "Average actions of items: 295.0\n",
      "The number of inters: 2065\n",
      "The sparsity of the dataset: 74.2132867132867%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "09 Jan 16:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "09 Jan 16:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "09 Jan 16:25    INFO  BPR(\n",
      "  (user_embedding): Embedding(1001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 64576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "09 Jan 16:25    INFO  epoch 0 training [time: 0.03s, train loss: 0.6948]\n",
      "09 Jan 16:25    INFO  epoch 0 evaluating [time: 0.02s, valid_score: 0.546100]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5461    mrr@3 : 0.3426    ndcg@3 : 0.3946    hit@3 : 0.5461    precision@3 : 0.182\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1\\BPR-Jan-09-2025_16-25-11.pth\n",
      "09 Jan 16:25    INFO  epoch 1 training [time: 0.01s, train loss: 0.6927]\n",
      "09 Jan 16:25    INFO  epoch 1 evaluating [time: 0.02s, valid_score: 0.553500]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5535    mrr@3 : 0.3469    ndcg@3 : 0.3997    hit@3 : 0.5535    precision@3 : 0.1845\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1\\BPR-Jan-09-2025_16-25-11.pth\n",
      "09 Jan 16:25    INFO  epoch 2 training [time: 0.02s, train loss: 0.6884]\n",
      "09 Jan 16:25    INFO  epoch 2 evaluating [time: 0.02s, valid_score: 0.553500]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5535    mrr@3 : 0.345    ndcg@3 : 0.3982    hit@3 : 0.5535    precision@3 : 0.1845\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1\\BPR-Jan-09-2025_16-25-11.pth\n",
      "09 Jan 16:25    INFO  epoch 3 training [time: 0.02s, train loss: 0.6844]\n",
      "09 Jan 16:25    INFO  epoch 3 evaluating [time: 0.02s, valid_score: 0.560900]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5609    mrr@3 : 0.3493    ndcg@3 : 0.4034    hit@3 : 0.5609    precision@3 : 0.187\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1\\BPR-Jan-09-2025_16-25-11.pth\n",
      "09 Jan 16:25    INFO  epoch 4 training [time: 0.06s, train loss: 0.6795]\n",
      "09 Jan 16:25    INFO  epoch 4 evaluating [time: 0.02s, valid_score: 0.557200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5572    mrr@3 : 0.3499    ndcg@3 : 0.4029    hit@3 : 0.5572    precision@3 : 0.1857\n",
      "09 Jan 16:25    INFO  epoch 5 training [time: 0.01s, train loss: 0.6755]\n",
      "09 Jan 16:25    INFO  epoch 5 evaluating [time: 0.02s, valid_score: 0.557200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5572    mrr@3 : 0.3487    ndcg@3 : 0.4019    hit@3 : 0.5572    precision@3 : 0.1857\n",
      "09 Jan 16:25    INFO  epoch 6 training [time: 0.01s, train loss: 0.6716]\n",
      "09 Jan 16:25    INFO  epoch 6 evaluating [time: 0.02s, valid_score: 0.546100]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5461    mrr@3 : 0.3389    ndcg@3 : 0.3918    hit@3 : 0.5461    precision@3 : 0.182\n",
      "09 Jan 16:25    INFO  epoch 7 training [time: 0.01s, train loss: 0.6701]\n",
      "09 Jan 16:25    INFO  epoch 7 evaluating [time: 0.02s, valid_score: 0.557200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5572    mrr@3 : 0.3426    ndcg@3 : 0.3973    hit@3 : 0.5572    precision@3 : 0.1857\n",
      "09 Jan 16:25    INFO  epoch 8 training [time: 0.01s, train loss: 0.6652]\n",
      "09 Jan 16:25    INFO  epoch 8 evaluating [time: 0.03s, valid_score: 0.557200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5572    mrr@3 : 0.3413    ndcg@3 : 0.3964    hit@3 : 0.5572    precision@3 : 0.1857\n",
      "09 Jan 16:25    INFO  epoch 9 training [time: 0.01s, train loss: 0.6617]\n",
      "09 Jan 16:25    INFO  epoch 9 evaluating [time: 0.02s, valid_score: 0.553500]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5535    mrr@3 : 0.3444    ndcg@3 : 0.3977    hit@3 : 0.5535    precision@3 : 0.1845\n",
      "09 Jan 16:25    INFO  epoch 10 training [time: 0.01s, train loss: 0.6587]\n",
      "09 Jan 16:25    INFO  epoch 10 evaluating [time: 0.02s, valid_score: 0.546100]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5461    mrr@3 : 0.3426    ndcg@3 : 0.3945    hit@3 : 0.5461    precision@3 : 0.182\n",
      "09 Jan 16:25    INFO  epoch 11 training [time: 0.01s, train loss: 0.6530]\n",
      "09 Jan 16:25    INFO  epoch 11 evaluating [time: 0.01s, valid_score: 0.549800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5498    mrr@3 : 0.3438    ndcg@3 : 0.3964    hit@3 : 0.5498    precision@3 : 0.1833\n",
      "09 Jan 16:25    INFO  epoch 12 training [time: 0.01s, train loss: 0.6493]\n",
      "09 Jan 16:25    INFO  epoch 12 evaluating [time: 0.01s, valid_score: 0.549800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5498    mrr@3 : 0.3407    ndcg@3 : 0.394    hit@3 : 0.5498    precision@3 : 0.1833\n",
      "09 Jan 16:25    INFO  epoch 13 training [time: 0.01s, train loss: 0.6472]\n",
      "09 Jan 16:25    INFO  epoch 13 evaluating [time: 0.02s, valid_score: 0.542400]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5424    mrr@3 : 0.3346    ndcg@3 : 0.3875    hit@3 : 0.5424    precision@3 : 0.1808\n",
      "09 Jan 16:25    INFO  epoch 14 training [time: 0.01s, train loss: 0.6420]\n",
      "09 Jan 16:25    INFO  epoch 14 evaluating [time: 0.01s, valid_score: 0.546100]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5461    mrr@3 : 0.3389    ndcg@3 : 0.3916    hit@3 : 0.5461    precision@3 : 0.182\n",
      "09 Jan 16:25    INFO  Finished training, best eval result in epoch 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5609\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5609), ('mrr@3', 0.3493), ('ndcg@3', 0.4034), ('hit@3', 0.5609), ('precision@3', 0.187)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "09 Jan 16:25    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt1\\BPR-Jan-09-2025_16-25-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5551), ('mrr@3', 0.3361), ('ndcg@3', 0.392), ('hit@3', 0.5551), ('precision@3', 0.185)])\n"
     ]
    }
   ],
   "source": [
    "dataset_name=base_dataset_name+'_pt1'\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':data_path+dataset_name,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "\n",
    "train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09 Jan 16:25    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt2\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt2\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "09 Jan 16:25    INFO  sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt2\n",
      "The number of users: 2001\n",
      "Average actions of users: 2.035\n",
      "The number of items: 8\n",
      "Average actions of items: 581.4285714285714\n",
      "The number of inters: 4070\n",
      "The sparsity of the dataset: 74.5752123938031%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "09 Jan 16:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "09 Jan 16:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "09 Jan 16:25    INFO  BPR(\n",
      "  (user_embedding): Embedding(2001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 128576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "09 Jan 16:25    INFO  epoch 0 training [time: 0.05s, train loss: 1.3831]\n",
      "09 Jan 16:25    INFO  epoch 0 evaluating [time: 0.04s, valid_score: 0.545600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5456    mrr@3 : 0.3489    ndcg@3 : 0.399    hit@3 : 0.5456    precision@3 : 0.1819\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt2\\BPR-Jan-09-2025_16-25-14.pth\n",
      "09 Jan 16:25    INFO  epoch 1 training [time: 0.01s, train loss: 1.3714]\n",
      "09 Jan 16:25    INFO  epoch 1 evaluating [time: 0.02s, valid_score: 0.557300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5573    mrr@3 : 0.3482    ndcg@3 : 0.4015    hit@3 : 0.5573    precision@3 : 0.1858\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt2\\BPR-Jan-09-2025_16-25-14.pth\n",
      "09 Jan 16:25    INFO  epoch 2 training [time: 0.01s, train loss: 1.3660]\n",
      "09 Jan 16:25    INFO  epoch 2 evaluating [time: 0.03s, valid_score: 0.543700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5437    mrr@3 : 0.3411    ndcg@3 : 0.3928    hit@3 : 0.5437    precision@3 : 0.1812\n",
      "09 Jan 16:25    INFO  epoch 3 training [time: 0.01s, train loss: 1.3541]\n",
      "09 Jan 16:25    INFO  epoch 3 evaluating [time: 0.02s, valid_score: 0.539800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5398    mrr@3 : 0.3395    ndcg@3 : 0.3906    hit@3 : 0.5398    precision@3 : 0.1799\n",
      "09 Jan 16:25    INFO  epoch 4 training [time: 0.01s, train loss: 1.3434]\n",
      "09 Jan 16:25    INFO  epoch 4 evaluating [time: 0.03s, valid_score: 0.539800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5398    mrr@3 : 0.3356    ndcg@3 : 0.3876    hit@3 : 0.5398    precision@3 : 0.1799\n",
      "09 Jan 16:25    INFO  epoch 5 training [time: 0.01s, train loss: 1.3316]\n",
      "09 Jan 16:25    INFO  epoch 5 evaluating [time: 0.03s, valid_score: 0.541700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5417    mrr@3 : 0.335    ndcg@3 : 0.3876    hit@3 : 0.5417    precision@3 : 0.1806\n",
      "09 Jan 16:25    INFO  epoch 6 training [time: 0.01s, train loss: 1.3191]\n",
      "09 Jan 16:25    INFO  epoch 6 evaluating [time: 0.02s, valid_score: 0.532000]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.532    mrr@3 : 0.3285    ndcg@3 : 0.3803    hit@3 : 0.532    precision@3 : 0.1773\n",
      "09 Jan 16:25    INFO  epoch 7 training [time: 0.01s, train loss: 1.3091]\n",
      "09 Jan 16:25    INFO  epoch 7 evaluating [time: 0.02s, valid_score: 0.528200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5282    mrr@3 : 0.3259    ndcg@3 : 0.3774    hit@3 : 0.5282    precision@3 : 0.1761\n",
      "09 Jan 16:25    INFO  epoch 8 training [time: 0.01s, train loss: 1.2965]\n",
      "09 Jan 16:25    INFO  epoch 8 evaluating [time: 0.01s, valid_score: 0.524300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5243    mrr@3 : 0.3223    ndcg@3 : 0.3738    hit@3 : 0.5243    precision@3 : 0.1748\n",
      "09 Jan 16:25    INFO  epoch 9 training [time: 0.02s, train loss: 1.2904]\n",
      "09 Jan 16:25    INFO  epoch 9 evaluating [time: 0.02s, valid_score: 0.520400]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5204    mrr@3 : 0.3165    ndcg@3 : 0.3685    hit@3 : 0.5204    precision@3 : 0.1735\n",
      "09 Jan 16:25    INFO  epoch 10 training [time: 0.01s, train loss: 1.2796]\n",
      "09 Jan 16:25    INFO  epoch 10 evaluating [time: 0.02s, valid_score: 0.520400]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5204    mrr@3 : 0.3168    ndcg@3 : 0.3687    hit@3 : 0.5204    precision@3 : 0.1735\n",
      "09 Jan 16:25    INFO  epoch 11 training [time: 0.01s, train loss: 1.2670]\n",
      "09 Jan 16:25    INFO  epoch 11 evaluating [time: 0.02s, valid_score: 0.506800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5068    mrr@3 : 0.311    ndcg@3 : 0.361    hit@3 : 0.5068    precision@3 : 0.1689\n",
      "09 Jan 16:25    INFO  epoch 12 training [time: 0.02s, train loss: 1.2535]\n",
      "09 Jan 16:25    INFO  epoch 12 evaluating [time: 0.02s, valid_score: 0.501000]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.501    mrr@3 : 0.3055    ndcg@3 : 0.3553    hit@3 : 0.501    precision@3 : 0.167\n",
      "09 Jan 16:25    INFO  Finished training, best eval result in epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5573\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5573), ('mrr@3', 0.3482), ('ndcg@3', 0.4015), ('hit@3', 0.5573), ('precision@3', 0.1858)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "09 Jan 16:25    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt2\\BPR-Jan-09-2025_16-25-14.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5663), ('mrr@3', 0.3361), ('ndcg@3', 0.3947), ('hit@3', 0.5663), ('precision@3', 0.1888)])\n"
     ]
    }
   ],
   "source": [
    "dataset_name=base_dataset_name+'_pt2'\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':data_path+dataset_name,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "\n",
    "train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09 Jan 16:25    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt3\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt3\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "09 Jan 16:25    INFO  sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt3\n",
      "The number of users: 3001\n",
      "Average actions of users: 2.0436666666666667\n",
      "The number of items: 8\n",
      "Average actions of items: 875.8571428571429\n",
      "The number of inters: 6131\n",
      "The sparsity of the dataset: 74.46267910696434%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "09 Jan 16:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "09 Jan 16:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "09 Jan 16:25    INFO  BPR(\n",
      "  (user_embedding): Embedding(3001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 192576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "09 Jan 16:25    INFO  epoch 0 training [time: 0.04s, train loss: 1.3877]\n",
      "09 Jan 16:25    INFO  epoch 0 evaluating [time: 0.03s, valid_score: 0.533300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3235    ndcg@3 : 0.3769    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt3\\BPR-Jan-09-2025_16-25-16.pth\n",
      "09 Jan 16:25    INFO  epoch 1 training [time: 0.02s, train loss: 1.3757]\n",
      "09 Jan 16:25    INFO  epoch 1 evaluating [time: 0.04s, valid_score: 0.542300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5423    mrr@3 : 0.325    ndcg@3 : 0.3803    hit@3 : 0.5423    precision@3 : 0.1808\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt3\\BPR-Jan-09-2025_16-25-16.pth\n",
      "09 Jan 16:25    INFO  epoch 2 training [time: 0.03s, train loss: 1.3659]\n",
      "09 Jan 16:25    INFO  epoch 2 evaluating [time: 0.04s, valid_score: 0.529500]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5295    mrr@3 : 0.3216    ndcg@3 : 0.3746    hit@3 : 0.5295    precision@3 : 0.1765\n",
      "09 Jan 16:25    INFO  epoch 3 training [time: 0.02s, train loss: 1.3556]\n",
      "09 Jan 16:25    INFO  epoch 3 evaluating [time: 0.03s, valid_score: 0.533300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3259    ndcg@3 : 0.3788    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "09 Jan 16:25    INFO  epoch 4 training [time: 0.02s, train loss: 1.3453]\n",
      "09 Jan 16:25    INFO  epoch 4 evaluating [time: 0.05s, valid_score: 0.530800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5308    mrr@3 : 0.3235    ndcg@3 : 0.3764    hit@3 : 0.5308    precision@3 : 0.1769\n",
      "09 Jan 16:25    INFO  epoch 5 training [time: 0.03s, train loss: 1.3336]\n",
      "09 Jan 16:25    INFO  epoch 5 evaluating [time: 0.04s, valid_score: 0.532100]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5321    mrr@3 : 0.3267    ndcg@3 : 0.3791    hit@3 : 0.5321    precision@3 : 0.1774\n",
      "09 Jan 16:25    INFO  epoch 6 training [time: 0.02s, train loss: 1.3245]\n",
      "09 Jan 16:25    INFO  epoch 6 evaluating [time: 0.04s, valid_score: 0.541000]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.541    mrr@3 : 0.3295    ndcg@3 : 0.3834    hit@3 : 0.541    precision@3 : 0.1803\n",
      "09 Jan 16:25    INFO  epoch 7 training [time: 0.02s, train loss: 1.3126]\n",
      "09 Jan 16:25    INFO  epoch 7 evaluating [time: 0.04s, valid_score: 0.530800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5308    mrr@3 : 0.3269    ndcg@3 : 0.3789    hit@3 : 0.5308    precision@3 : 0.1769\n",
      "09 Jan 16:25    INFO  epoch 8 training [time: 0.03s, train loss: 1.3015]\n",
      "09 Jan 16:25    INFO  epoch 8 evaluating [time: 0.04s, valid_score: 0.530800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5308    mrr@3 : 0.3288    ndcg@3 : 0.3804    hit@3 : 0.5308    precision@3 : 0.1769\n",
      "09 Jan 16:25    INFO  epoch 9 training [time: 0.03s, train loss: 1.2887]\n",
      "09 Jan 16:25    INFO  epoch 9 evaluating [time: 0.04s, valid_score: 0.533300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3306    ndcg@3 : 0.3823    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "09 Jan 16:25    INFO  epoch 10 training [time: 0.02s, train loss: 1.2768]\n",
      "09 Jan 16:25    INFO  epoch 10 evaluating [time: 0.04s, valid_score: 0.533300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3295    ndcg@3 : 0.3815    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "09 Jan 16:25    INFO  epoch 11 training [time: 0.01s, train loss: 1.2655]\n",
      "09 Jan 16:25    INFO  epoch 11 evaluating [time: 0.05s, valid_score: 0.534600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5346    mrr@3 : 0.3301    ndcg@3 : 0.3823    hit@3 : 0.5346    precision@3 : 0.1782\n",
      "09 Jan 16:25    INFO  epoch 12 training [time: 0.02s, train loss: 1.2543]\n",
      "09 Jan 16:25    INFO  epoch 12 evaluating [time: 0.04s, valid_score: 0.535900]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5359    mrr@3 : 0.3308    ndcg@3 : 0.3831    hit@3 : 0.5359    precision@3 : 0.1786\n",
      "09 Jan 16:25    INFO  Finished training, best eval result in epoch 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5423\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5423), ('mrr@3', 0.325), ('ndcg@3', 0.3803), ('hit@3', 0.5423), ('precision@3', 0.1808)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "09 Jan 16:25    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71_pt3\\BPR-Jan-09-2025_16-25-16.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5602), ('mrr@3', 0.3478), ('ndcg@3', 0.4019), ('hit@3', 0.5602), ('precision@3', 0.1867)])\n"
     ]
    }
   ],
   "source": [
    "dataset_name=base_dataset_name+'_pt3'\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':data_path+dataset_name,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "\n",
    "train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09 Jan 16:25    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "09 Jan 16:25    INFO  sudden_drift_dataset_u0_all_parts_4000x7_0.71\n",
      "The number of users: 4002\n",
      "Average actions of users: 2.0359910022494376\n",
      "The number of items: 8\n",
      "Average actions of items: 1163.7142857142858\n",
      "The number of inters: 8146\n",
      "The sparsity of the dataset: 74.55647176411794%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "09 Jan 16:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "09 Jan 16:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "09 Jan 16:25    INFO  BPR(\n",
      "  (user_embedding): Embedding(4002, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 256640\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n",
      "09 Jan 16:25    INFO  epoch 0 training [time: 0.04s, train loss: 2.0811]\n",
      "09 Jan 16:25    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.526400]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5264    mrr@3 : 0.3237    ndcg@3 : 0.3754    hit@3 : 0.5264    precision@3 : 0.1755\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 1 training [time: 0.03s, train loss: 2.0630]\n",
      "09 Jan 16:25    INFO  epoch 1 evaluating [time: 0.04s, valid_score: 0.537100]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5371    mrr@3 : 0.3283    ndcg@3 : 0.3816    hit@3 : 0.5371    precision@3 : 0.179\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 2 training [time: 0.03s, train loss: 2.0408]\n",
      "09 Jan 16:25    INFO  epoch 2 evaluating [time: 0.05s, valid_score: 0.540000]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.54    mrr@3 : 0.3335    ndcg@3 : 0.3862    hit@3 : 0.54    precision@3 : 0.18\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 3 training [time: 0.03s, train loss: 2.0240]\n",
      "09 Jan 16:25    INFO  epoch 3 evaluating [time: 0.05s, valid_score: 0.544900]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5449    mrr@3 : 0.3387    ndcg@3 : 0.3913    hit@3 : 0.5449    precision@3 : 0.1816\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 4 training [time: 0.02s, train loss: 2.0059]\n",
      "09 Jan 16:25    INFO  epoch 4 evaluating [time: 0.05s, valid_score: 0.551800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5518    mrr@3 : 0.3437    ndcg@3 : 0.3969    hit@3 : 0.5518    precision@3 : 0.1839\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 5 training [time: 0.03s, train loss: 1.9839]\n",
      "09 Jan 16:25    INFO  epoch 5 evaluating [time: 0.05s, valid_score: 0.545900]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5459    mrr@3 : 0.3416    ndcg@3 : 0.3938    hit@3 : 0.5459    precision@3 : 0.182\n",
      "09 Jan 16:25    INFO  epoch 6 training [time: 0.03s, train loss: 1.9623]\n",
      "09 Jan 16:25    INFO  epoch 6 evaluating [time: 0.04s, valid_score: 0.549800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5498    mrr@3 : 0.3447    ndcg@3 : 0.3971    hit@3 : 0.5498    precision@3 : 0.1833\n",
      "09 Jan 16:25    INFO  epoch 7 training [time: 0.02s, train loss: 1.9432]\n",
      "09 Jan 16:25    INFO  epoch 7 evaluating [time: 0.04s, valid_score: 0.550800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5508    mrr@3 : 0.3485    ndcg@3 : 0.4001    hit@3 : 0.5508    precision@3 : 0.1836\n",
      "09 Jan 16:25    INFO  epoch 8 training [time: 0.03s, train loss: 1.9225]\n",
      "09 Jan 16:25    INFO  epoch 8 evaluating [time: 0.05s, valid_score: 0.545900]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5459    mrr@3 : 0.3477    ndcg@3 : 0.3982    hit@3 : 0.5459    precision@3 : 0.182\n",
      "09 Jan 16:25    INFO  epoch 9 training [time: 0.03s, train loss: 1.9001]\n",
      "09 Jan 16:25    INFO  epoch 9 evaluating [time: 0.05s, valid_score: 0.542000]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.542    mrr@3 : 0.3468    ndcg@3 : 0.3967    hit@3 : 0.542    precision@3 : 0.1807\n",
      "09 Jan 16:25    INFO  epoch 10 training [time: 0.03s, train loss: 1.8789]\n",
      "09 Jan 16:25    INFO  epoch 10 evaluating [time: 0.06s, valid_score: 0.548800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5488    mrr@3 : 0.3454    ndcg@3 : 0.3973    hit@3 : 0.5488    precision@3 : 0.1829\n",
      "09 Jan 16:25    INFO  epoch 11 training [time: 0.03s, train loss: 1.8567]\n",
      "09 Jan 16:25    INFO  epoch 11 evaluating [time: 0.05s, valid_score: 0.555700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5557    mrr@3 : 0.3491    ndcg@3 : 0.4018    hit@3 : 0.5557    precision@3 : 0.1852\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 12 training [time: 0.02s, train loss: 1.8302]\n",
      "09 Jan 16:25    INFO  epoch 12 evaluating [time: 0.11s, valid_score: 0.559600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5596    mrr@3 : 0.3511    ndcg@3 : 0.4043    hit@3 : 0.5596    precision@3 : 0.1865\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 13 training [time: 0.02s, train loss: 1.8059]\n",
      "09 Jan 16:25    INFO  epoch 13 evaluating [time: 0.04s, valid_score: 0.564500]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5645    mrr@3 : 0.3553    ndcg@3 : 0.4086    hit@3 : 0.5645    precision@3 : 0.1882\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 14 training [time: 0.02s, train loss: 1.7826]\n",
      "09 Jan 16:25    INFO  epoch 14 evaluating [time: 0.05s, valid_score: 0.563500]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5635    mrr@3 : 0.3568    ndcg@3 : 0.4095    hit@3 : 0.5635    precision@3 : 0.1878\n",
      "09 Jan 16:25    INFO  epoch 15 training [time: 0.03s, train loss: 1.7535]\n",
      "09 Jan 16:25    INFO  epoch 15 evaluating [time: 0.03s, valid_score: 0.566400]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5664    mrr@3 : 0.3602    ndcg@3 : 0.4129    hit@3 : 0.5664    precision@3 : 0.1888\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 16 training [time: 0.02s, train loss: 1.7270]\n",
      "09 Jan 16:25    INFO  epoch 16 evaluating [time: 0.04s, valid_score: 0.566400]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5664    mrr@3 : 0.36    ndcg@3 : 0.4127    hit@3 : 0.5664    precision@3 : 0.1888\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 17 training [time: 0.04s, train loss: 1.7005]\n",
      "09 Jan 16:25    INFO  epoch 17 evaluating [time: 0.05s, valid_score: 0.572300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5723    mrr@3 : 0.3649    ndcg@3 : 0.4178    hit@3 : 0.5723    precision@3 : 0.1908\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 18 training [time: 0.02s, train loss: 1.6714]\n",
      "09 Jan 16:25    INFO  epoch 18 evaluating [time: 0.05s, valid_score: 0.576200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5762    mrr@3 : 0.3657    ndcg@3 : 0.4195    hit@3 : 0.5762    precision@3 : 0.1921\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 19 training [time: 0.03s, train loss: 1.6418]\n",
      "09 Jan 16:25    INFO  epoch 19 evaluating [time: 0.05s, valid_score: 0.575200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5752    mrr@3 : 0.3652    ndcg@3 : 0.4189    hit@3 : 0.5752    precision@3 : 0.1917\n",
      "09 Jan 16:25    INFO  epoch 20 training [time: 0.02s, train loss: 1.6127]\n",
      "09 Jan 16:25    INFO  epoch 20 evaluating [time: 0.05s, valid_score: 0.570300]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5703    mrr@3 : 0.3652    ndcg@3 : 0.4177    hit@3 : 0.5703    precision@3 : 0.1901\n",
      "09 Jan 16:25    INFO  epoch 21 training [time: 0.02s, train loss: 1.5866]\n",
      "09 Jan 16:25    INFO  epoch 21 evaluating [time: 0.04s, valid_score: 0.576200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5762    mrr@3 : 0.369    ndcg@3 : 0.4219    hit@3 : 0.5762    precision@3 : 0.1921\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 22 training [time: 0.03s, train loss: 1.5529]\n",
      "09 Jan 16:25    INFO  epoch 22 evaluating [time: 0.04s, valid_score: 0.576200]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5762    mrr@3 : 0.3698    ndcg@3 : 0.4226    hit@3 : 0.5762    precision@3 : 0.1921\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 23 training [time: 0.10s, train loss: 1.5241]\n",
      "09 Jan 16:25    INFO  epoch 23 evaluating [time: 0.07s, valid_score: 0.579100]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5791    mrr@3 : 0.3708    ndcg@3 : 0.4241    hit@3 : 0.5791    precision@3 : 0.193\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 24 training [time: 0.03s, train loss: 1.4920]\n",
      "09 Jan 16:25    INFO  epoch 24 evaluating [time: 0.04s, valid_score: 0.586900]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5869    mrr@3 : 0.373    ndcg@3 : 0.4277    hit@3 : 0.5869    precision@3 : 0.1956\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 25 training [time: 0.03s, train loss: 1.4571]\n",
      "09 Jan 16:25    INFO  epoch 25 evaluating [time: 0.07s, valid_score: 0.585900]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5859    mrr@3 : 0.3765    ndcg@3 : 0.43    hit@3 : 0.5859    precision@3 : 0.1953\n",
      "09 Jan 16:25    INFO  epoch 26 training [time: 0.03s, train loss: 1.4309]\n",
      "09 Jan 16:25    INFO  epoch 26 evaluating [time: 0.05s, valid_score: 0.590800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5908    mrr@3 : 0.3774    ndcg@3 : 0.432    hit@3 : 0.5908    precision@3 : 0.1969\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 27 training [time: 0.03s, train loss: 1.3931]\n",
      "09 Jan 16:25    INFO  epoch 27 evaluating [time: 0.05s, valid_score: 0.591800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5918    mrr@3 : 0.3778    ndcg@3 : 0.4324    hit@3 : 0.5918    precision@3 : 0.1973\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 28 training [time: 0.03s, train loss: 1.3640]\n",
      "09 Jan 16:25    INFO  epoch 28 evaluating [time: 0.06s, valid_score: 0.594700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5947    mrr@3 : 0.3758    ndcg@3 : 0.4317    hit@3 : 0.5947    precision@3 : 0.1982\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 29 training [time: 0.03s, train loss: 1.3316]\n",
      "09 Jan 16:25    INFO  epoch 29 evaluating [time: 0.05s, valid_score: 0.594700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5947    mrr@3 : 0.3779    ndcg@3 : 0.4333    hit@3 : 0.5947    precision@3 : 0.1982\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 30 training [time: 0.02s, train loss: 1.2986]\n",
      "09 Jan 16:25    INFO  epoch 30 evaluating [time: 0.10s, valid_score: 0.592800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5928    mrr@3 : 0.3768    ndcg@3 : 0.432    hit@3 : 0.5928    precision@3 : 0.1976\n",
      "09 Jan 16:25    INFO  epoch 31 training [time: 0.03s, train loss: 1.2659]\n",
      "09 Jan 16:25    INFO  epoch 31 evaluating [time: 0.06s, valid_score: 0.590800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5908    mrr@3 : 0.3745    ndcg@3 : 0.4298    hit@3 : 0.5908    precision@3 : 0.1969\n",
      "09 Jan 16:25    INFO  epoch 32 training [time: 0.03s, train loss: 1.2342]\n",
      "09 Jan 16:25    INFO  epoch 32 evaluating [time: 0.05s, valid_score: 0.593800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5938    mrr@3 : 0.3774    ndcg@3 : 0.4327    hit@3 : 0.5938    precision@3 : 0.1979\n",
      "09 Jan 16:25    INFO  epoch 33 training [time: 0.02s, train loss: 1.2042]\n",
      "09 Jan 16:25    INFO  epoch 33 evaluating [time: 0.05s, valid_score: 0.593800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5938    mrr@3 : 0.3818    ndcg@3 : 0.436    hit@3 : 0.5938    precision@3 : 0.1979\n",
      "09 Jan 16:25    INFO  epoch 34 training [time: 0.03s, train loss: 1.1698]\n",
      "09 Jan 16:25    INFO  epoch 34 evaluating [time: 0.04s, valid_score: 0.597700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5977    mrr@3 : 0.382    ndcg@3 : 0.4371    hit@3 : 0.5977    precision@3 : 0.1992\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 35 training [time: 0.02s, train loss: 1.1413]\n",
      "09 Jan 16:25    INFO  epoch 35 evaluating [time: 0.11s, valid_score: 0.598600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5986    mrr@3 : 0.3836    ndcg@3 : 0.4386    hit@3 : 0.5986    precision@3 : 0.1995\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 36 training [time: 0.03s, train loss: 1.1051]\n",
      "09 Jan 16:25    INFO  epoch 36 evaluating [time: 0.06s, valid_score: 0.598600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5986    mrr@3 : 0.3825    ndcg@3 : 0.4377    hit@3 : 0.5986    precision@3 : 0.1995\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 37 training [time: 0.03s, train loss: 1.0767]\n",
      "09 Jan 16:25    INFO  epoch 37 evaluating [time: 0.05s, valid_score: 0.601600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.6016    mrr@3 : 0.3859    ndcg@3 : 0.4409    hit@3 : 0.6016    precision@3 : 0.2005\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 38 training [time: 0.02s, train loss: 1.0420]\n",
      "09 Jan 16:25    INFO  epoch 38 evaluating [time: 0.05s, valid_score: 0.601600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.6016    mrr@3 : 0.3836    ndcg@3 : 0.4392    hit@3 : 0.6016    precision@3 : 0.2005\n",
      "09 Jan 16:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n",
      "09 Jan 16:25    INFO  epoch 39 training [time: 0.03s, train loss: 1.0137]\n",
      "09 Jan 16:25    INFO  epoch 39 evaluating [time: 0.13s, valid_score: 0.598600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5986    mrr@3 : 0.3815    ndcg@3 : 0.4369    hit@3 : 0.5986    precision@3 : 0.1995\n",
      "09 Jan 16:25    INFO  epoch 40 training [time: 0.04s, train loss: 0.9804]\n",
      "09 Jan 16:25    INFO  epoch 40 evaluating [time: 0.05s, valid_score: 0.599600]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5996    mrr@3 : 0.3835    ndcg@3 : 0.4386    hit@3 : 0.5996    precision@3 : 0.1999\n",
      "09 Jan 16:25    INFO  epoch 41 training [time: 0.03s, train loss: 0.9497]\n",
      "09 Jan 16:25    INFO  epoch 41 evaluating [time: 0.04s, valid_score: 0.596700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5967    mrr@3 : 0.3825    ndcg@3 : 0.4372    hit@3 : 0.5967    precision@3 : 0.1989\n",
      "09 Jan 16:25    INFO  epoch 42 training [time: 0.02s, train loss: 0.9251]\n",
      "09 Jan 16:25    INFO  epoch 42 evaluating [time: 0.05s, valid_score: 0.595700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5957    mrr@3 : 0.3823    ndcg@3 : 0.4369    hit@3 : 0.5957    precision@3 : 0.1986\n",
      "09 Jan 16:25    INFO  epoch 43 training [time: 0.03s, train loss: 0.8903]\n",
      "09 Jan 16:25    INFO  epoch 43 evaluating [time: 0.05s, valid_score: 0.597700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5977    mrr@3 : 0.3818    ndcg@3 : 0.437    hit@3 : 0.5977    precision@3 : 0.1992\n",
      "09 Jan 16:25    INFO  epoch 44 training [time: 0.02s, train loss: 0.8647]\n",
      "09 Jan 16:25    INFO  epoch 44 evaluating [time: 0.09s, valid_score: 0.596700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5967    mrr@3 : 0.3822    ndcg@3 : 0.437    hit@3 : 0.5967    precision@3 : 0.1989\n",
      "09 Jan 16:25    INFO  epoch 45 training [time: 0.05s, train loss: 0.8375]\n",
      "09 Jan 16:25    INFO  epoch 45 evaluating [time: 0.05s, valid_score: 0.589800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5898    mrr@3 : 0.3799    ndcg@3 : 0.4336    hit@3 : 0.5898    precision@3 : 0.1966\n",
      "09 Jan 16:25    INFO  epoch 46 training [time: 0.02s, train loss: 0.8113]\n",
      "09 Jan 16:25    INFO  epoch 46 evaluating [time: 0.04s, valid_score: 0.593800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5938    mrr@3 : 0.3817    ndcg@3 : 0.4359    hit@3 : 0.5938    precision@3 : 0.1979\n",
      "09 Jan 16:25    INFO  epoch 47 training [time: 0.02s, train loss: 0.7853]\n",
      "09 Jan 16:25    INFO  epoch 47 evaluating [time: 0.05s, valid_score: 0.592800]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5928    mrr@3 : 0.3815    ndcg@3 : 0.4355    hit@3 : 0.5928    precision@3 : 0.1976\n",
      "09 Jan 16:25    INFO  epoch 48 training [time: 0.03s, train loss: 0.7581]\n",
      "09 Jan 16:25    INFO  epoch 48 evaluating [time: 0.04s, valid_score: 0.594700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5947    mrr@3 : 0.3823    ndcg@3 : 0.4366    hit@3 : 0.5947    precision@3 : 0.1982\n",
      "09 Jan 16:25    INFO  epoch 49 training [time: 0.03s, train loss: 0.7333]\n",
      "09 Jan 16:25    INFO  epoch 49 evaluating [time: 0.09s, valid_score: 0.594700]\n",
      "09 Jan 16:25    INFO  valid result: \n",
      "recall@3 : 0.5947    mrr@3 : 0.3833    ndcg@3 : 0.4373    hit@3 : 0.5947    precision@3 : 0.1982\n",
      "09 Jan 16:25    INFO  Finished training, best eval result in epoch 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.6016\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.6016), ('mrr@3', 0.3836), ('ndcg@3', 0.4392), ('hit@3', 0.6016), ('precision@3', 0.2005)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "09 Jan 16:25    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_all_parts_4000x7_0.71\\BPR-Jan-09-2025_16-25-19.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.6734), ('mrr@3', 0.4335), ('ndcg@3', 0.4948), ('hit@3', 0.6734), ('precision@3', 0.2245)])\n"
     ]
    }
   ],
   "source": [
    "dataset_name=base_dataset_name+''\n",
    "parameter_dict = {\n",
    "    'dataset': dataset_name+'.inter',\n",
    "    'data_path': data_path,\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'use_gpu':USE_GPU,\n",
    "    'topk':K,\n",
    "    'valid_metric':VALID_METRIC,\n",
    "    'checkpoint_dir':data_path+dataset_name,\n",
    "    'seed':SEED,\n",
    "    'shuffle': SHUFFLE\n",
    "}\n",
    "\n",
    "\n",
    "train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger error in Updated (user0 ALL parts) splittage version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='pt_2') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_16-25-11', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='pt_3') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_16-25-11', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt5') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_16-25-11', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt6') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_16-25-11', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt7') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_16-25-11', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='_pt8') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_16-25-11', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt1', data_ver='') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-09-2025_16-25-11', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_16-25-14', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt3') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_16-25-14', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt5') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_16-25-14', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_16-25-14', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt7') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_16-25-14', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='_pt8') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_16-25-14', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt2', data_ver='') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-09-2025_16-25-14', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_16-25-16', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt2') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_16-25-16', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt5') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_16-25-16', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_16-25-16', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt7') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_16-25-16', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='_pt8') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_16-25-16', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='_pt3', data_ver='') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-09-2025_16-25-16', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_16-25-19', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt2') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_16-25-19', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt3') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_16-25-19', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt5') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_16-25-19', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_16-25-19', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt7') (UsI e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_16-25-19', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigger_error(model_ver='', data_ver='_pt8') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-09-2025_16-25-19', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-generate data with added user0 seeing item 1 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_items_list ['i_1', 'i_5']\n",
      "renamed_items {'i_1': 'drifted_i_1', 'i_5': 'drifted_i_5'}\n",
      "non_drift_items_list ['i_4', 'i_3', 'i_2']\n",
      "users_not_sampled 566\n",
      "specs_str 3999x7_0.71\n",
      "sparsity:  0.7094988032722467\n",
      "item_id  drifted_i_1  drifted_i_5  i_1  i_2  i_3  i_4  i_5\n",
      "user_id                                                   \n",
      "u_10               0            0    1    0    0    0    1\n",
      "u_100              0            0    1    0    0    0    1\n",
      "u_1000             0            0    1    0    1    0    0\n",
      "u_1001             0            0    1    0    1    0    0\n",
      "u_1002             0            0    1    0    1    1    1\n",
      "...              ...          ...  ...  ...  ...  ...  ...\n",
      "u_995              0            0    1    0    0    0    1\n",
      "u_996              0            0    1    0    0    1    0\n",
      "u_997              0            0    1    1    0    1    0\n",
      "u_998              0            0    1    0    0    1    0\n",
      "u_999              0            0    1    0    0    0    1\n",
      "\n",
      "[3999 rows x 7 columns]\n",
      "  user_id item_id     timestamp\n",
      "0  u_1311     i_4  1.735093e+09\n",
      "1   u_230     i_4  1.735093e+09\n",
      "2    u_53     i_4  1.735093e+09\n",
      "3  u_1520     i_4  1.735093e+09\n",
      "4   u_565     i_4  1.735093e+09\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71.\n",
      "item_id\n",
      "drifted_i_5    1289\n",
      "drifted_i_1    1288\n",
      "i_1            1280\n",
      "i_5            1279\n",
      "i_4            1000\n",
      "i_3            1000\n",
      "i_2            1000\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1.\n",
      "item_id\n",
      "i_1            662\n",
      "i_5            645\n",
      "i_3            256\n",
      "i_2            252\n",
      "i_4            248\n",
      "drifted_i_5      1\n",
      "drifted_i_1      1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt2/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt2.\n",
      "item_id\n",
      "i_1            1280\n",
      "i_5            1279\n",
      "i_4             500\n",
      "i_3             500\n",
      "i_2             500\n",
      "drifted_i_5       1\n",
      "drifted_i_1       1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3.\n",
      "item_id\n",
      "i_1            1280\n",
      "i_5            1279\n",
      "i_2             753\n",
      "i_3             749\n",
      "i_4             748\n",
      "drifted_i_1     662\n",
      "drifted_i_5     652\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt5/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt5.\n",
      "item_id\n",
      "i_5            635\n",
      "i_1            619\n",
      "i_4            252\n",
      "i_2            248\n",
      "i_3            244\n",
      "drifted_i_5      1\n",
      "drifted_i_1      1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt6/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt6.\n",
      "item_id\n",
      "drifted_i_1    662\n",
      "drifted_i_5    652\n",
      "i_2            253\n",
      "i_3            249\n",
      "i_4            248\n",
      "i_5              1\n",
      "i_1              1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt7/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt7.\n",
      "item_id\n",
      "drifted_i_5    638\n",
      "drifted_i_1    627\n",
      "i_4            252\n",
      "i_3            251\n",
      "i_2            247\n",
      "i_1              1\n",
      "i_5              1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt8/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt8.\n",
      "item_id\n",
      "drifted_i_1    662\n",
      "drifted_i_5    652\n",
      "i_5            635\n",
      "i_1            619\n",
      "i_2            501\n",
      "i_4            500\n",
      "i_3            493\n",
      "Name: count, dtype: int64\n",
      "Saved file at processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71/saved_dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def validate_folderpath(folderpath):\n",
    "    # print('im validating')\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "        print('Folder created: ', folderpath)\n",
    "\n",
    "\n",
    "def save_picklefile(d, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "\n",
    "    print('Saved file at '+filepath)\n",
    "\n",
    "def load_picklefile(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "    return loaded_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def generate_artificial_random_dataset(n_users,\n",
    "                                       n_items, \n",
    "                                       ts,\n",
    "                                       all_items_seen,\n",
    "                                       random_seed,\n",
    "                                       n_items_to_drift,\n",
    "                                       sudden_drift_start,\n",
    "                                       drift_items_freq_list,\n",
    "                                       non_drift_items_freq_list,\n",
    "                                       save_path,\n",
    "                                       base_filename,\n",
    "                                       bin_size):\n",
    "    \n",
    "    def add_zero_user(df):\n",
    "\n",
    "        df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "        df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "        df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "        df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "        # df.loc[-2] = ['u_-1', 'i_2', ts, 0]\n",
    "        # df.loc[-3] = ['u_-1', 'i_3', ts, 0]\n",
    "        # df.loc[-5] = ['u_0', 'i_4', ts, 0]\n",
    "        df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "        df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        df.sort_values(by='user_id_n', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "        # print('added zero user\\n', df.head())\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def create_folderpath(save_path, base_filename, specs_str):\n",
    "        return save_path+base_filename+'_'+specs_str+'/'\n",
    "    \n",
    "\n",
    "    def save_items_frequencies(n_items_to_drift,\n",
    "                               sudden_drift_start,\n",
    "                               drift_items_freq_list,\n",
    "                               non_drift_items_freq_list,\n",
    "                               save_path, \n",
    "                               base_filename,\n",
    "                               specs_str):\n",
    "        \n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "\n",
    "        d = {'n_items_to_drift': n_items_to_drift,\n",
    "             'sudden_drift_start': sudden_drift_start,\n",
    "             'drift_items_freq_list': drift_items_freq_list,\n",
    "             'non_drift_items_freq_list': non_drift_items_freq_list}\n",
    "\n",
    "        save_picklefile(d, folderpath+'saved_dictionary.pkl')\n",
    "       \n",
    "\n",
    "    \n",
    "    def save_dataset_atomic_file(df, user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "    def add_user0_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "            df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "        \n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_add_user0_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        add_user0_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_sparsity(df):\n",
    "        # df.item_id.groupby([df.user_id, df.item_id]).count().sum() == df.user_id.count()\n",
    "        sparsity = 1 - df.user_id.count()/(df.user_id.nunique()*df.item_id.nunique())\n",
    "        specs_str = str(df.user_id.nunique())+'x'+str(df.item_id.nunique())+'_'+str(round(sparsity, 2))\n",
    "        print('specs_str', specs_str)\n",
    "        return sparsity, specs_str\n",
    "    \n",
    "\n",
    "    def rename_item(row):\n",
    "        if int(row['user_id'].split('_')[1]) > sudden_drift_start and row['item_id'] in renamed_items:\n",
    "            return renamed_items[row['item_id']]\n",
    "        return row['item_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # users_list = [f'u_{i+1}' for i in range(1, n_users)]\n",
    "    users_list = [f'u_{i+1}' for i in range(n_users)]\n",
    "    items_list = [f'i_{j+1}' for j in range(n_items)]\n",
    "\n",
    "\n",
    "    if all_items_seen:\n",
    "\n",
    "        data = []\n",
    "        for user in users_list:\n",
    "            for item in items_list:\n",
    "                data.append({'user_id': user, 'item_id': item, 'timestamp':ts})\n",
    "\n",
    "        all_items_seen_df = pd.DataFrame(data)\n",
    "\n",
    "        # Introduce sudden drift\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}       \n",
    "        \n",
    "\n",
    "        all_items_seen_df['item_id'] = all_items_seen_df.apply(rename_item, axis=1)\n",
    "        # print(all_items_seen_df.item_id.groupby([all_items_seen_df.user_id, all_items_seen_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        \n",
    "        sparsity , specs_str = calculate_sparsity(all_items_seen_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "\n",
    "        sampled_df = add_zero_user(sampled_df)\n",
    "        users_list.insert(0, 'u_0')\n",
    "        \n",
    "\n",
    "        # split_dataset_into_4_and_save_atomic_file(all_items_seen_df,users_list, bin_size, save_path, specs_str)\n",
    "        # save_dataset_atomic_file(all_items_seen_df, save_path, specs_str)\n",
    "        split_dataset_into_4_add_user0_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(drift_items_freq_list) != n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "        elif len(non_drift_items_freq_list) != len(items_list)-n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "\n",
    "\n",
    "        def sample_with_repetition_of_pattern(users_list, items_list, items_freq_list):\n",
    "            random.seed(random_seed)\n",
    "            sampled_df = pd.DataFrame({})\n",
    "            for i, freq in enumerate(items_freq_list):\n",
    "                # print('k ',k)\n",
    "                user_sample = random.sample(users_list[:sudden_drift_start], k=freq) +\\\n",
    "                                random.sample(users_list[sudden_drift_start:], k=freq)\n",
    "                temp_df = pd.DataFrame({'user_id': user_sample, \n",
    "                                        'item_id': items_list[i]})\n",
    "                # print(temp_df.item_id.groupby([temp_df.user_id, temp_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "                sampled_df = pd.concat([sampled_df, temp_df])\n",
    "            \n",
    "            return sampled_df\n",
    "        \n",
    "\n",
    "        # Introduce sudden drift\n",
    "        # No need to random sample, bc the list will have the frequencies for each item\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        # drift_items_list = [items_list[i] for i,x in enumerate(items_freq_list) if x == sudden_drift_start]\n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}\n",
    "        non_drift_items_list = list(set(items_list) - set(drift_items_list))\n",
    "        \n",
    "        print('drift_items_list', drift_items_list)\n",
    "        print('renamed_items', renamed_items)\n",
    "        print('non_drift_items_list', non_drift_items_list)\n",
    "\n",
    "        \n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        sampled_df = sample_with_repetition_of_pattern(users_list,\n",
    "                                                       non_drift_items_list,\n",
    "                                                       non_drift_items_freq_list)\n",
    "        \n",
    "        sampled_df = pd.concat([sampled_df,\n",
    "                                sample_with_repetition_of_pattern(users_list,\n",
    "                                                                    drift_items_list,\n",
    "                                                                    drift_items_freq_list)])\n",
    "\n",
    "        if sampled_df.user_id.nunique() < n_users:\n",
    "            # print(sampled_df.head())\n",
    "            users_not_sampled = list(set(users_list) - set(sampled_df.user_id))\n",
    "            print('users_not_sampled', len(users_not_sampled))\n",
    "            # print('drift_items_list', drift_items_list)\n",
    "            for user in users_not_sampled:\n",
    "                for item in drift_items_list:\n",
    "                    # print(sampled_df.loc[sampled_df['user_id']==user, 'item_id'].count())\n",
    "                    sampled_df.loc[len(sampled_df)] = [user, item]\n",
    "\n",
    "\n",
    "        sampled_df['item_id'] = sampled_df.apply(rename_item, axis=1)\n",
    "        # print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        sampled_df['timestamp'] = ts\n",
    "\n",
    "\n",
    "\n",
    "        sparsity, specs_str = calculate_sparsity(sampled_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "        # print(specs_str)\n",
    "        print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "        # print(sampled_df.head())\n",
    "\n",
    "\n",
    "        # when trainning on pt1, yield ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users.\n",
    "        # sampled_df = add_zero_user(sampled_df) # to solve the error \n",
    "        users_list.insert(0, 'u_0')\n",
    "\n",
    "        # save_dataset_atomic_file(sampled_df, save_path, specs_str)\n",
    "        # split_dataset_into_4_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        split_dataset_into_4_add_user0_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "        return sampled_df\n",
    "\n",
    "# Parameters\n",
    "n_users = 4000 # bc of random sample, some users dont have occurrencies\n",
    "n_items = 5\n",
    "sudden_drift_start = 2000  # Starting user index for drift (1-indexed)\n",
    "bin_size = 1000\n",
    "\n",
    "string = \"24/12/2024 21:12:24\"\n",
    "ts = time.mktime(datetime.strptime(string, \"%d/%m/%Y %H:%M:%S\").timetuple())\n",
    "\n",
    "all_items_seen = False\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "ratio_to_drift = 2 # Select 50% of items to rename\n",
    "n_items_to_drift = n_items // ratio_to_drift\n",
    "\n",
    "base_filename = 'sudden_drift_dataset_u0_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "drift_items_freq_list = [sudden_drift_start//2, sudden_drift_start//2]\n",
    "non_drift_items_freq_list = [sudden_drift_start//4, sudden_drift_start//4, sudden_drift_start//4]\n",
    "\n",
    "df = generate_artificial_random_dataset(n_users=n_users,\n",
    "                                    n_items=n_items, \n",
    "                                    ts=ts,\n",
    "                                    all_items_seen=all_items_seen,\n",
    "                                    n_items_to_drift=n_items_to_drift,\n",
    "                                    random_seed=random_seed,\n",
    "                                    sudden_drift_start=sudden_drift_start,\n",
    "                                    drift_items_freq_list=drift_items_freq_list,\n",
    "                                    non_drift_items_freq_list=non_drift_items_freq_list,\n",
    "                                    save_path=save_path,\n",
    "                                    base_filename=base_filename,\n",
    "                                    bin_size=bin_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, now all parts have all items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "\n",
    "\n",
    "def train_test(model_name,\n",
    "               dataset_name,\n",
    "               parameter_dict):\n",
    "\n",
    "    # configurations initialization\n",
    "    config = Config(model=model_name, dataset=dataset_name, config_dict=parameter_dict)\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = BPR(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = Trainer(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "    print('\\n\\nTraining best results')\n",
    "    print('best_valid_score: ', best_valid_score)\n",
    "    print('best_valid_result: ', best_valid_result)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    \n",
    "    print('\\n\\nTest results')\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test Updated user0 sees i1 i5 i1_drift i5_drift in ALL parts splittage version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = 'sudden_drift_dataset_u0_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "# Current model~~~~\n",
    "base_dataset_name = base_filename+'_4000x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "_pt1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "12 Jan 16:33    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "The number of users: 1001\n",
      "Average actions of users: 2.065\n",
      "The number of items: 8\n",
      "Average actions of items: 295.0\n",
      "The number of inters: 2065\n",
      "The sparsity of the dataset: 74.2132867132867%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "12 Jan 16:33    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "12 Jan 16:33    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "12 Jan 16:33    INFO  BPR(\n",
      "  (user_embedding): Embedding(1001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 64576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 0 training [time: 0.07s, train loss: 0.6935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 0 evaluating [time: 0.08s, valid_score: 0.524000]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.524    mrr@3 : 0.321    ndcg@3 : 0.3727    hit@3 : 0.524    precision@3 : 0.1747\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-12-2025_16-33-35.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 1 training [time: 0.07s, train loss: 0.6896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 1 evaluating [time: 0.14s, valid_score: 0.516600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5166    mrr@3 : 0.3161    ndcg@3 : 0.3672    hit@3 : 0.5166    precision@3 : 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 2 training [time: 0.08s, train loss: 0.6866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 2 evaluating [time: 0.10s, valid_score: 0.516600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5166    mrr@3 : 0.3155    ndcg@3 : 0.3667    hit@3 : 0.5166    precision@3 : 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 3 training [time: 0.15s, train loss: 0.6810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 3 evaluating [time: 0.10s, valid_score: 0.509200]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5092    mrr@3 : 0.313    ndcg@3 : 0.3629    hit@3 : 0.5092    precision@3 : 0.1697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 4 training [time: 0.09s, train loss: 0.6778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 4 evaluating [time: 0.09s, valid_score: 0.501800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5018    mrr@3 : 0.3112    ndcg@3 : 0.3597    hit@3 : 0.5018    precision@3 : 0.1673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 5 training [time: 0.12s, train loss: 0.6746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 5 evaluating [time: 0.09s, valid_score: 0.505500]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5055    mrr@3 : 0.3137    ndcg@3 : 0.3625    hit@3 : 0.5055    precision@3 : 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 6 training [time: 0.08s, train loss: 0.6716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 6 evaluating [time: 0.09s, valid_score: 0.512900]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5129    mrr@3 : 0.3161    ndcg@3 : 0.3662    hit@3 : 0.5129    precision@3 : 0.171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 7 training [time: 0.12s, train loss: 0.6682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 7 evaluating [time: 0.09s, valid_score: 0.505500]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5055    mrr@3 : 0.3161    ndcg@3 : 0.3643    hit@3 : 0.5055    precision@3 : 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 8 training [time: 0.09s, train loss: 0.6630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 8 evaluating [time: 0.09s, valid_score: 0.498200]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4982    mrr@3 : 0.3137    ndcg@3 : 0.3607    hit@3 : 0.4982    precision@3 : 0.1661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 9 training [time: 0.11s, train loss: 0.6603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 9 evaluating [time: 0.09s, valid_score: 0.501800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5018    mrr@3 : 0.3161    ndcg@3 : 0.3634    hit@3 : 0.5018    precision@3 : 0.1673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 10 training [time: 0.07s, train loss: 0.6573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 10 evaluating [time: 0.09s, valid_score: 0.501800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5018    mrr@3 : 0.3137    ndcg@3 : 0.3615    hit@3 : 0.5018    precision@3 : 0.1673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([648, 648, 648,  ..., 223, 847, 807])\n",
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 11 training [time: 0.14s, train loss: 0.6511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   5,   8,   9,  15,  18,  21,  25,  30,  43,  56,  66,  67,  68,\n",
      "         77,  83,  84,  86,  87,  91,  92,  95,  98, 105, 106, 107, 111, 116,\n",
      "        118, 119, 120, 125, 126, 132, 140, 141, 142, 143, 144, 147, 148, 152,\n",
      "        153, 155, 156, 163, 165, 166, 168, 169, 175, 177, 188, 191, 193, 195,\n",
      "        200, 203, 206, 207, 208, 212, 214, 219, 221, 225, 226, 231, 235, 244,\n",
      "        249, 250, 256, 257, 260, 264, 269, 270, 272, 275, 285, 289, 294, 304,\n",
      "        307, 312, 315, 317, 319, 324, 325, 328, 329, 334, 339, 342, 352, 357,\n",
      "        360, 367, 374, 390, 391, 393, 394, 395, 396, 399, 409, 410, 413, 418,\n",
      "        420, 433, 434, 435, 440, 442, 449, 455, 461, 462, 464, 468, 470, 473,\n",
      "        478, 486, 490, 491, 492, 494, 495, 499, 500, 502, 503, 506, 509, 510,\n",
      "        513, 516, 518, 536, 538, 543, 544, 545, 548, 559, 560, 561, 564, 565,\n",
      "        568, 571, 572, 574, 579, 581, 583, 584, 585, 586, 587, 589, 592, 594,\n",
      "        598, 602, 603, 607, 613, 615, 616, 621, 624, 629, 631, 635, 637, 644,\n",
      "        645, 646, 648, 649, 662, 666, 667, 674, 677, 678, 679, 681, 682, 684,\n",
      "        688, 691, 694, 695, 696, 698, 706, 708, 716, 721, 722, 727, 737, 741,\n",
      "        742, 743, 757, 760, 766, 767, 778, 779, 780, 781, 785, 786, 801, 812,\n",
      "        822, 826, 830, 834, 835, 838, 843, 848, 851, 854, 860, 861, 868, 869,\n",
      "        884, 892, 894, 899, 902, 904, 907, 920, 921, 923, 924, 930, 931, 933,\n",
      "        938, 940, 941, 943, 947, 948, 949, 953, 958, 960, 963, 964, 965, 969,\n",
      "        970, 971, 982, 993, 997])\n",
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 11 evaluating [time: 0.11s, valid_score: 0.509200]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5092    mrr@3 : 0.3149    ndcg@3 : 0.3643    hit@3 : 0.5092    precision@3 : 0.1697\n",
      "12 Jan 16:33    INFO  Finished training, best eval result in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.524\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.524), ('mrr@3', 0.321), ('ndcg@3', 0.3727), ('hit@3', 0.524), ('precision@3', 0.1747)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "12 Jan 16:33    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-12-2025_16-33-35.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   3,   5,   6,   7,   8,   9,  10,  11,  12,  15,  16,  17,  18,\n",
      "         19,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,\n",
      "         35,  37,  38,  40,  41,  43,  44,  45,  47,  51,  53,  54,  56,  60,\n",
      "         61,  63,  65,  66,  67,  68,  69,  71,  72,  75,  76,  77,  80,  81,\n",
      "         82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,\n",
      "         97,  98,  99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143,\n",
      "        144, 145, 146, 147, 148, 150, 151, 152, 153, 155, 156, 159, 160, 161,\n",
      "        162, 163, 165, 166, 168, 169, 170, 172, 173, 174, 175, 176, 177, 179,\n",
      "        180, 182, 183, 184, 186, 188, 189, 191, 192, 193, 194, 195, 196, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 211, 212, 214, 215,\n",
      "        217, 218, 219, 221, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236,\n",
      "        237, 238, 242, 244, 246, 247, 248, 249, 250, 251, 254, 255, 256, 257,\n",
      "        259, 260, 261, 262, 263, 264, 266, 268, 269, 270, 271, 272, 273, 274,\n",
      "        275, 277, 278, 279, 280, 283, 285, 286, 287, 289, 292, 294, 295, 296,\n",
      "        297, 299, 300, 301, 302, 303, 304, 307, 308, 310, 312, 314, 315, 317,\n",
      "        318, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 332, 333, 334,\n",
      "        335, 336, 339, 340, 341, 342, 344, 348, 352, 354, 355, 357, 358, 359,\n",
      "        360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376,\n",
      "        377, 379, 381, 382, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "        395, 396, 397, 398, 399, 400, 401, 402, 409, 410, 412, 413, 414, 417,\n",
      "        418, 420, 421, 423, 427, 428, 430, 431, 433, 434, 435, 436, 437, 438,\n",
      "        439, 440, 442, 444, 445, 447, 448, 449, 450, 451, 452, 453, 455, 458,\n",
      "        459, 460, 461, 462, 464, 466, 467, 468, 469, 470, 471, 473, 474, 476,\n",
      "        477, 478, 479, 481, 482, 483, 484, 485, 486, 489, 490, 491, 492, 493,\n",
      "        494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 508, 509, 510,\n",
      "        511, 513, 514, 516, 517, 518, 519, 520, 521, 523, 524, 525, 526, 530,\n",
      "        531, 533, 536, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549,\n",
      "        550, 551, 552, 554, 556, 558, 559, 560, 561, 563, 564, 565, 567, 568,\n",
      "        570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 584,\n",
      "        585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601,\n",
      "        602, 603, 604, 607, 608, 609, 610, 612, 613, 615, 616, 617, 618, 621,\n",
      "        622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 635, 637, 638, 640,\n",
      "        641, 642, 644, 645, 646, 647, 648, 649, 651, 652, 654, 656, 659, 660,\n",
      "        661, 662, 664, 665, 666, 667, 668, 669, 672, 674, 675, 676, 677, 678,\n",
      "        679, 680, 681, 682, 684, 685, 686, 688])\n",
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n",
      "User IDs: tensor([ 690,  691,  693,  694,  695,  696,  698,  699,  702,  704,  705,  706,\n",
      "         708,  709,  712,  713,  714,  715,  716,  718,  719,  720,  721,  722,\n",
      "         723,  724,  725,  727,  728,  729,  730,  731,  732,  733,  735,  737,\n",
      "         740,  741,  742,  743,  744,  745,  747,  748,  749,  755,  757,  758,\n",
      "         759,  760,  764,  766,  767,  769,  773,  774,  776,  777,  778,  779,\n",
      "         780,  781,  782,  783,  785,  786,  787,  788,  790,  791,  792,  793,\n",
      "         794,  796,  801,  802,  803,  805,  808,  809,  811,  812,  814,  815,\n",
      "         816,  817,  818,  819,  821,  822,  823,  825,  826,  828,  830,  833,\n",
      "         834,  835,  838,  839,  843,  844,  845,  848,  851,  852,  853,  854,\n",
      "         855,  856,  857,  859,  860,  861,  862,  864,  866,  867,  868,  869,\n",
      "         872,  873,  877,  878,  879,  880,  881,  884,  887,  892,  894,  895,\n",
      "         896,  898,  899,  901,  902,  904,  906,  907,  908,  909,  911,  915,\n",
      "         916,  918,  919,  920,  921,  922,  923,  924,  925,  926,  927,  928,\n",
      "         929,  930,  931,  932,  933,  934,  935,  937,  938,  939,  940,  941,\n",
      "         942,  943,  944,  947,  948,  949,  951,  953,  954,  956,  958,  959,\n",
      "         960,  963,  964,  965,  969,  970,  971,  974,  975,  976,  977,  978,\n",
      "         980,  982,  987,  988,  989,  993,  994,  995,  996,  997,  998,  999,\n",
      "        1000])\n",
      "User ID Range: 690 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5286), ('mrr@3', 0.3475), ('ndcg@3', 0.3938), ('hit@3', 0.5286), ('precision@3', 0.1762)])\n",
      "\n",
      "\n",
      "_pt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "12 Jan 16:33    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\n",
      "The number of users: 2001\n",
      "Average actions of users: 2.035\n",
      "The number of items: 8\n",
      "Average actions of items: 581.4285714285714\n",
      "The number of inters: 4070\n",
      "The sparsity of the dataset: 74.5752123938031%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "12 Jan 16:33    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "12 Jan 16:33    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "12 Jan 16:33    INFO  BPR(\n",
      "  (user_embedding): Embedding(2001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 128576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 0 training [time: 0.23s, train loss: 1.3858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 0 evaluating [time: 0.18s, valid_score: 0.499000]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.499    mrr@3 : 0.3087    ndcg@3 : 0.3573    hit@3 : 0.499    precision@3 : 0.1663\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\\BPR-Jan-12-2025_16-33-39.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 1 training [time: 0.22s, train loss: 1.3793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 1 evaluating [time: 0.26s, valid_score: 0.497100]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4971    mrr@3 : 0.311    ndcg@3 : 0.3585    hit@3 : 0.4971    precision@3 : 0.1657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 2 training [time: 0.31s, train loss: 1.3626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 2 evaluating [time: 0.22s, valid_score: 0.501000]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.501    mrr@3 : 0.3068    ndcg@3 : 0.3564    hit@3 : 0.501    precision@3 : 0.167\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\\BPR-Jan-12-2025_16-33-39.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 3 training [time: 0.25s, train loss: 1.3526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 3 evaluating [time: 0.20s, valid_score: 0.512600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5126    mrr@3 : 0.312    ndcg@3 : 0.3632    hit@3 : 0.5126    precision@3 : 0.1709\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\\BPR-Jan-12-2025_16-33-39.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 4 training [time: 0.22s, train loss: 1.3460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 4 evaluating [time: 0.19s, valid_score: 0.514600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5146    mrr@3 : 0.3117    ndcg@3 : 0.3634    hit@3 : 0.5146    precision@3 : 0.1715\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\\BPR-Jan-12-2025_16-33-39.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 5 training [time: 0.21s, train loss: 1.3352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 5 evaluating [time: 0.18s, valid_score: 0.512600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5126    mrr@3 : 0.3081    ndcg@3 : 0.3602    hit@3 : 0.5126    precision@3 : 0.1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 6 training [time: 0.22s, train loss: 1.3199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 6 evaluating [time: 0.17s, valid_score: 0.506800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5068    mrr@3 : 0.3013    ndcg@3 : 0.3537    hit@3 : 0.5068    precision@3 : 0.1689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 7 training [time: 0.21s, train loss: 1.3133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 7 evaluating [time: 0.17s, valid_score: 0.508700]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5087    mrr@3 : 0.2987    ndcg@3 : 0.3523    hit@3 : 0.5087    precision@3 : 0.1696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 8 training [time: 0.15s, train loss: 1.3007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 8 evaluating [time: 0.18s, valid_score: 0.495100]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4951    mrr@3 : 0.2935    ndcg@3 : 0.3449    hit@3 : 0.4951    precision@3 : 0.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 9 training [time: 0.17s, train loss: 1.2878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 9 evaluating [time: 0.23s, valid_score: 0.489300]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4893    mrr@3 : 0.2864    ndcg@3 : 0.3381    hit@3 : 0.4893    precision@3 : 0.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 10 training [time: 0.21s, train loss: 1.2758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 10 evaluating [time: 0.22s, valid_score: 0.485400]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4854    mrr@3 : 0.2864    ndcg@3 : 0.3371    hit@3 : 0.4854    precision@3 : 0.1618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 11 training [time: 0.19s, train loss: 1.2644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 11 evaluating [time: 0.19s, valid_score: 0.487400]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4874    mrr@3 : 0.29    ndcg@3 : 0.3403    hit@3 : 0.4874    precision@3 : 0.1625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 12 training [time: 0.23s, train loss: 1.2531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 12 evaluating [time: 0.18s, valid_score: 0.481600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4816    mrr@3 : 0.2877    ndcg@3 : 0.3371    hit@3 : 0.4816    precision@3 : 0.1605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 13 training [time: 0.20s, train loss: 1.2420]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 13 evaluating [time: 0.19s, valid_score: 0.479600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4796    mrr@3 : 0.2864    ndcg@3 : 0.3357    hit@3 : 0.4796    precision@3 : 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 14 training [time: 0.23s, train loss: 1.2327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 14 evaluating [time: 0.18s, valid_score: 0.473800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.4738    mrr@3 : 0.2816    ndcg@3 : 0.3306    hit@3 : 0.4738    precision@3 : 0.1579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1596, 1596, 1514,  ...,   52, 1630, 1666])\n",
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 903, 1889,  426,  245, 1050, 1602, 1664,  784,  158,  937,  917,  143,\n",
      "         182, 1687,  386,  596, 1035,  711,  700,  658, 1997,  652,  776,  763,\n",
      "         754,  233,  746,   94,  991,  236,  346, 1290,  569, 1670, 1805, 1637,\n",
      "        1346, 1586,  318,  599, 1148, 1959, 1100,  595, 1621,  950, 1615, 1174,\n",
      "        1466, 1447, 1483, 1335, 1619, 1697, 1463,  888, 1352, 1654, 1822, 1769,\n",
      "         914, 1684,  194,  429, 1628, 1307,  378,  123, 1863,  258, 1904, 1528,\n",
      "        1194,  330, 1568,  846, 1939, 1566, 1316,  553, 1211,  836,  979,  863,\n",
      "        1407,  403,  578, 1020,  537,  893,  739, 1897, 1507,  422, 1251, 1911])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 15 training [time: 0.19s, train loss: 1.2179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 15 evaluating [time: 0.16s, valid_score: 0.468000]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.468    mrr@3 : 0.2767    ndcg@3 : 0.3254    hit@3 : 0.468    precision@3 : 0.156\n",
      "12 Jan 16:33    INFO  Finished training, best eval result in epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5146\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5146), ('mrr@3', 0.3117), ('ndcg@3', 0.3634), ('hit@3', 0.5146), ('precision@3', 0.1715)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "12 Jan 16:33    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\\BPR-Jan-12-2025_16-33-39.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   3,   5,   6,   7,   8,   9,  10,  11,  12,  15,  16,  17,  18,\n",
      "         19,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,\n",
      "         35,  37,  38,  40,  41,  43,  44,  45,  47,  51,  53,  54,  56,  60,\n",
      "         61,  63,  65,  66,  67,  68,  69,  71,  72,  75,  76,  77,  80,  81,\n",
      "         82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,\n",
      "         97,  98,  99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143,\n",
      "        144, 145, 146, 147, 148, 150, 151, 152, 153, 155, 156, 159, 160, 161,\n",
      "        162, 163, 165, 166, 168, 169, 170, 172, 173, 174, 175, 176, 177, 179,\n",
      "        180, 182, 183, 184, 186, 188, 189, 191, 192, 193, 194, 195, 196, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 211, 212, 214, 215,\n",
      "        217, 218, 219, 221, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236,\n",
      "        237, 238, 242, 244, 246, 247, 248, 249, 250, 251, 254, 255, 256, 257,\n",
      "        259, 260, 261, 262, 263, 264, 266, 268, 269, 270, 271, 272, 273, 274,\n",
      "        275, 277, 278, 279, 280, 283, 285, 286, 287, 289, 292, 294, 295, 296,\n",
      "        297, 299, 300, 301, 302, 303, 304, 307, 308, 310, 312, 314, 315, 317,\n",
      "        318, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 332, 333, 334,\n",
      "        335, 336, 339, 340, 341, 342, 344, 348, 352, 354, 355, 357, 358, 359,\n",
      "        360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376,\n",
      "        377, 379, 381, 382, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "        395, 396, 397, 398, 399, 400, 401, 402, 409, 410, 412, 413, 414, 417,\n",
      "        418, 420, 421, 423, 427, 428, 430, 431, 433, 434, 435, 436, 437, 438,\n",
      "        439, 440, 442, 444, 445, 447, 448, 449, 450, 451, 452, 453, 455, 458,\n",
      "        459, 460, 461, 462, 464, 466, 467, 468, 469, 470, 471, 473, 474, 476,\n",
      "        477, 478, 479, 481, 482, 483, 484, 485, 486, 489, 490, 491, 492, 493,\n",
      "        494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 508, 509, 510,\n",
      "        511, 513, 514, 516, 517, 518, 519, 520, 521, 523, 524, 525, 526, 530,\n",
      "        531, 533, 536, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549,\n",
      "        550, 551, 552, 554, 556, 558, 559, 560, 561, 563, 564, 565, 567, 568,\n",
      "        570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 584,\n",
      "        585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601,\n",
      "        602, 603, 604, 607, 608, 609, 610, 612, 613, 615, 616, 617, 618, 621,\n",
      "        622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 635, 637, 638, 640,\n",
      "        641, 642, 644, 645, 646, 647, 648, 649, 651, 652, 654, 656, 659, 660,\n",
      "        661, 662, 664, 665, 666, 667, 668, 669, 672, 674, 675, 676, 677, 678,\n",
      "        679, 680, 681, 682, 684, 685, 686, 688])\n",
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([ 690,  691,  693,  694,  695,  696,  698,  699,  702,  704,  705,  706,\n",
      "         708,  709,  712,  713,  714,  715,  716,  718,  719,  720,  721,  722,\n",
      "         723,  724,  725,  727,  728,  729,  730,  731,  732,  733,  735,  737,\n",
      "         740,  741,  742,  743,  744,  745,  747,  748,  749,  755,  757,  758,\n",
      "         759,  760,  764,  766,  767,  769,  773,  774,  776,  777,  778,  779,\n",
      "         780,  781,  782,  783,  785,  786,  787,  788,  790,  791,  792,  793,\n",
      "         794,  796,  801,  802,  803,  805,  808,  809,  811,  812,  814,  815,\n",
      "         816,  817,  818,  819,  821,  822,  823,  825,  826,  828,  830,  833,\n",
      "         834,  835,  838,  839,  843,  844,  845,  848,  851,  852,  853,  854,\n",
      "         855,  856,  857,  859,  860,  861,  862,  864,  866,  867,  868,  869,\n",
      "         872,  873,  877,  878,  879,  880,  881,  884,  887,  892,  894,  895,\n",
      "         896,  898,  899,  901,  902,  904,  906,  907,  908,  909,  911,  915,\n",
      "         916,  918,  919,  920,  921,  922,  923,  924,  925,  926,  927,  928,\n",
      "         929,  930,  931,  932,  933,  934,  935,  937,  938,  939,  940,  941,\n",
      "         942,  943,  944,  947,  948,  949,  951,  953,  954,  956,  958,  959,\n",
      "         960,  963,  964,  965,  969,  970,  971,  974,  975,  976,  977,  978,\n",
      "         980,  982,  987,  988,  989,  993,  994,  995,  996,  997,  998,  999,\n",
      "        1000, 1001, 1002, 1005, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1016,\n",
      "        1019, 1021, 1022, 1024, 1025, 1026, 1027, 1030, 1031, 1035, 1036, 1037,\n",
      "        1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1047, 1051, 1053, 1054,\n",
      "        1057, 1059, 1060, 1061, 1062, 1063, 1064, 1068, 1069, 1071, 1072, 1073,\n",
      "        1074, 1075, 1076, 1077, 1079, 1081, 1082, 1084, 1085, 1088, 1089, 1090,\n",
      "        1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1101, 1103, 1105, 1106,\n",
      "        1107, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120,\n",
      "        1122, 1123, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1135, 1136,\n",
      "        1137, 1138, 1140, 1141, 1142, 1144, 1145, 1146, 1147, 1150, 1151, 1154,\n",
      "        1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1167, 1168, 1169, 1170,\n",
      "        1171, 1173, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1187,\n",
      "        1188, 1189, 1191, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1202, 1203,\n",
      "        1206, 1207, 1208, 1211, 1212, 1214, 1215, 1216, 1218, 1219, 1220, 1222,\n",
      "        1223, 1224, 1225, 1226, 1227, 1228, 1230, 1232, 1233, 1234, 1235, 1236,\n",
      "        1238, 1240, 1241, 1243, 1244, 1246, 1248, 1249, 1250, 1253, 1254, 1255,\n",
      "        1256, 1257, 1258, 1259, 1261, 1262, 1264, 1266, 1267, 1268, 1270, 1271,\n",
      "        1273, 1274, 1276, 1277, 1278, 1279, 1280, 1282, 1284, 1285, 1286, 1287,\n",
      "        1288, 1289, 1291, 1293, 1294, 1295, 1296, 1297, 1298, 1300, 1301, 1302,\n",
      "        1303, 1304, 1305, 1306, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1318,\n",
      "        1319, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1331, 1332,\n",
      "        1336, 1337, 1338, 1340, 1341, 1342, 1343, 1344, 1345, 1347, 1348, 1349,\n",
      "        1351, 1353, 1356, 1357, 1358, 1360, 1361, 1362, 1366, 1367, 1369, 1370,\n",
      "        1371, 1372, 1373, 1374, 1375, 1377, 1381, 1383, 1384, 1387, 1389, 1392,\n",
      "        1393, 1395, 1396, 1397, 1398, 1400, 1401, 1402, 1404, 1405, 1406, 1408,\n",
      "        1409, 1410, 1411, 1412, 1414, 1416, 1418, 1420, 1421, 1423, 1424, 1425,\n",
      "        1426, 1428, 1429, 1431, 1432, 1433, 1434, 1435])\n",
      "User ID Range: 690 to 1435\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User IDs: tensor([1438, 1439, 1440, 1441, 1442, 1443, 1444, 1446, 1448, 1449, 1450, 1451,\n",
      "        1452, 1453, 1455, 1456, 1459, 1460, 1461, 1462, 1463, 1464, 1468, 1471,\n",
      "        1472, 1473, 1474, 1475, 1478, 1480, 1482, 1483, 1484, 1485, 1491, 1493,\n",
      "        1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1506, 1507, 1508,\n",
      "        1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1522,\n",
      "        1523, 1524, 1525, 1526, 1527, 1529, 1531, 1532, 1533, 1535, 1536, 1537,\n",
      "        1539, 1541, 1543, 1545, 1546, 1548, 1549, 1551, 1554, 1555, 1556, 1557,\n",
      "        1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1569, 1570, 1572, 1573,\n",
      "        1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1584, 1585, 1588, 1590,\n",
      "        1591, 1592, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1604, 1606, 1607,\n",
      "        1608, 1609, 1610, 1614, 1615, 1616, 1622, 1623, 1624, 1626, 1629, 1631,\n",
      "        1632, 1633, 1634, 1636, 1638, 1641, 1642, 1643, 1644, 1648, 1650, 1651,\n",
      "        1652, 1654, 1655, 1656, 1659, 1660, 1663, 1668, 1669, 1671, 1672, 1673,\n",
      "        1675, 1676, 1677, 1679, 1681, 1682, 1683, 1685, 1688, 1689, 1692, 1693,\n",
      "        1694, 1695, 1699, 1700, 1701, 1702, 1703, 1705, 1707, 1708, 1709, 1710,\n",
      "        1711, 1713, 1714, 1715, 1716, 1718, 1719, 1724, 1725, 1726, 1727, 1728,\n",
      "        1729, 1730, 1731, 1732, 1734, 1735, 1736, 1737, 1739, 1740, 1741, 1742,\n",
      "        1743, 1746, 1748, 1750, 1751, 1752, 1753, 1754, 1756, 1757, 1758, 1759,\n",
      "        1760, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1773, 1774, 1776, 1777,\n",
      "        1778, 1779, 1780, 1781, 1782, 1784, 1786, 1787, 1788, 1790, 1791, 1794,\n",
      "        1795, 1796, 1797, 1799, 1800, 1801, 1806, 1808, 1813, 1814, 1815, 1816,\n",
      "        1817, 1818, 1819, 1820, 1821, 1823, 1824, 1825, 1826, 1827, 1828, 1829,\n",
      "        1830, 1831, 1832, 1833, 1835, 1836, 1837, 1838, 1840, 1841, 1842, 1843,\n",
      "        1847, 1848, 1849, 1850, 1852, 1854, 1855, 1856, 1859, 1860, 1862, 1864,\n",
      "        1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876,\n",
      "        1877, 1881, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1891, 1892,\n",
      "        1895, 1896, 1898, 1899, 1900, 1901, 1902, 1906, 1907, 1908, 1915, 1916,\n",
      "        1917, 1919, 1920, 1921, 1922, 1923, 1924, 1926, 1927, 1929, 1930, 1932,\n",
      "        1933, 1934, 1938, 1940, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949,\n",
      "        1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1961, 1962, 1963,\n",
      "        1964, 1965, 1966, 1967, 1969, 1970, 1971, 1973, 1974, 1975, 1976, 1977,\n",
      "        1978, 1980, 1981, 1982, 1984, 1985, 1987, 1988, 1990, 1991, 1992, 1993,\n",
      "        1994, 1996, 2000])\n",
      "User ID Range: 1438 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5018), ('mrr@3', 0.3044), ('ndcg@3', 0.3548), ('hit@3', 0.5018), ('precision@3', 0.1673)])\n",
      "\n",
      "\n",
      "_pt3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "12 Jan 16:33    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\n",
      "The number of users: 3001\n",
      "Average actions of users: 2.0436666666666667\n",
      "The number of items: 8\n",
      "Average actions of items: 875.8571428571429\n",
      "The number of inters: 6131\n",
      "The sparsity of the dataset: 74.46267910696434%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "12 Jan 16:33    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "12 Jan 16:33    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "12 Jan 16:33    INFO  BPR(\n",
      "  (user_embedding): Embedding(3001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 192576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 0 training [time: 0.20s, train loss: 1.3850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 0 evaluating [time: 0.21s, valid_score: 0.530800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5308    mrr@3 : 0.3274    ndcg@3 : 0.3792    hit@3 : 0.5308    precision@3 : 0.1769\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-12-2025_16-33-48.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 1 training [time: 0.21s, train loss: 1.3751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 1 evaluating [time: 0.22s, valid_score: 0.537200]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5372    mrr@3 : 0.331    ndcg@3 : 0.3836    hit@3 : 0.5372    precision@3 : 0.1791\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-12-2025_16-33-48.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 2 training [time: 0.19s, train loss: 1.3646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 2 evaluating [time: 0.24s, valid_score: 0.535900]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5359    mrr@3 : 0.3248    ndcg@3 : 0.3786    hit@3 : 0.5359    precision@3 : 0.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 3 training [time: 0.26s, train loss: 1.3537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 3 evaluating [time: 0.22s, valid_score: 0.541000]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.541    mrr@3 : 0.3263    ndcg@3 : 0.381    hit@3 : 0.541    precision@3 : 0.1803\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-12-2025_16-33-48.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 4 training [time: 0.24s, train loss: 1.3432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 4 evaluating [time: 0.21s, valid_score: 0.543600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5436    mrr@3 : 0.3288    ndcg@3 : 0.3836    hit@3 : 0.5436    precision@3 : 0.1812\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-12-2025_16-33-48.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 5 training [time: 0.23s, train loss: 1.3310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 5 evaluating [time: 0.20s, valid_score: 0.542300]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5423    mrr@3 : 0.3261    ndcg@3 : 0.3813    hit@3 : 0.5423    precision@3 : 0.1808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 6 training [time: 0.24s, train loss: 1.3208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 6 evaluating [time: 0.19s, valid_score: 0.546200]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5462    mrr@3 : 0.3267    ndcg@3 : 0.3827    hit@3 : 0.5462    precision@3 : 0.1821\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-12-2025_16-33-48.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 7 training [time: 0.17s, train loss: 1.3107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 7 evaluating [time: 0.20s, valid_score: 0.533300]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3239    ndcg@3 : 0.3773    hit@3 : 0.5333    precision@3 : 0.1778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 8 training [time: 0.28s, train loss: 1.2994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 8 evaluating [time: 0.22s, valid_score: 0.529500]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5295    mrr@3 : 0.3278    ndcg@3 : 0.3792    hit@3 : 0.5295    precision@3 : 0.1765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 9 training [time: 0.23s, train loss: 1.2877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 9 evaluating [time: 0.21s, valid_score: 0.521800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5218    mrr@3 : 0.3231    ndcg@3 : 0.3738    hit@3 : 0.5218    precision@3 : 0.1739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 10 training [time: 0.22s, train loss: 1.2752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 10 evaluating [time: 0.22s, valid_score: 0.523100]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5231    mrr@3 : 0.3212    ndcg@3 : 0.3727    hit@3 : 0.5231    precision@3 : 0.1744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 11 training [time: 0.23s, train loss: 1.2629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 11 evaluating [time: 0.21s, valid_score: 0.521800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5218    mrr@3 : 0.3177    ndcg@3 : 0.3698    hit@3 : 0.5218    precision@3 : 0.1739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 12 training [time: 0.18s, train loss: 1.2502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 12 evaluating [time: 0.25s, valid_score: 0.512800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5128    mrr@3 : 0.3137    ndcg@3 : 0.3645    hit@3 : 0.5128    precision@3 : 0.1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 13 training [time: 0.20s, train loss: 1.2381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 13 evaluating [time: 0.26s, valid_score: 0.502600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5026    mrr@3 : 0.3064    ndcg@3 : 0.3564    hit@3 : 0.5026    precision@3 : 0.1675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 14 training [time: 0.20s, train loss: 1.2262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 14 evaluating [time: 0.27s, valid_score: 0.507700]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5077    mrr@3 : 0.3068    ndcg@3 : 0.3581    hit@3 : 0.5077    precision@3 : 0.1692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 15 training [time: 0.20s, train loss: 1.2124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 15 evaluating [time: 0.26s, valid_score: 0.503800]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5038    mrr@3 : 0.3053    ndcg@3 : 0.356    hit@3 : 0.5038    precision@3 : 0.1679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 16 training [time: 0.19s, train loss: 1.1989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 16 evaluating [time: 0.25s, valid_score: 0.500000]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5    mrr@3 : 0.3041    ndcg@3 : 0.3541    hit@3 : 0.5    precision@3 : 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([1131, 1107, 1107,  ..., 2229, 1359, 1373])\n",
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2199, 2943, 2943,  ...,  282, 2042,  692])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 17 training [time: 0.18s, train loss: 1.1856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 17 evaluating [time: 0.24s, valid_score: 0.501300]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5013    mrr@3 : 0.3036    ndcg@3 : 0.354    hit@3 : 0.5013    precision@3 : 0.1671\n",
      "12 Jan 16:33    INFO  Finished training, best eval result in epoch 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5462\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5462), ('mrr@3', 0.3267), ('ndcg@3', 0.3827), ('hit@3', 0.5462), ('precision@3', 0.1821)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "12 Jan 16:33    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-12-2025_16-33-48.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   3,   5,   6,   7,   8,   9,  10,  11,  12,  15,  16,  17,  18,\n",
      "         19,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,\n",
      "         35,  37,  38,  40,  41,  43,  44,  45,  47,  51,  53,  54,  56,  60,\n",
      "         61,  63,  65,  66,  67,  68,  69,  71,  72,  75,  76,  77,  80,  81,\n",
      "         82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,\n",
      "         97,  98,  99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143,\n",
      "        144, 145, 146, 147, 148, 150, 151, 152, 153, 155, 156, 159, 160, 161,\n",
      "        162, 163, 165, 166, 168, 169, 170, 172, 173, 174, 175, 176, 177, 179,\n",
      "        180, 182, 183, 184, 186, 188, 189, 191, 192, 193, 194, 195, 196, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 211, 212, 214, 215,\n",
      "        217, 218, 219, 221, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236,\n",
      "        237, 238, 242, 244, 246, 247, 248, 249, 250, 251, 254, 255, 256, 257,\n",
      "        259, 260, 261, 262, 263, 264, 266, 268, 269, 270, 271, 272, 273, 274,\n",
      "        275, 277, 278, 279, 280, 283, 285, 286, 287, 289, 292, 294, 295, 296,\n",
      "        297, 299, 300, 301, 302, 303, 304, 307, 308, 310, 312, 314, 315, 317,\n",
      "        318, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 332, 333, 334,\n",
      "        335, 336, 339, 340, 341, 342, 344, 348, 352, 354, 355, 357, 358, 359,\n",
      "        360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376,\n",
      "        377, 379, 381, 382, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "        395, 396, 397, 398, 399, 400, 401, 402, 409, 410, 412, 413, 414, 417,\n",
      "        418, 420, 421, 423, 427, 428, 430, 431, 433, 434, 435, 436, 437, 438,\n",
      "        439, 440, 442, 444, 445, 447, 448, 449, 450, 451, 452, 453, 455, 458,\n",
      "        459, 460, 461, 462, 464, 466, 467, 468, 469, 470, 471, 473, 474, 476,\n",
      "        477, 478, 479, 481, 482, 483, 484, 485, 486, 489, 490, 491, 492, 493,\n",
      "        494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 508, 509, 510,\n",
      "        511, 513, 514, 516, 517, 518, 519, 520, 521, 523, 524, 525, 526, 530,\n",
      "        531, 533, 536, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549,\n",
      "        550, 551, 552, 554, 556, 558, 559, 560, 561, 563, 564, 565, 567, 568,\n",
      "        570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 584,\n",
      "        585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601,\n",
      "        602, 603, 604, 607, 608, 609, 610, 612, 613, 615, 616, 617, 618, 621,\n",
      "        622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 635, 637, 638, 640,\n",
      "        641, 642, 644, 645, 646, 647, 648, 649, 651, 652, 654, 656, 659, 660,\n",
      "        661, 662, 664, 665, 666, 667, 668, 669, 672, 674, 675, 676, 677, 678,\n",
      "        679, 680, 681, 682, 684, 685, 686, 688])\n",
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([ 690,  691,  693,  694,  695,  696,  698,  699,  702,  704,  705,  706,\n",
      "         708,  709,  712,  713,  714,  715,  716,  718,  719,  720,  721,  722,\n",
      "         723,  724,  725,  727,  728,  729,  730,  731,  732,  733,  735,  737,\n",
      "         740,  741,  742,  743,  744,  745,  747,  748,  749,  755,  757,  758,\n",
      "         759,  760,  764,  766,  767,  769,  773,  774,  776,  777,  778,  779,\n",
      "         780,  781,  782,  783,  785,  786,  787,  788,  790,  791,  792,  793,\n",
      "         794,  796,  801,  802,  803,  805,  808,  809,  811,  812,  814,  815,\n",
      "         816,  817,  818,  819,  821,  822,  823,  825,  826,  828,  830,  833,\n",
      "         834,  835,  838,  839,  843,  844,  845,  848,  851,  852,  853,  854,\n",
      "         855,  856,  857,  859,  860,  861,  862,  864,  866,  867,  868,  869,\n",
      "         872,  873,  877,  878,  879,  880,  881,  884,  887,  892,  894,  895,\n",
      "         896,  898,  899,  901,  902,  904,  906,  907,  908,  909,  911,  915,\n",
      "         916,  918,  919,  920,  921,  922,  923,  924,  925,  926,  927,  928,\n",
      "         929,  930,  931,  932,  933,  934,  935,  937,  938,  939,  940,  941,\n",
      "         942,  943,  944,  947,  948,  949,  951,  953,  954,  956,  958,  959,\n",
      "         960,  963,  964,  965,  969,  970,  971,  974,  975,  976,  977,  978,\n",
      "         980,  982,  987,  988,  989,  993,  994,  995,  996,  997,  998,  999,\n",
      "        1000, 1001, 1002, 1005, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1016,\n",
      "        1019, 1021, 1022, 1024, 1025, 1026, 1027, 1030, 1031, 1035, 1036, 1037,\n",
      "        1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1047, 1051, 1053, 1054,\n",
      "        1057, 1059, 1060, 1061, 1062, 1063, 1064, 1068, 1069, 1071, 1072, 1073,\n",
      "        1074, 1075, 1076, 1077, 1079, 1081, 1082, 1084, 1085, 1088, 1089, 1090,\n",
      "        1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1101, 1103, 1105, 1106,\n",
      "        1107, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120,\n",
      "        1122, 1123, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1135, 1136,\n",
      "        1137, 1138, 1140, 1141, 1142, 1144, 1145, 1146, 1147, 1150, 1151, 1154,\n",
      "        1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1167, 1168, 1169, 1170,\n",
      "        1171, 1173, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1187,\n",
      "        1188, 1189, 1191, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1202, 1203,\n",
      "        1206, 1207, 1208, 1211, 1212, 1214, 1215, 1216, 1218, 1219, 1220, 1222,\n",
      "        1223, 1224, 1225, 1226, 1227, 1228, 1230, 1232, 1233, 1234, 1235, 1236,\n",
      "        1238, 1240, 1241, 1243, 1244, 1246, 1248, 1249, 1250, 1253, 1254, 1255,\n",
      "        1256, 1257, 1258, 1259, 1261, 1262, 1264, 1266, 1267, 1268, 1270, 1271,\n",
      "        1273, 1274, 1276, 1277, 1278, 1279, 1280, 1282, 1284, 1285, 1286, 1287,\n",
      "        1288, 1289, 1291, 1293, 1294, 1295, 1296, 1297, 1298, 1300, 1301, 1302,\n",
      "        1303, 1304, 1305, 1306, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1318,\n",
      "        1319, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1331, 1332,\n",
      "        1336, 1337, 1338, 1340, 1341, 1342, 1343, 1344, 1345, 1347, 1348, 1349,\n",
      "        1351, 1353, 1356, 1357, 1358, 1360, 1361, 1362, 1366, 1367, 1369, 1370,\n",
      "        1371, 1372, 1373, 1374, 1375, 1377, 1381, 1383, 1384, 1387, 1389, 1392,\n",
      "        1393, 1395, 1396, 1397, 1398, 1400, 1401, 1402, 1404, 1405, 1406, 1408,\n",
      "        1409, 1410, 1411, 1412, 1414, 1416, 1418, 1420, 1421, 1423, 1424, 1425,\n",
      "        1426, 1428, 1429, 1431, 1432, 1433, 1434, 1435])\n",
      "User ID Range: 690 to 1435\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([1438, 1439, 1440, 1441, 1442, 1443, 1444, 1446, 1448, 1449, 1450, 1451,\n",
      "        1452, 1453, 1455, 1456, 1459, 1460, 1461, 1462, 1463, 1464, 1468, 1471,\n",
      "        1472, 1473, 1474, 1475, 1478, 1480, 1482, 1483, 1484, 1485, 1491, 1493,\n",
      "        1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1506, 1507, 1508,\n",
      "        1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1522,\n",
      "        1523, 1524, 1525, 1526, 1527, 1529, 1531, 1532, 1533, 1535, 1536, 1537,\n",
      "        1539, 1541, 1543, 1545, 1546, 1548, 1549, 1551, 1554, 1555, 1556, 1557,\n",
      "        1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1569, 1570, 1572, 1573,\n",
      "        1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1584, 1585, 1588, 1590,\n",
      "        1591, 1592, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1604, 1606, 1607,\n",
      "        1608, 1609, 1610, 1614, 1615, 1616, 1622, 1623, 1624, 1626, 1629, 1631,\n",
      "        1632, 1633, 1634, 1636, 1638, 1641, 1642, 1643, 1644, 1648, 1650, 1651,\n",
      "        1652, 1654, 1655, 1656, 1659, 1660, 1663, 1668, 1669, 1671, 1672, 1673,\n",
      "        1675, 1676, 1677, 1679, 1681, 1682, 1683, 1685, 1688, 1689, 1692, 1693,\n",
      "        1694, 1695, 1699, 1700, 1701, 1702, 1703, 1705, 1707, 1708, 1709, 1710,\n",
      "        1711, 1713, 1714, 1715, 1716, 1718, 1719, 1724, 1725, 1726, 1727, 1728,\n",
      "        1729, 1730, 1731, 1732, 1734, 1735, 1736, 1737, 1739, 1740, 1741, 1742,\n",
      "        1743, 1746, 1748, 1750, 1751, 1752, 1753, 1754, 1756, 1757, 1758, 1759,\n",
      "        1760, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1773, 1774, 1776, 1777,\n",
      "        1778, 1779, 1780, 1781, 1782, 1784, 1786, 1787, 1788, 1790, 1791, 1794,\n",
      "        1795, 1796, 1797, 1799, 1800, 1801, 1806, 1808, 1813, 1814, 1815, 1816,\n",
      "        1817, 1818, 1819, 1820, 1821, 1823, 1824, 1825, 1826, 1827, 1828, 1829,\n",
      "        1830, 1831, 1832, 1833, 1835, 1836, 1837, 1838, 1840, 1841, 1842, 1843,\n",
      "        1847, 1848, 1849, 1850, 1852, 1854, 1855, 1856, 1859, 1860, 1862, 1864,\n",
      "        1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876,\n",
      "        1877, 1881, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1891, 1892,\n",
      "        1895, 1896, 1898, 1899, 1900, 1901, 1902, 1906, 1907, 1908, 1915, 1916,\n",
      "        1917, 1919, 1920, 1921, 1922, 1923, 1924, 1926, 1927, 1929, 1930, 1932,\n",
      "        1933, 1934, 1938, 1940, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949,\n",
      "        1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1961, 1962, 1963,\n",
      "        1964, 1965, 1966, 1967, 1969, 1970, 1971, 1973, 1974, 1975, 1976, 1977,\n",
      "        1978, 1980, 1981, 1982, 1984, 1985, 1987, 1988, 1990, 1991, 1992, 1993,\n",
      "        1994, 1996, 2000, 2001, 2004, 2006, 2007, 2008, 2009, 2010, 2014, 2016,\n",
      "        2017, 2018, 2021, 2022, 2024, 2027, 2028, 2029, 2030, 2031, 2032, 2034,\n",
      "        2036, 2038, 2040, 2045, 2046, 2047, 2050, 2051, 2052, 2053, 2054, 2055,\n",
      "        2056, 2057, 2060, 2061, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070,\n",
      "        2071, 2072, 2075, 2076, 2077, 2078, 2080, 2081, 2082, 2083, 2084, 2085,\n",
      "        2086, 2087, 2088, 2090, 2091, 2092, 2094, 2095, 2096, 2098, 2099, 2100,\n",
      "        2101, 2102, 2103, 2105, 2107, 2108, 2109, 2111, 2112, 2113, 2114, 2115,\n",
      "        2116, 2121, 2122, 2124, 2126, 2127, 2129, 2131, 2132, 2135, 2136, 2138,\n",
      "        2139, 2141, 2142, 2143, 2144, 2146, 2150, 2151, 2152, 2153, 2155, 2156,\n",
      "        2157, 2159, 2160, 2161, 2163, 2164, 2167, 2168, 2169, 2171, 2172, 2173,\n",
      "        2174, 2175, 2176, 2178, 2179, 2183, 2186, 2188])\n",
      "User ID Range: 1438 to 2188\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2189, 2190, 2191, 2192, 2193, 2194, 2196, 2198, 2199, 2200, 2201, 2203,\n",
      "        2204, 2205, 2207, 2208, 2209, 2210, 2212, 2213, 2214, 2215, 2216, 2217,\n",
      "        2218, 2220, 2222, 2223, 2225, 2227, 2228, 2229, 2230, 2234, 2235, 2236,\n",
      "        2237, 2238, 2239, 2240, 2242, 2243, 2244, 2245, 2246, 2247, 2250, 2251,\n",
      "        2252, 2255, 2256, 2257, 2259, 2260, 2261, 2263, 2264, 2266, 2268, 2269,\n",
      "        2271, 2272, 2275, 2276, 2277, 2278, 2279, 2281, 2282, 2283, 2284, 2285,\n",
      "        2286, 2288, 2290, 2291, 2292, 2294, 2295, 2297, 2298, 2299, 2300, 2301,\n",
      "        2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2314,\n",
      "        2315, 2317, 2318, 2320, 2321, 2322, 2324, 2325, 2327, 2328, 2329, 2332,\n",
      "        2333, 2334, 2335, 2336, 2337, 2338, 2340, 2341, 2342, 2343, 2346, 2348,\n",
      "        2349, 2352, 2354, 2355, 2356, 2358, 2359, 2361, 2363, 2364, 2366, 2369,\n",
      "        2370, 2371, 2373, 2374, 2375, 2377, 2378, 2380, 2381, 2383, 2388, 2389,\n",
      "        2390, 2391, 2392, 2393, 2395, 2396, 2398, 2400, 2403, 2405, 2406, 2407,\n",
      "        2409, 2410, 2411, 2413, 2414, 2415, 2417, 2418, 2420, 2421, 2422, 2424,\n",
      "        2425, 2426, 2427, 2428, 2429, 2430, 2434, 2435, 2436, 2437, 2439, 2440,\n",
      "        2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2450, 2452, 2453, 2455,\n",
      "        2456, 2460, 2461, 2462, 2464, 2465, 2466, 2468, 2469, 2470, 2471, 2473,\n",
      "        2474, 2475, 2477, 2478, 2479, 2480, 2481, 2482, 2485, 2486, 2487, 2489,\n",
      "        2490, 2491, 2492, 2493, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502,\n",
      "        2503, 2504, 2505, 2508, 2509, 2510, 2511, 2513, 2514, 2515, 2516, 2518,\n",
      "        2520, 2521, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2532, 2533, 2536,\n",
      "        2537, 2538, 2541, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2551, 2556,\n",
      "        2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569,\n",
      "        2571, 2572, 2574, 2582, 2583, 2584, 2585, 2587, 2588, 2589, 2591, 2593,\n",
      "        2594, 2597, 2599, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612,\n",
      "        2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624,\n",
      "        2625, 2626, 2627, 2628, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637,\n",
      "        2638, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2648, 2650, 2651, 2652,\n",
      "        2653, 2654, 2655, 2656, 2659, 2661, 2662, 2663, 2664, 2665, 2666, 2667,\n",
      "        2668, 2670, 2671, 2672, 2673, 2674, 2675, 2677, 2679, 2680, 2681, 2682,\n",
      "        2683, 2684, 2685, 2686, 2687, 2688, 2690, 2692, 2693, 2695, 2696, 2697,\n",
      "        2698, 2700, 2702, 2705, 2706, 2708, 2709, 2710, 2713, 2714, 2716, 2718,\n",
      "        2719, 2720, 2721, 2722, 2723, 2725, 2726, 2727, 2728, 2731, 2732, 2733,\n",
      "        2735, 2736, 2737, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749,\n",
      "        2750, 2751, 2753, 2754, 2755, 2756, 2757, 2759, 2760, 2761, 2762, 2763,\n",
      "        2765, 2766, 2768, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778,\n",
      "        2779, 2780, 2781, 2782, 2783, 2785, 2786, 2787, 2788, 2789, 2790, 2791,\n",
      "        2792, 2793, 2794, 2796, 2797, 2798, 2799, 2800, 2801, 2804, 2806, 2808,\n",
      "        2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821,\n",
      "        2822, 2824, 2826, 2827, 2828, 2830, 2831, 2833, 2835, 2837, 2838, 2839,\n",
      "        2841, 2843, 2845, 2846, 2847, 2849, 2850, 2851, 2852, 2853, 2856, 2858,\n",
      "        2859, 2860, 2861, 2863, 2864, 2867, 2868, 2869, 2870, 2872, 2873, 2875,\n",
      "        2876, 2880, 2881, 2882, 2883, 2884, 2886, 2890])\n",
      "User ID Range: 2189 to 2890\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User IDs: tensor([2891, 2892, 2894, 2895, 2897, 2899, 2900, 2901, 2902, 2903, 2904, 2905,\n",
      "        2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2915, 2918, 2919, 2920,\n",
      "        2921, 2922, 2923, 2924, 2925, 2926, 2927, 2929, 2930, 2931, 2932, 2933,\n",
      "        2934, 2936, 2937, 2938, 2940, 2941, 2943, 2944, 2945, 2947, 2948, 2951,\n",
      "        2952, 2953, 2954, 2955, 2956, 2959, 2960, 2961, 2965, 2967, 2973, 2974,\n",
      "        2975, 2976, 2977, 2978, 2979, 2982, 2984, 2987, 2988, 2989, 2990, 2991,\n",
      "        2993, 2994, 2996, 2998, 2999, 3000])\n",
      "User ID Range: 2891 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5245), ('mrr@3', 0.3171), ('ndcg@3', 0.37), ('hit@3', 0.5245), ('precision@3', 0.1748)])\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "12 Jan 16:33    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71\n",
      "The number of users: 4002\n",
      "Average actions of users: 2.0359910022494376\n",
      "The number of items: 8\n",
      "Average actions of items: 1163.7142857142858\n",
      "The number of inters: 8146\n",
      "The sparsity of the dataset: 74.55647176411794%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "12 Jan 16:33    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "12 Jan 16:33    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "12 Jan 16:33    INFO  BPR(\n",
      "  (user_embedding): Embedding(4002, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 256640\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 0 training [time: 0.26s, train loss: 2.0803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 0 evaluating [time: 0.25s, valid_score: 0.514600]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5146    mrr@3 : 0.3123    ndcg@3 : 0.3639    hit@3 : 0.5146    precision@3 : 0.1715\n",
      "12 Jan 16:33    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-12-2025_16-33-58.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 1 training [time: 0.30s, train loss: 2.0590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:33    INFO  epoch 1 evaluating [time: 0.28s, valid_score: 0.503900]\n",
      "12 Jan 16:33    INFO  valid result: \n",
      "recall@3 : 0.5039    mrr@3 : 0.3083    ndcg@3 : 0.3582    hit@3 : 0.5039    precision@3 : 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 2 training [time: 0.36s, train loss: 2.0414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 2 evaluating [time: 0.24s, valid_score: 0.504900]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.5049    mrr@3 : 0.3062    ndcg@3 : 0.3568    hit@3 : 0.5049    precision@3 : 0.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 3 training [time: 0.35s, train loss: 2.0187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 3 evaluating [time: 0.25s, valid_score: 0.502900]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.5029    mrr@3 : 0.3044    ndcg@3 : 0.355    hit@3 : 0.5029    precision@3 : 0.1676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 4 training [time: 0.35s, train loss: 2.0016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 4 evaluating [time: 0.26s, valid_score: 0.505900]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.5059    mrr@3 : 0.3032    ndcg@3 : 0.3548    hit@3 : 0.5059    precision@3 : 0.1686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 5 training [time: 0.30s, train loss: 1.9811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 5 evaluating [time: 0.30s, valid_score: 0.503900]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.5039    mrr@3 : 0.3029    ndcg@3 : 0.3541    hit@3 : 0.5039    precision@3 : 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 6 training [time: 0.34s, train loss: 1.9603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 6 evaluating [time: 0.26s, valid_score: 0.497100]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.4971    mrr@3 : 0.3016    ndcg@3 : 0.3513    hit@3 : 0.4971    precision@3 : 0.1657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 7 training [time: 0.37s, train loss: 1.9374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 7 evaluating [time: 0.28s, valid_score: 0.500000]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.5    mrr@3 : 0.3008    ndcg@3 : 0.3514    hit@3 : 0.5    precision@3 : 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 8 training [time: 0.31s, train loss: 1.9144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 8 evaluating [time: 0.29s, valid_score: 0.504900]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.5049    mrr@3 : 0.3011    ndcg@3 : 0.3529    hit@3 : 0.5049    precision@3 : 0.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 9 training [time: 0.35s, train loss: 1.8953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 9 evaluating [time: 0.24s, valid_score: 0.494100]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.4941    mrr@3 : 0.2977    ndcg@3 : 0.3477    hit@3 : 0.4941    precision@3 : 0.1647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 10 training [time: 0.35s, train loss: 1.8713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 10 evaluating [time: 0.27s, valid_score: 0.488300]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.4883    mrr@3 : 0.2951    ndcg@3 : 0.3443    hit@3 : 0.4883    precision@3 : 0.1628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([ 397, 3444, 3145,  ..., 2182, 1795, 3068])\n",
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2907,  284, 2952,  ..., 1094, 3705, 3096])\n",
      "User ID Range: 6 to 4001\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1918,  832, 1995, 2133, 1170, 2336, 2935, 1909, 3893,  475,  761, 1920,\n",
      "         738, 1553, 1944,  392,  857, 2803, 1070,  638, 2647,  819,  354, 3786,\n",
      "        3700, 2130, 2485, 1334, 2738,  359,  403,  325, 2347, 1538, 2238,  437,\n",
      "         180, 1646, 2888,  438, 3071, 3330,  979, 3740,  290, 2035, 1029, 2603,\n",
      "         352,  291, 2467, 3581, 2862, 2062, 3821, 2946, 1048, 2367, 2959, 2600,\n",
      "        1589, 1379,  346, 3610, 2353, 2540,  444, 1528,  820, 3640, 1552, 1521,\n",
      "          52, 3716, 2649, 2254, 3785, 2973,  853, 3689, 1664,  456, 1156,  950,\n",
      "        3154, 1487, 2742, 2525, 3290, 2581, 1467, 2506, 2211, 3126, 3091, 2362,\n",
      "        3817, 1939,  855, 3917,  338, 2986, 2676,  458, 2914, 3446,   49, 1657,\n",
      "         750, 3292, 3688,  164,    4, 3284, 1822,  945, 2575, 1763, 3454, 2982,\n",
      "        3721,  807, 1014, 1053, 2221, 2969, 2120,  454, 2431, 1185, 2043, 1998,\n",
      "        3240,  345, 1960, 1010, 1635, 2365, 1812,  966, 1297,  404,  885, 2523,\n",
      "         967, 1479, 2669, 2898, 1181, 3983, 3768, 3529,  789, 2848, 1299, 1894,\n",
      "        3879,  252, 2093,  957, 1662,  313, 2020, 1800, 1628, 3510, 3380,   48,\n",
      "        3495,  158, 3556, 3855, 1941, 2769, 2274, 2280, 3988,  123, 1149, 1295,\n",
      "        3313, 3925, 1209, 2857, 1717,  893,  991, 1959])\n",
      "User ID Range: 4 to 3988\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 11 training [time: 0.34s, train loss: 1.8465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    5,    8,    9,   15,   18,   21,   25,   30,   43,   56,   66,\n",
      "          67,   68,   77,   83,   84,   86,   87,   91,   92,   95,   98,  105,\n",
      "         106,  107,  111,  116,  118,  119,  120,  125,  126,  132,  140,  141,\n",
      "         142,  143,  144,  147,  148,  152,  153,  155,  156,  163,  165,  166,\n",
      "         168,  169,  175,  177,  188,  191,  193,  195,  200,  203,  206,  207,\n",
      "         208,  212,  214,  219,  221,  225,  226,  231,  235,  244,  249,  250,\n",
      "         256,  257,  260,  264,  269,  270,  272,  275,  285,  289,  294,  304,\n",
      "         307,  312,  315,  317,  319,  324,  325,  328,  329,  334,  339,  342,\n",
      "         352,  357,  360,  367,  374,  390,  391,  393,  394,  395,  396,  399,\n",
      "         409,  410,  413,  418,  420,  433,  434,  435,  440,  442,  449,  455,\n",
      "         461,  462,  464,  468,  470,  473,  478,  486,  490,  491,  492,  494,\n",
      "         495,  499,  500,  502,  503,  506,  509,  510,  513,  516,  518,  536,\n",
      "         538,  543,  544,  545,  548,  559,  560,  561,  564,  565,  568,  571,\n",
      "         572,  574,  579,  581,  583,  584,  585,  586,  587,  589,  592,  594,\n",
      "         598,  602,  603,  607,  613,  615,  616,  621,  624,  629,  631,  635,\n",
      "         637,  644,  645,  646,  648,  649,  662,  666,  667,  674,  677,  678,\n",
      "         679,  681,  682,  684,  688,  691,  694,  695,  696,  698,  706,  708,\n",
      "         716,  721,  722,  727,  737,  741,  742,  743,  757,  760,  766,  767,\n",
      "         778,  779,  780,  781,  785,  786,  801,  812,  822,  826,  830,  834,\n",
      "         835,  838,  843,  848,  851,  854,  860,  861,  868,  869,  884,  892,\n",
      "         894,  899,  902,  904,  907,  920,  921,  923,  924,  930,  931,  933,\n",
      "         938,  940,  941,  943,  947,  948,  949,  953,  958,  960,  963,  964,\n",
      "         965,  969,  970,  971,  982,  993,  997, 1002, 1007, 1013, 1024, 1026,\n",
      "        1031, 1037, 1040, 1041, 1042, 1045, 1057, 1061, 1072, 1076, 1079, 1082,\n",
      "        1085, 1088, 1089, 1092, 1095, 1099, 1101, 1105, 1106, 1107, 1112, 1114,\n",
      "        1118, 1120, 1129, 1132, 1135, 1136, 1137, 1140, 1144, 1146, 1161, 1163,\n",
      "        1179, 1182, 1184, 1188, 1193, 1196, 1197, 1207, 1208, 1220, 1222, 1224,\n",
      "        1238, 1240, 1243, 1244, 1250, 1254, 1261, 1262, 1267, 1268, 1274, 1277,\n",
      "        1278, 1282, 1287, 1291, 1294, 1302, 1303, 1310, 1311, 1312, 1314, 1315,\n",
      "        1318, 1322, 1323, 1324, 1325, 1329, 1332, 1337, 1341, 1344, 1348, 1351,\n",
      "        1353, 1356, 1357, 1358, 1360, 1361, 1362, 1369, 1372, 1374, 1377, 1381,\n",
      "        1384, 1387, 1395, 1398, 1401, 1404, 1409, 1411, 1414, 1418, 1438, 1439,\n",
      "        1441, 1442, 1443, 1444, 1451, 1455, 1459, 1462, 1468, 1471, 1472, 1473,\n",
      "        1475, 1478, 1485, 1493, 1495, 1498, 1508, 1510, 1514, 1527, 1529, 1531,\n",
      "        1532, 1533, 1535, 1539, 1548, 1551, 1556, 1559, 1562, 1563, 1564, 1570,\n",
      "        1572, 1573, 1575, 1576, 1577, 1580, 1588, 1591, 1596, 1599, 1607, 1608,\n",
      "        1609, 1615, 1622, 1624, 1634, 1650, 1656, 1671, 1673, 1682, 1685, 1688,\n",
      "        1693, 1694, 1695, 1699, 1700, 1701, 1705, 1707, 1708, 1711, 1714, 1725,\n",
      "        1737, 1740, 1742, 1746, 1748, 1753, 1756, 1765, 1766, 1770, 1771, 1776,\n",
      "        1778, 1784, 1787, 1791, 1796, 1808, 1818, 1819, 1826, 1827, 1829, 1840,\n",
      "        1843, 1854, 1856, 1859, 1866, 1870, 1871, 1874, 1888, 1890, 1891, 1895,\n",
      "        1900, 1901, 1915, 1919, 1921, 1934, 1940, 1942, 1943, 1945, 1948, 1949,\n",
      "        1950, 1955, 1956, 1958, 1969, 1975, 1982, 1984])\n",
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1985, 1994, 2000, 2007, 2014, 2018, 2021, 2030, 2034, 2050, 2054, 2055,\n",
      "        2056, 2061, 2064, 2065, 2069, 2078, 2083, 2084, 2086, 2094, 2095, 2096,\n",
      "        2105, 2107, 2108, 2109, 2114, 2115, 2124, 2129, 2131, 2132, 2136, 2139,\n",
      "        2142, 2144, 2151, 2152, 2153, 2155, 2156, 2159, 2163, 2167, 2169, 2173,\n",
      "        2175, 2176, 2186, 2188, 2189, 2192, 2193, 2196, 2199, 2200, 2201, 2205,\n",
      "        2212, 2214, 2218, 2220, 2223, 2225, 2227, 2234, 2235, 2236, 2237, 2239,\n",
      "        2250, 2252, 2256, 2260, 2261, 2272, 2279, 2282, 2283, 2286, 2288, 2290,\n",
      "        2292, 2297, 2304, 2305, 2310, 2314, 2315, 2317, 2318, 2320, 2324, 2325,\n",
      "        2327, 2334, 2338, 2355, 2358, 2359, 2361, 2371, 2390, 2391, 2409, 2413,\n",
      "        2422, 2426, 2434, 2435, 2442, 2443, 2446, 2450, 2453, 2461, 2462, 2464,\n",
      "        2465, 2469, 2479, 2482, 2485, 2486, 2487, 2489, 2495, 2500, 2501, 2509,\n",
      "        2510, 2513, 2514, 2515, 2518, 2524, 2538, 2543, 2545, 2548, 2549, 2559,\n",
      "        2560, 2561, 2564, 2567, 2569, 2571, 2572, 2574, 2582, 2583, 2588, 2589,\n",
      "        2593, 2594, 2606, 2607, 2614, 2615, 2619, 2620, 2622, 2624, 2625, 2633,\n",
      "        2635, 2637, 2640, 2642, 2661, 2662, 2666, 2667, 2671, 2672, 2673, 2674,\n",
      "        2680, 2682, 2688, 2693, 2696, 2700, 2708, 2709, 2720, 2721, 2722, 2726,\n",
      "        2727, 2735, 2737, 2743, 2744, 2747, 2749, 2751, 2754, 2756, 2757, 2760,\n",
      "        2761, 2765, 2768, 2772, 2780, 2785, 2786, 2788, 2797, 2812, 2817, 2818,\n",
      "        2822, 2824, 2833, 2837, 2838, 2843, 2845, 2849, 2850, 2851, 2852, 2853,\n",
      "        2860, 2861, 2864, 2868, 2875, 2882, 2883, 2884, 2886, 2899, 2902, 2906,\n",
      "        2907, 2911, 2912, 2922, 2923, 2924, 2925, 2927, 2930, 2933, 2934, 2937,\n",
      "        2940, 2943, 2947, 2952, 2954, 2965, 2967, 2973, 2977, 2982, 2989, 2991,\n",
      "        2993, 2994, 2996, 2998, 3001, 3004, 3006, 3020, 3026, 3029, 3037, 3040,\n",
      "        3044, 3045, 3051, 3057, 3062, 3063, 3064, 3069, 3075, 3088, 3089, 3092,\n",
      "        3100, 3102, 3104, 3106, 3108, 3119, 3120, 3128, 3131, 3133, 3137, 3142,\n",
      "        3143, 3150, 3152, 3156, 3158, 3161, 3169, 3173, 3177, 3179, 3180, 3181,\n",
      "        3185, 3194, 3204, 3205, 3207, 3214, 3217, 3221, 3223, 3224, 3225, 3229,\n",
      "        3231, 3241, 3242, 3243, 3244, 3245, 3251, 3253, 3261, 3262, 3267, 3270,\n",
      "        3271, 3273, 3278, 3280, 3282, 3286, 3287, 3291, 3298, 3302, 3303, 3308,\n",
      "        3310, 3311, 3315, 3316, 3318, 3319, 3322, 3328, 3331, 3332, 3335, 3342,\n",
      "        3344, 3348, 3349, 3350, 3351, 3352, 3355, 3357, 3358, 3359, 3367, 3375,\n",
      "        3378, 3379, 3382, 3383, 3389, 3390, 3393, 3396, 3398, 3403, 3408, 3412,\n",
      "        3416, 3422, 3423, 3428, 3434, 3437, 3443, 3447, 3453, 3473, 3475, 3476,\n",
      "        3478, 3485, 3490, 3491, 3501, 3505, 3507, 3521, 3525, 3528, 3530, 3532,\n",
      "        3546, 3549, 3568, 3569, 3572, 3587, 3595, 3602, 3611, 3612, 3614, 3616,\n",
      "        3627, 3631, 3634, 3637, 3643, 3648, 3649, 3652, 3653, 3655, 3663, 3665,\n",
      "        3667, 3671, 3674, 3677, 3679, 3682, 3683, 3686, 3690, 3692, 3699, 3708,\n",
      "        3711, 3712, 3733, 3734, 3737, 3738, 3746, 3749, 3750, 3761, 3763, 3764,\n",
      "        3766, 3771, 3783, 3786, 3798, 3802, 3807, 3810, 3812, 3819, 3820, 3825,\n",
      "        3827, 3835, 3839, 3844, 3848, 3851, 3852, 3853, 3858, 3860, 3862, 3866,\n",
      "        3870, 3875, 3878, 3889, 3891, 3906, 3908, 3915, 3919, 3921, 3926, 3927,\n",
      "        3932, 3937, 3939, 3943, 3950, 3951, 3956, 3965, 3967, 3968, 3969, 3972,\n",
      "        3973, 3974, 3975, 3979, 3987, 3991, 3995, 3999])\n",
      "User ID Range: 1985 to 3999\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  epoch 11 evaluating [time: 0.29s, valid_score: 0.486300]\n",
      "12 Jan 16:34    INFO  valid result: \n",
      "recall@3 : 0.4863    mrr@3 : 0.2957    ndcg@3 : 0.3443    hit@3 : 0.4863    precision@3 : 0.1621\n",
      "12 Jan 16:34    INFO  Finished training, best eval result in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5146\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5146), ('mrr@3', 0.3123), ('ndcg@3', 0.3639), ('hit@3', 0.5146), ('precision@3', 0.1715)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "12 Jan 16:34    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-12-2025_16-33-58.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([  1,   3,   5,   6,   7,   8,   9,  10,  11,  12,  15,  16,  17,  18,\n",
      "         19,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,\n",
      "         35,  37,  38,  40,  41,  43,  44,  45,  47,  51,  53,  54,  56,  60,\n",
      "         61,  63,  65,  66,  67,  68,  69,  71,  72,  75,  76,  77,  80,  81,\n",
      "         82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  95,  96,\n",
      "         97,  98,  99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127,\n",
      "        128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 141, 142, 143,\n",
      "        144, 145, 146, 147, 148, 150, 151, 152, 153, 155, 156, 159, 160, 161,\n",
      "        162, 163, 165, 166, 168, 169, 170, 172, 173, 174, 175, 176, 177, 179,\n",
      "        180, 182, 183, 184, 186, 188, 189, 191, 192, 193, 194, 195, 196, 198,\n",
      "        199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 211, 212, 214, 215,\n",
      "        217, 218, 219, 221, 225, 226, 228, 229, 230, 231, 232, 234, 235, 236,\n",
      "        237, 238, 242, 244, 246, 247, 248, 249, 250, 251, 254, 255, 256, 257,\n",
      "        259, 260, 261, 262, 263, 264, 266, 268, 269, 270, 271, 272, 273, 274,\n",
      "        275, 277, 278, 279, 280, 283, 285, 286, 287, 289, 292, 294, 295, 296,\n",
      "        297, 299, 300, 301, 302, 303, 304, 307, 308, 310, 312, 314, 315, 317,\n",
      "        318, 319, 320, 321, 322, 323, 324, 325, 327, 328, 329, 332, 333, 334,\n",
      "        335, 336, 339, 340, 341, 342, 344, 348, 352, 354, 355, 357, 358, 359,\n",
      "        360, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 374, 375, 376,\n",
      "        377, 379, 381, 382, 384, 385, 387, 388, 389, 390, 391, 392, 393, 394,\n",
      "        395, 396, 397, 398, 399, 400, 401, 402, 409, 410, 412, 413, 414, 417,\n",
      "        418, 420, 421, 423, 427, 428, 430, 431, 433, 434, 435, 436, 437, 438,\n",
      "        439, 440, 442, 444, 445, 447, 448, 449, 450, 451, 452, 453, 455, 458,\n",
      "        459, 460, 461, 462, 464, 466, 467, 468, 469, 470, 471, 473, 474, 476,\n",
      "        477, 478, 479, 481, 482, 483, 484, 485, 486, 489, 490, 491, 492, 493,\n",
      "        494, 495, 496, 497, 499, 500, 501, 502, 503, 506, 507, 508, 509, 510,\n",
      "        511, 513, 514, 516, 517, 518, 519, 520, 521, 523, 524, 525, 526, 530,\n",
      "        531, 533, 536, 538, 539, 540, 541, 542, 543, 544, 545, 547, 548, 549,\n",
      "        550, 551, 552, 554, 556, 558, 559, 560, 561, 563, 564, 565, 567, 568,\n",
      "        570, 571, 572, 573, 574, 575, 576, 577, 579, 580, 581, 582, 583, 584,\n",
      "        585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 597, 598, 600, 601,\n",
      "        602, 603, 604, 607, 608, 609, 610, 612, 613, 615, 616, 617, 618, 621,\n",
      "        622, 623, 624, 625, 626, 627, 628, 629, 631, 633, 635, 637, 638, 640,\n",
      "        641, 642, 644, 645, 646, 647, 648, 649, 651, 652, 654, 656, 659, 660,\n",
      "        661, 662, 664, 665, 666, 667, 668, 669, 672, 674, 675, 676, 677, 678,\n",
      "        679, 680, 681, 682, 684, 685, 686, 688])\n",
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([ 690,  691,  693,  694,  695,  696,  698,  699,  702,  704,  705,  706,\n",
      "         708,  709,  712,  713,  714,  715,  716,  718,  719,  720,  721,  722,\n",
      "         723,  724,  725,  727,  728,  729,  730,  731,  732,  733,  735,  737,\n",
      "         740,  741,  742,  743,  744,  745,  747,  748,  749,  755,  757,  758,\n",
      "         759,  760,  764,  766,  767,  769,  773,  774,  776,  777,  778,  779,\n",
      "         780,  781,  782,  783,  785,  786,  787,  788,  790,  791,  792,  793,\n",
      "         794,  796,  801,  802,  803,  805,  808,  809,  811,  812,  814,  815,\n",
      "         816,  817,  818,  819,  821,  822,  823,  825,  826,  828,  830,  833,\n",
      "         834,  835,  838,  839,  843,  844,  845,  848,  851,  852,  853,  854,\n",
      "         855,  856,  857,  859,  860,  861,  862,  864,  866,  867,  868,  869,\n",
      "         872,  873,  877,  878,  879,  880,  881,  884,  887,  892,  894,  895,\n",
      "         896,  898,  899,  901,  902,  904,  906,  907,  908,  909,  911,  915,\n",
      "         916,  918,  919,  920,  921,  922,  923,  924,  925,  926,  927,  928,\n",
      "         929,  930,  931,  932,  933,  934,  935,  937,  938,  939,  940,  941,\n",
      "         942,  943,  944,  947,  948,  949,  951,  953,  954,  956,  958,  959,\n",
      "         960,  963,  964,  965,  969,  970,  971,  974,  975,  976,  977,  978,\n",
      "         980,  982,  987,  988,  989,  993,  994,  995,  996,  997,  998,  999,\n",
      "        1000, 1001, 1002, 1005, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1016,\n",
      "        1019, 1021, 1022, 1024, 1025, 1026, 1027, 1030, 1031, 1035, 1036, 1037,\n",
      "        1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1047, 1051, 1053, 1054,\n",
      "        1057, 1059, 1060, 1061, 1062, 1063, 1064, 1068, 1069, 1071, 1072, 1073,\n",
      "        1074, 1075, 1076, 1077, 1079, 1081, 1082, 1084, 1085, 1088, 1089, 1090,\n",
      "        1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1101, 1103, 1105, 1106,\n",
      "        1107, 1109, 1110, 1111, 1112, 1113, 1114, 1116, 1117, 1118, 1119, 1120,\n",
      "        1122, 1123, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1135, 1136,\n",
      "        1137, 1138, 1140, 1141, 1142, 1144, 1145, 1146, 1147, 1150, 1151, 1154,\n",
      "        1155, 1156, 1157, 1159, 1160, 1161, 1162, 1163, 1167, 1168, 1169, 1170,\n",
      "        1171, 1173, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1187,\n",
      "        1188, 1189, 1191, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1202, 1203,\n",
      "        1206, 1207, 1208, 1211, 1212, 1214, 1215, 1216, 1218, 1219, 1220, 1222,\n",
      "        1223, 1224, 1225, 1226, 1227, 1228, 1230, 1232, 1233, 1234, 1235, 1236,\n",
      "        1238, 1240, 1241, 1243, 1244, 1246, 1248, 1249, 1250, 1253, 1254, 1255,\n",
      "        1256, 1257, 1258, 1259, 1261, 1262, 1264, 1266, 1267, 1268, 1270, 1271,\n",
      "        1273, 1274, 1276, 1277, 1278, 1279, 1280, 1282, 1284, 1285, 1286, 1287,\n",
      "        1288, 1289, 1291, 1293, 1294, 1295, 1296, 1297, 1298, 1300, 1301, 1302,\n",
      "        1303, 1304, 1305, 1306, 1308, 1309, 1310, 1311, 1312, 1314, 1315, 1318,\n",
      "        1319, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1331, 1332,\n",
      "        1336, 1337, 1338, 1340, 1341, 1342, 1343, 1344, 1345, 1347, 1348, 1349,\n",
      "        1351, 1353, 1356, 1357, 1358, 1360, 1361, 1362, 1366, 1367, 1369, 1370,\n",
      "        1371, 1372, 1373, 1374, 1375, 1377, 1381, 1383, 1384, 1387, 1389, 1392,\n",
      "        1393, 1395, 1396, 1397, 1398, 1400, 1401, 1402, 1404, 1405, 1406, 1408,\n",
      "        1409, 1410, 1411, 1412, 1414, 1416, 1418, 1420, 1421, 1423, 1424, 1425,\n",
      "        1426, 1428, 1429, 1431, 1432, 1433, 1434, 1435])\n",
      "User ID Range: 690 to 1435\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([1438, 1439, 1440, 1441, 1442, 1443, 1444, 1446, 1448, 1449, 1450, 1451,\n",
      "        1452, 1453, 1455, 1456, 1459, 1460, 1461, 1462, 1463, 1464, 1468, 1471,\n",
      "        1472, 1473, 1474, 1475, 1478, 1480, 1482, 1483, 1484, 1485, 1491, 1493,\n",
      "        1495, 1496, 1497, 1498, 1500, 1501, 1502, 1503, 1504, 1506, 1507, 1508,\n",
      "        1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1522,\n",
      "        1523, 1524, 1525, 1526, 1527, 1529, 1531, 1532, 1533, 1535, 1536, 1537,\n",
      "        1539, 1541, 1543, 1545, 1546, 1548, 1549, 1551, 1554, 1555, 1556, 1557,\n",
      "        1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1569, 1570, 1572, 1573,\n",
      "        1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1584, 1585, 1588, 1590,\n",
      "        1591, 1592, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1604, 1606, 1607,\n",
      "        1608, 1609, 1610, 1614, 1615, 1616, 1622, 1623, 1624, 1626, 1629, 1631,\n",
      "        1632, 1633, 1634, 1636, 1638, 1641, 1642, 1643, 1644, 1648, 1650, 1651,\n",
      "        1652, 1654, 1655, 1656, 1659, 1660, 1663, 1668, 1669, 1671, 1672, 1673,\n",
      "        1675, 1676, 1677, 1679, 1681, 1682, 1683, 1685, 1688, 1689, 1692, 1693,\n",
      "        1694, 1695, 1699, 1700, 1701, 1702, 1703, 1705, 1707, 1708, 1709, 1710,\n",
      "        1711, 1713, 1714, 1715, 1716, 1718, 1719, 1724, 1725, 1726, 1727, 1728,\n",
      "        1729, 1730, 1731, 1732, 1734, 1735, 1736, 1737, 1739, 1740, 1741, 1742,\n",
      "        1743, 1746, 1748, 1750, 1751, 1752, 1753, 1754, 1756, 1757, 1758, 1759,\n",
      "        1760, 1764, 1765, 1766, 1767, 1768, 1770, 1771, 1773, 1774, 1776, 1777,\n",
      "        1778, 1779, 1780, 1781, 1782, 1784, 1786, 1787, 1788, 1790, 1791, 1794,\n",
      "        1795, 1796, 1797, 1799, 1800, 1801, 1806, 1808, 1813, 1814, 1815, 1816,\n",
      "        1817, 1818, 1819, 1820, 1821, 1823, 1824, 1825, 1826, 1827, 1828, 1829,\n",
      "        1830, 1831, 1832, 1833, 1835, 1836, 1837, 1838, 1840, 1841, 1842, 1843,\n",
      "        1847, 1848, 1849, 1850, 1852, 1854, 1855, 1856, 1859, 1860, 1862, 1864,\n",
      "        1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876,\n",
      "        1877, 1881, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1891, 1892,\n",
      "        1895, 1896, 1898, 1899, 1900, 1901, 1902, 1906, 1907, 1908, 1915, 1916,\n",
      "        1917, 1919, 1920, 1921, 1922, 1923, 1924, 1926, 1927, 1929, 1930, 1932,\n",
      "        1933, 1934, 1938, 1940, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949,\n",
      "        1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1961, 1962, 1963,\n",
      "        1964, 1965, 1966, 1967, 1969, 1970, 1971, 1973, 1974, 1975, 1976, 1977,\n",
      "        1978, 1980, 1981, 1982, 1984, 1985, 1987, 1988, 1990, 1991, 1992, 1993,\n",
      "        1994, 1996, 2000, 2001, 2004, 2006, 2007, 2008, 2009, 2010, 2014, 2016,\n",
      "        2017, 2018, 2021, 2022, 2024, 2027, 2028, 2029, 2030, 2031, 2032, 2034,\n",
      "        2036, 2038, 2040, 2045, 2046, 2047, 2050, 2051, 2052, 2053, 2054, 2055,\n",
      "        2056, 2057, 2060, 2061, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070,\n",
      "        2071, 2072, 2075, 2076, 2077, 2078, 2080, 2081, 2082, 2083, 2084, 2085,\n",
      "        2086, 2087, 2088, 2090, 2091, 2092, 2094, 2095, 2096, 2098, 2099, 2100,\n",
      "        2101, 2102, 2103, 2105, 2107, 2108, 2109, 2111, 2112, 2113, 2114, 2115,\n",
      "        2116, 2121, 2122, 2124, 2126, 2127, 2129, 2131, 2132, 2135, 2136, 2138,\n",
      "        2139, 2141, 2142, 2143, 2144, 2146, 2150, 2151, 2152, 2153, 2155, 2156,\n",
      "        2157, 2159, 2160, 2161, 2163, 2164, 2167, 2168, 2169, 2171, 2172, 2173,\n",
      "        2174, 2175, 2176, 2178, 2179, 2183, 2186, 2188])\n",
      "User ID Range: 1438 to 2188\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2189, 2190, 2191, 2192, 2193, 2194, 2196, 2198, 2199, 2200, 2201, 2203,\n",
      "        2204, 2205, 2207, 2208, 2209, 2210, 2212, 2213, 2214, 2215, 2216, 2217,\n",
      "        2218, 2220, 2222, 2223, 2225, 2227, 2228, 2229, 2230, 2234, 2235, 2236,\n",
      "        2237, 2238, 2239, 2240, 2242, 2243, 2244, 2245, 2246, 2247, 2250, 2251,\n",
      "        2252, 2255, 2256, 2257, 2259, 2260, 2261, 2263, 2264, 2266, 2268, 2269,\n",
      "        2271, 2272, 2275, 2276, 2277, 2278, 2279, 2281, 2282, 2283, 2284, 2285,\n",
      "        2286, 2288, 2290, 2291, 2292, 2294, 2295, 2297, 2298, 2299, 2300, 2301,\n",
      "        2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2314,\n",
      "        2315, 2317, 2318, 2320, 2321, 2322, 2324, 2325, 2327, 2328, 2329, 2332,\n",
      "        2333, 2334, 2335, 2336, 2337, 2338, 2340, 2341, 2342, 2343, 2346, 2348,\n",
      "        2349, 2352, 2354, 2355, 2356, 2358, 2359, 2361, 2363, 2364, 2366, 2369,\n",
      "        2370, 2371, 2373, 2374, 2375, 2377, 2378, 2380, 2381, 2383, 2388, 2389,\n",
      "        2390, 2391, 2392, 2393, 2395, 2396, 2398, 2400, 2403, 2405, 2406, 2407,\n",
      "        2409, 2410, 2411, 2413, 2414, 2415, 2417, 2418, 2420, 2421, 2422, 2424,\n",
      "        2425, 2426, 2427, 2428, 2429, 2430, 2434, 2435, 2436, 2437, 2439, 2440,\n",
      "        2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2450, 2452, 2453, 2455,\n",
      "        2456, 2460, 2461, 2462, 2464, 2465, 2466, 2468, 2469, 2470, 2471, 2473,\n",
      "        2474, 2475, 2477, 2478, 2479, 2480, 2481, 2482, 2485, 2486, 2487, 2489,\n",
      "        2490, 2491, 2492, 2493, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502,\n",
      "        2503, 2504, 2505, 2508, 2509, 2510, 2511, 2513, 2514, 2515, 2516, 2518,\n",
      "        2520, 2521, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2532, 2533, 2536,\n",
      "        2537, 2538, 2541, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2551, 2556,\n",
      "        2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569,\n",
      "        2571, 2572, 2574, 2582, 2583, 2584, 2585, 2587, 2588, 2589, 2591, 2593,\n",
      "        2594, 2597, 2599, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612,\n",
      "        2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624,\n",
      "        2625, 2626, 2627, 2628, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637,\n",
      "        2638, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2648, 2650, 2651, 2652,\n",
      "        2653, 2654, 2655, 2656, 2659, 2661, 2662, 2663, 2664, 2665, 2666, 2667,\n",
      "        2668, 2670, 2671, 2672, 2673, 2674, 2675, 2677, 2679, 2680, 2681, 2682,\n",
      "        2683, 2684, 2685, 2686, 2687, 2688, 2690, 2692, 2693, 2695, 2696, 2697,\n",
      "        2698, 2700, 2702, 2705, 2706, 2708, 2709, 2710, 2713, 2714, 2716, 2718,\n",
      "        2719, 2720, 2721, 2722, 2723, 2725, 2726, 2727, 2728, 2731, 2732, 2733,\n",
      "        2735, 2736, 2737, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749,\n",
      "        2750, 2751, 2753, 2754, 2755, 2756, 2757, 2759, 2760, 2761, 2762, 2763,\n",
      "        2765, 2766, 2768, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778,\n",
      "        2779, 2780, 2781, 2782, 2783, 2785, 2786, 2787, 2788, 2789, 2790, 2791,\n",
      "        2792, 2793, 2794, 2796, 2797, 2798, 2799, 2800, 2801, 2804, 2806, 2808,\n",
      "        2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821,\n",
      "        2822, 2824, 2826, 2827, 2828, 2830, 2831, 2833, 2835, 2837, 2838, 2839,\n",
      "        2841, 2843, 2845, 2846, 2847, 2849, 2850, 2851, 2852, 2853, 2856, 2858,\n",
      "        2859, 2860, 2861, 2863, 2864, 2867, 2868, 2869, 2870, 2872, 2873, 2875,\n",
      "        2876, 2880, 2881, 2882, 2883, 2884, 2886, 2890])\n",
      "User ID Range: 2189 to 2890\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([2891, 2892, 2894, 2895, 2897, 2899, 2900, 2901, 2902, 2903, 2904, 2905,\n",
      "        2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2915, 2918, 2919, 2920,\n",
      "        2921, 2922, 2923, 2924, 2925, 2926, 2927, 2929, 2930, 2931, 2932, 2933,\n",
      "        2934, 2936, 2937, 2938, 2940, 2941, 2943, 2944, 2945, 2947, 2948, 2951,\n",
      "        2952, 2953, 2954, 2955, 2956, 2959, 2960, 2961, 2965, 2967, 2973, 2974,\n",
      "        2975, 2976, 2977, 2978, 2979, 2982, 2984, 2987, 2988, 2989, 2990, 2991,\n",
      "        2993, 2994, 2996, 2998, 2999, 3000, 3001, 3003, 3004, 3005, 3006, 3007,\n",
      "        3008, 3009, 3010, 3013, 3015, 3016, 3018, 3019, 3020, 3021, 3022, 3024,\n",
      "        3026, 3028, 3029, 3030, 3031, 3032, 3033, 3035, 3036, 3037, 3040, 3041,\n",
      "        3043, 3044, 3045, 3047, 3048, 3049, 3050, 3051, 3053, 3054, 3055, 3056,\n",
      "        3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3067, 3068, 3069,\n",
      "        3071, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3083, 3084, 3085, 3086,\n",
      "        3087, 3088, 3089, 3090, 3092, 3093, 3094, 3095, 3097, 3098, 3100, 3101,\n",
      "        3102, 3104, 3105, 3106, 3108, 3111, 3112, 3113, 3114, 3116, 3117, 3119,\n",
      "        3120, 3123, 3125, 3128, 3129, 3130, 3131, 3132, 3133, 3135, 3137, 3139,\n",
      "        3141, 3142, 3143, 3144, 3146, 3148, 3150, 3151, 3152, 3153, 3156, 3157,\n",
      "        3158, 3160, 3161, 3164, 3165, 3167, 3169, 3170, 3171, 3172, 3173, 3174,\n",
      "        3175, 3176, 3177, 3179, 3180, 3181, 3182, 3184, 3185, 3187, 3188, 3189,\n",
      "        3191, 3192, 3194, 3195, 3196, 3199, 3200, 3202, 3203, 3204, 3205, 3206,\n",
      "        3207, 3210, 3213, 3214, 3216, 3217, 3218, 3221, 3222, 3223, 3224, 3225,\n",
      "        3226, 3227, 3228, 3229, 3230, 3231, 3233, 3237, 3239, 3241, 3242, 3243,\n",
      "        3244, 3245, 3247, 3249, 3251, 3252, 3253, 3256, 3258, 3259, 3260, 3261,\n",
      "        3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273,\n",
      "        3274, 3275, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3285, 3286, 3287,\n",
      "        3288, 3289, 3291, 3294, 3295, 3296, 3297, 3298, 3299, 3301, 3302, 3303,\n",
      "        3304, 3305, 3307, 3308, 3309, 3310, 3311, 3312, 3315, 3316, 3318, 3319,\n",
      "        3322, 3323, 3324, 3325, 3327, 3328, 3329, 3331, 3332, 3334, 3335, 3336,\n",
      "        3339, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351,\n",
      "        3352, 3353, 3355, 3356, 3357, 3358, 3359, 3361, 3362, 3363, 3364, 3365,\n",
      "        3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378,\n",
      "        3379, 3381, 3382, 3383, 3384, 3385, 3386, 3387, 3389, 3390, 3392, 3393,\n",
      "        3394, 3396, 3397, 3398, 3400, 3403, 3404, 3406, 3407, 3408, 3409, 3410,\n",
      "        3411, 3412, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3422, 3423, 3424,\n",
      "        3426, 3428, 3429, 3431, 3432, 3433, 3434, 3435, 3437, 3438, 3439, 3441,\n",
      "        3443, 3444, 3445, 3447, 3448, 3449, 3450, 3453, 3454, 3455, 3456, 3458,\n",
      "        3459, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472,\n",
      "        3473, 3474, 3475, 3476, 3477, 3478, 3479, 3481, 3482, 3483, 3484, 3485,\n",
      "        3486, 3487, 3489, 3490, 3491, 3492, 3493, 3496, 3497, 3500, 3501, 3502,\n",
      "        3503, 3504, 3505, 3506, 3507, 3508, 3509, 3511, 3513, 3514, 3516, 3517,\n",
      "        3520, 3521, 3522, 3523, 3525, 3526, 3527, 3528, 3530, 3531, 3532, 3533,\n",
      "        3535, 3536, 3539, 3541, 3542, 3546, 3547, 3548, 3549, 3550, 3554, 3555,\n",
      "        3557, 3558, 3559, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571,\n",
      "        3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579])\n",
      "User ID Range: 2891 to 3579\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "User IDs: tensor([3580, 3583, 3584, 3585, 3587, 3589, 3590, 3592, 3595, 3596, 3599, 3600,\n",
      "        3601, 3602, 3604, 3606, 3611, 3612, 3613, 3614, 3616, 3617, 3618, 3619,\n",
      "        3620, 3621, 3623, 3624, 3625, 3626, 3627, 3628, 3630, 3631, 3632, 3634,\n",
      "        3635, 3636, 3637, 3638, 3641, 3643, 3644, 3648, 3649, 3650, 3652, 3653,\n",
      "        3654, 3655, 3657, 3660, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3670,\n",
      "        3671, 3673, 3674, 3675, 3676, 3677, 3679, 3680, 3681, 3682, 3683, 3684,\n",
      "        3686, 3688, 3690, 3692, 3693, 3694, 3695, 3696, 3697, 3698, 3699, 3704,\n",
      "        3708, 3709, 3711, 3712, 3714, 3717, 3718, 3719, 3726, 3727, 3732, 3733,\n",
      "        3734, 3735, 3737, 3738, 3739, 3742, 3743, 3744, 3745, 3746, 3748, 3749,\n",
      "        3750, 3751, 3752, 3754, 3755, 3756, 3760, 3761, 3763, 3764, 3765, 3766,\n",
      "        3767, 3770, 3771, 3773, 3774, 3775, 3776, 3780, 3783, 3784, 3786, 3788,\n",
      "        3789, 3790, 3791, 3793, 3794, 3796, 3797, 3798, 3799, 3800, 3802, 3804,\n",
      "        3805, 3806, 3807, 3808, 3810, 3812, 3813, 3816, 3818, 3819, 3820, 3822,\n",
      "        3824, 3825, 3826, 3827, 3829, 3830, 3831, 3833, 3834, 3835, 3836, 3838,\n",
      "        3839, 3840, 3842, 3843, 3844, 3846, 3848, 3849, 3850, 3851, 3852, 3853,\n",
      "        3856, 3858, 3859, 3860, 3861, 3862, 3863, 3864, 3865, 3866, 3869, 3870,\n",
      "        3872, 3873, 3874, 3875, 3877, 3878, 3882, 3884, 3885, 3886, 3888, 3889,\n",
      "        3891, 3892, 3894, 3895, 3897, 3899, 3900, 3901, 3904, 3905, 3906, 3907,\n",
      "        3908, 3909, 3910, 3911, 3913, 3914, 3915, 3918, 3919, 3921, 3923, 3924,\n",
      "        3926, 3927, 3928, 3930, 3931, 3932, 3935, 3936, 3937, 3939, 3940, 3941,\n",
      "        3942, 3943, 3945, 3946, 3947, 3948, 3949, 3950, 3951, 3952, 3956, 3957,\n",
      "        3958, 3959, 3964, 3965, 3966, 3967, 3968, 3969, 3970, 3971, 3972, 3973,\n",
      "        3974, 3975, 3978, 3979, 3981, 3982, 3984, 3987, 3991, 3993, 3995, 3996,\n",
      "        3999, 4000])\n",
      "User ID Range: 3580 to 4000\n",
      "Embedding Weight Shape: torch.Size([4002, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5571), ('mrr@3', 0.3339), ('ndcg@3', 0.3908), ('hit@3', 0.5571), ('precision@3', 0.1857)])\n"
     ]
    }
   ],
   "source": [
    "for part in ['_pt1', '_pt2', '_pt3', '']:\n",
    "    print('\\n\\n'+part)\n",
    "    dataset_name=base_dataset_name+part\n",
    "    parameter_dict = {\n",
    "        'dataset': dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        'checkpoint_dir':data_path+dataset_name,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE\n",
    "    }\n",
    "\n",
    "\n",
    "    train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trigger_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_earlier_data(model_name,\n",
    "                         earlier_datasets,\n",
    "                         current_dataset_name,\n",
    "                         parameter_dict,\n",
    "                         checkpoint_file):\n",
    "\n",
    "\n",
    "    current_config,\\\n",
    "        current_logger,\\\n",
    "                current_dataset,\\\n",
    "                    current_train_data, current_valid_data, current_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                current_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "    # model loading and initialization\n",
    "    current_model = BPR(current_config, current_train_data.dataset).to(current_config['device'])\n",
    "    current_logger.info(current_model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = get_trainer(current_config['MODEL_TYPE'], current_config['model'])(current_config, current_model)\n",
    "\n",
    "\n",
    "    # results = []\n",
    "\n",
    "    for earlier_dataset_name in earlier_datasets:\n",
    "        print('\\n\\n'+earlier_dataset_name)\n",
    "        earlier_config,\\\n",
    "        earlier_logger,\\\n",
    "                earlier_dataset,\\\n",
    "                    earlier_train_data, earlier_valid_data, earlier_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                earlier_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "\n",
    "        # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "        # trainer.eval_collector.data_collect(earlier_train_data)\n",
    "        trainer.eval_collector.data_collect(current_train_data)\n",
    "\n",
    "        # model evaluation\n",
    "        test_result = trainer.evaluate(earlier_test_data, model_file=checkpoint_file)\n",
    "        # results += [test_result]\n",
    "    \n",
    "        print(test_result)\n",
    "\n",
    "\n",
    "def trigger_error(data_path, base_dataset_name, model_ver, checkpoint_ver, data_ver):\n",
    "    current_ver = model_ver\n",
    "    current_dataset_name = base_dataset_name+current_ver\n",
    "\n",
    "    earlier_datasets = [base_dataset_name+data_ver]#,base_dataset_name+'_pt6', base_dataset_name+'_pt7', base_dataset_name+'_pt8'] # 1,5,6,7,8\n",
    "\n",
    "\n",
    "    # Checkpoint - \n",
    "    # checkpoint_ver = 'BPR-Jan-01-2025_16-20-32'\n",
    "    checkpoint_dir = data_path+base_dataset_name+current_ver\n",
    "    checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "    parameter_dict = {\n",
    "        'dataset': current_dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        # 'user_inter_num_interval':'[1,inf)',\n",
    "        'checkpoint_dir':checkpoint_dir,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE,\n",
    "        'state':'ERROR',\n",
    "        # 'show_progress': SHOW_PROGRESS,\n",
    "        # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "        'eval_args': {'split': {'LS': 'test_only'}, # leave-one-out sample type\n",
    "                    'group_by': 'user',\n",
    "                    'order': 'RO', # random ordering\n",
    "                    'mode': 'pop001'} #  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\n",
    "    }\n",
    "\n",
    "    test_on_earlier_data(MODEL,\n",
    "                    earlier_datasets,\n",
    "                    current_dataset_name,\n",
    "                    parameter_dict, \n",
    "                    checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expect all data_ver='_pt7' to yield Index ou of Range error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-10-2025_12-00-48', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt1') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-10-2025_12-00-55', data_ver='_pt1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt2') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrigger_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_dataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_ver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_pt1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_ver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBPR-Jan-10-2025_14-26-30\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_ver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_pt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [10], line 80\u001b[0m, in \u001b[0;36mtrigger_error\u001b[1;34m(data_path, base_dataset_name, model_ver, checkpoint_ver, data_ver)\u001b[0m\n\u001b[0;32m     57\u001b[0m checkpoint_file \u001b[38;5;241m=\u001b[39m checkpoint_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mcheckpoint_ver\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     60\u001b[0m parameter_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: current_dataset_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.inter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m: data_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop001\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;66;03m#  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\u001b[39;00m\n\u001b[0;32m     78\u001b[0m }\n\u001b[1;32m---> 80\u001b[0m \u001b[43mtest_on_earlier_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearlier_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcurrent_dataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m                \u001b[49m\u001b[43mparameter_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [10], line 41\u001b[0m, in \u001b[0;36mtest_on_earlier_data\u001b[1;34m(model_name, earlier_datasets, current_dataset_name, parameter_dict, checkpoint_file)\u001b[0m\n\u001b[0;32m     38\u001b[0m trainer\u001b[38;5;241m.\u001b[39meval_collector\u001b[38;5;241m.\u001b[39mdata_collect(current_train_data)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# model evaluation\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m test_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearlier_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# results += [test_result]\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_result)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:616\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_data, load_best_model, model_file, show_progress)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batched_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iter_data):\n\u001b[0;32m    615\u001b[0m     num_sample \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batched_data)\n\u001b[1;32m--> 616\u001b[0m     interaction, scores, positive_u, positive_i \u001b[38;5;241m=\u001b[39m \u001b[43meval_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_available \u001b[38;5;129;01mand\u001b[39;00m show_progress:\n\u001b[0;32m    618\u001b[0m         iter_data\u001b[38;5;241m.\u001b[39mset_postfix_str(\n\u001b[0;32m    619\u001b[0m             set_color(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU RAM: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m get_gpu_usage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myellow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    620\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:546\u001b[0m, in \u001b[0;36mTrainer._neg_sample_batch_eval\u001b[1;34m(self, batched_data)\u001b[0m\n\u001b[0;32m    544\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m interaction\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_batch_size:\n\u001b[1;32m--> 546\u001b[0m     origin_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     origin_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spilt_predict(interaction, batch_size)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\model\\general_recommender\\bpr.py:105\u001b[0m, in \u001b[0;36mBPR.predict\u001b[1;34m(self, interaction)\u001b[0m\n\u001b[0;32m    103\u001b[0m user \u001b[38;5;241m=\u001b[39m interaction[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUSER_ID]\n\u001b[0;32m    104\u001b[0m item \u001b[38;5;241m=\u001b[39m interaction[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mITEM_ID]\n\u001b[1;32m--> 105\u001b[0m user_e, item_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmul(user_e, item_e)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\model\\general_recommender\\bpr.py:85\u001b[0m, in \u001b[0;36mBPR.forward\u001b[1;34m(self, user, item)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user, item):\n\u001b[1;32m---> 85\u001b[0m     user_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     item_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_item_embedding(item)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_e, item_e\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\model\\general_recommender\\bpr.py:70\u001b[0m, in \u001b[0;36mBPR.get_user_embedding\u001b[1;34m(self, user)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser ID Range:\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem())  \u001b[38;5;66;03m# Print the range of user IDs\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding Weight Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_14-26-30', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt2') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-10-2025_12-00-48', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt2') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-10-2025_12-00-55', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt3') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_14-26-30', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt3') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt3') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-10-2025_12-00-55', data_ver='_pt3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_14-26-30', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-10-2025_12-00-48', data_ver='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt6') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_14-26-30', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-10-2025_12-00-48', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt6') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-10-2025_12-00-55', data_ver='_pt6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt8') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_14-26-30', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt8') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt8') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-10-2025_12-00-48', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt8') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-10-2025_12-00-55', data_ver='_pt8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt5') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = ERROR\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'test_only'}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'pop001', 'test': 'pop001'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'popularity', 'sample_num': 1}\n",
      "test_neg_sample_args = {'distribution': 'popularity', 'sample_num': 1}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "12 Jan 16:34    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "The number of users: 1001\n",
      "Average actions of users: 2.065\n",
      "The number of items: 8\n",
      "Average actions of items: 295.0\n",
      "The number of inters: 2065\n",
      "The sparsity of the dataset: 74.2132867132867%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "12 Jan 16:34    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "12 Jan 16:34    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'test_only'}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'pop001', 'test': 'pop001'}}]\n",
      "12 Jan 16:34    INFO  BPR(\n",
      "  (user_embedding): Embedding(1001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 64576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12 Jan 16:34    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = ERROR\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt5\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'test_only'}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'pop001', 'test': 'pop001'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'popularity', 'sample_num': 1}\n",
      "test_neg_sample_args = {'distribution': 'popularity', 'sample_num': 1}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "12 Jan 16:34    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt5\n",
      "The number of users: 1002\n",
      "Average actions of users: 2.006993006993007\n",
      "The number of items: 8\n",
      "Average actions of items: 287.0\n",
      "The number of inters: 2009\n",
      "The sparsity of the dataset: 74.93762475049901%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "12 Jan 16:34    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "12 Jan 16:34    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'test_only'}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'pop001', 'test': 'pop001'}}]\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "12 Jan 16:34    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_4000x7_0.71_pt1/BPR-Jan-10-2025_14-26-30.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User IDs: tensor([   1,    1,    2,  ...,  997, 1001, 1001])\n",
      "User ID Range: 1 to 1001\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_12-00-41', data_ver='_pt5')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrigger_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_dataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_ver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_pt1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_ver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBPR-Jan-10-2025_14-26-30\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_ver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_pt5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [16], line 80\u001b[0m, in \u001b[0;36mtrigger_error\u001b[1;34m(data_path, base_dataset_name, model_ver, checkpoint_ver, data_ver)\u001b[0m\n\u001b[0;32m     57\u001b[0m checkpoint_file \u001b[38;5;241m=\u001b[39m checkpoint_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mcheckpoint_ver\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     60\u001b[0m parameter_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m: current_dataset_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.inter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m: data_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop001\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;66;03m#  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\u001b[39;00m\n\u001b[0;32m     78\u001b[0m }\n\u001b[1;32m---> 80\u001b[0m \u001b[43mtest_on_earlier_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearlier_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcurrent_dataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m                \u001b[49m\u001b[43mparameter_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [16], line 41\u001b[0m, in \u001b[0;36mtest_on_earlier_data\u001b[1;34m(model_name, earlier_datasets, current_dataset_name, parameter_dict, checkpoint_file)\u001b[0m\n\u001b[0;32m     38\u001b[0m trainer\u001b[38;5;241m.\u001b[39meval_collector\u001b[38;5;241m.\u001b[39mdata_collect(current_train_data)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# model evaluation\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m test_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearlier_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# results += [test_result]\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_result)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:616\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_data, load_best_model, model_file, show_progress)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batched_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iter_data):\n\u001b[0;32m    615\u001b[0m     num_sample \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batched_data)\n\u001b[1;32m--> 616\u001b[0m     interaction, scores, positive_u, positive_i \u001b[38;5;241m=\u001b[39m \u001b[43meval_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_available \u001b[38;5;129;01mand\u001b[39;00m show_progress:\n\u001b[0;32m    618\u001b[0m         iter_data\u001b[38;5;241m.\u001b[39mset_postfix_str(\n\u001b[0;32m    619\u001b[0m             set_color(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU RAM: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m get_gpu_usage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myellow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    620\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:546\u001b[0m, in \u001b[0;36mTrainer._neg_sample_batch_eval\u001b[1;34m(self, batched_data)\u001b[0m\n\u001b[0;32m    544\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m interaction\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_batch_size:\n\u001b[1;32m--> 546\u001b[0m     origin_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteraction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     origin_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spilt_predict(interaction, batch_size)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\model\\general_recommender\\bpr.py:105\u001b[0m, in \u001b[0;36mBPR.predict\u001b[1;34m(self, interaction)\u001b[0m\n\u001b[0;32m    103\u001b[0m user \u001b[38;5;241m=\u001b[39m interaction[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mUSER_ID]\n\u001b[0;32m    104\u001b[0m item \u001b[38;5;241m=\u001b[39m interaction[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mITEM_ID]\n\u001b[1;32m--> 105\u001b[0m user_e, item_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmul(user_e, item_e)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\model\\general_recommender\\bpr.py:85\u001b[0m, in \u001b[0;36mBPR.forward\u001b[1;34m(self, user, item)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user, item):\n\u001b[1;32m---> 85\u001b[0m     user_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_user_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     item_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_item_embedding(item)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m user_e, item_e\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\model\\general_recommender\\bpr.py:70\u001b[0m, in \u001b[0;36mBPR.get_user_embedding\u001b[1;34m(self, user)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser ID Range:\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m, user\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem())  \u001b[38;5;66;03m# Print the range of user IDs\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding Weight Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_12-00-41', data_ver='_pt5')\n",
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_14-26-30', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt5') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt5') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-10-2025_12-00-48', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt5') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-10-2025_12-00-55', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt7') (IoR e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_12-00-41', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt7') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt3', data_ver='_pt7') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt3', checkpoint_ver = 'BPR-Jan-10-2025_12-00-48', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='', data_ver='_pt7') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='', checkpoint_ver = 'BPR-Jan-10-2025_12-00-55', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change what data is fed to eval_colector re-doing some trigger error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_earlier_data(model_name,\n",
    "                         earlier_datasets,\n",
    "                         current_dataset_name,\n",
    "                         parameter_dict,\n",
    "                         checkpoint_file):\n",
    "\n",
    "\n",
    "    current_config,\\\n",
    "        current_logger,\\\n",
    "                current_dataset,\\\n",
    "                    current_train_data, current_valid_data, current_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                current_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "    # model loading and initialization\n",
    "    current_model = BPR(current_config, current_train_data.dataset).to(current_config['device'])\n",
    "    current_logger.info(current_model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = get_trainer(current_config['MODEL_TYPE'], current_config['model'])(current_config, current_model)\n",
    "\n",
    "\n",
    "    # results = []\n",
    "\n",
    "    for earlier_dataset_name in earlier_datasets:\n",
    "        print('\\n\\n'+earlier_dataset_name)\n",
    "        earlier_config,\\\n",
    "        earlier_logger,\\\n",
    "                earlier_dataset,\\\n",
    "                    earlier_train_data, earlier_valid_data, earlier_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                earlier_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "\n",
    "        # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "        trainer.eval_collector.data_collect(earlier_train_data)\n",
    "        # trainer.eval_collector.data_collect(current_train_data)\n",
    "\n",
    "        # model evaluation\n",
    "        test_result = trainer.evaluate(earlier_test_data, model_file=checkpoint_file)\n",
    "        # results += [test_result]\n",
    "    \n",
    "        print(test_result)\n",
    "\n",
    "\n",
    "def trigger_error(data_path, base_dataset_name, model_ver, checkpoint_ver, data_ver):\n",
    "    current_ver = model_ver\n",
    "    current_dataset_name = base_dataset_name+current_ver\n",
    "\n",
    "    earlier_datasets = [base_dataset_name+data_ver]#,base_dataset_name+'_pt6', base_dataset_name+'_pt7', base_dataset_name+'_pt8'] # 1,5,6,7,8\n",
    "\n",
    "\n",
    "    # Checkpoint - \n",
    "    # checkpoint_ver = 'BPR-Jan-01-2025_16-20-32'\n",
    "    checkpoint_dir = data_path+base_dataset_name+current_ver\n",
    "    checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "    parameter_dict = {\n",
    "        'dataset': current_dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        # 'user_inter_num_interval':'[1,inf)',\n",
    "        'checkpoint_dir':checkpoint_dir,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE,\n",
    "        'state':'ERROR',\n",
    "        # 'show_progress': SHOW_PROGRESS,\n",
    "        # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "        'eval_args': {'split': {'LS': 'test_only'}, # leave-one-out sample type\n",
    "                    'group_by': 'user',\n",
    "                    'order': 'RO', # random ordering\n",
    "                    'mode': 'pop001'} #  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\n",
    "    }\n",
    "\n",
    "    test_on_earlier_data(MODEL,\n",
    "                    earlier_datasets,\n",
    "                    current_dataset_name,\n",
    "                    parameter_dict, \n",
    "                    checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_12-00-41', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt7') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_12-00-41', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt7') (pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='_pt7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-generate data with new user indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def validate_folderpath(folderpath):\n",
    "    # print('im validating')\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "        print('Folder created: ', folderpath)\n",
    "\n",
    "\n",
    "def save_picklefile(d, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "\n",
    "    print('Saved file at '+filepath)\n",
    "\n",
    "def load_picklefile(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "    return loaded_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def generate_artificial_random_dataset(n_users,\n",
    "                                       n_items, \n",
    "                                       ts,\n",
    "                                       all_items_seen,\n",
    "                                       random_seed,\n",
    "                                       n_items_to_drift,\n",
    "                                       sudden_drift_start,\n",
    "                                       drift_items_freq_list,\n",
    "                                       non_drift_items_freq_list,\n",
    "                                       save_path,\n",
    "                                       base_filename,\n",
    "                                       bin_size):\n",
    "    \n",
    "    def add_zero_user(df):\n",
    "\n",
    "        df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "        df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "        df.loc[-1] = ['u_1', 'i_1', ts, 0]\n",
    "        df.loc[-4] = ['u_1', 'i_5', ts, 0]\n",
    "        # df.loc[-2] = ['u_-1', 'i_2', ts, 0]\n",
    "        # df.loc[-3] = ['u_-1', 'i_3', ts, 0]\n",
    "        # df.loc[-5] = ['u_0', 'i_4', ts, 0]\n",
    "        df.loc[-6] = ['u_1', 'drifted_i_1', ts, 0]\n",
    "        df.loc[-7] = ['u_1', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        df.sort_values(by='user_id_n', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "        # print('added zero user\\n', df.head())\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def create_folderpath(save_path, base_filename, specs_str):\n",
    "        return save_path+base_filename+'_'+specs_str+'/'\n",
    "    \n",
    "\n",
    "    def save_items_frequencies(n_items_to_drift,\n",
    "                               sudden_drift_start,\n",
    "                               drift_items_freq_list,\n",
    "                               non_drift_items_freq_list,\n",
    "                               save_path, \n",
    "                               base_filename,\n",
    "                               specs_str):\n",
    "        \n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "\n",
    "        d = {'n_items_to_drift': n_items_to_drift,\n",
    "             'sudden_drift_start': sudden_drift_start,\n",
    "             'drift_items_freq_list': drift_items_freq_list,\n",
    "             'non_drift_items_freq_list': non_drift_items_freq_list}\n",
    "\n",
    "        save_picklefile(d, folderpath+'saved_dictionary.pkl')\n",
    "       \n",
    "\n",
    "    \n",
    "    def save_dataset_atomic_file(df, user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "    def add_user0_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "            df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "        \n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_add_user0_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        add_user0_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_sparsity(df):\n",
    "        # df.item_id.groupby([df.user_id, df.item_id]).count().sum() == df.user_id.count()\n",
    "        sparsity = 1 - df.user_id.count()/(df.user_id.nunique()*df.item_id.nunique())\n",
    "        specs_str = str(df.user_id.nunique())+'x'+str(df.item_id.nunique())+'_'+str(round(sparsity, 2))\n",
    "        print('specs_str', specs_str)\n",
    "        return sparsity, specs_str\n",
    "    \n",
    "\n",
    "    def rename_item(row):\n",
    "        if int(row['user_id'].split('_')[1]) > sudden_drift_start and row['item_id'] in renamed_items:\n",
    "            return renamed_items[row['item_id']]\n",
    "        return row['item_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    users_list = [f'u_{i+1}' for i in range(1, n_users)]\n",
    "    items_list = [f'i_{j+1}' for j in range(n_items)]\n",
    "\n",
    "\n",
    "    if all_items_seen:\n",
    "\n",
    "        data = []\n",
    "        for user in users_list:\n",
    "            for item in items_list:\n",
    "                data.append({'user_id': user, 'item_id': item, 'timestamp':ts})\n",
    "\n",
    "        all_items_seen_df = pd.DataFrame(data)\n",
    "\n",
    "        # Introduce sudden drift\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}       \n",
    "        \n",
    "\n",
    "        all_items_seen_df['item_id'] = all_items_seen_df.apply(rename_item, axis=1)\n",
    "        # print(all_items_seen_df.item_id.groupby([all_items_seen_df.user_id, all_items_seen_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        \n",
    "        sparsity , specs_str = calculate_sparsity(all_items_seen_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "\n",
    "        sampled_df = add_zero_user(sampled_df)\n",
    "        users_list.insert(0, 'u_0')\n",
    "        \n",
    "\n",
    "        # split_dataset_into_4_and_save_atomic_file(all_items_seen_df,users_list, bin_size, save_path, specs_str)\n",
    "        # save_dataset_atomic_file(all_items_seen_df, save_path, specs_str)\n",
    "        split_dataset_into_4_add_user0_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(drift_items_freq_list) != n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "        elif len(non_drift_items_freq_list) != len(items_list)-n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "\n",
    "\n",
    "        def sample_with_repetition_of_pattern(users_list, items_list, items_freq_list):\n",
    "            random.seed(random_seed)\n",
    "            sampled_df = pd.DataFrame({})\n",
    "            for i, freq in enumerate(items_freq_list):\n",
    "                # print('k ',k)\n",
    "                user_sample = random.sample(users_list[:sudden_drift_start], k=freq) +\\\n",
    "                                random.sample(users_list[sudden_drift_start:], k=freq)\n",
    "                temp_df = pd.DataFrame({'user_id': user_sample, \n",
    "                                        'item_id': items_list[i]})\n",
    "                # print(temp_df.item_id.groupby([temp_df.user_id, temp_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "                sampled_df = pd.concat([sampled_df, temp_df])\n",
    "            \n",
    "            return sampled_df\n",
    "        \n",
    "\n",
    "        # Introduce sudden drift\n",
    "        # No need to random sample, bc the list will have the frequencies for each item\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        # drift_items_list = [items_list[i] for i,x in enumerate(items_freq_list) if x == sudden_drift_start]\n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}\n",
    "        non_drift_items_list = list(set(items_list) - set(drift_items_list))\n",
    "        \n",
    "        print('drift_items_list', drift_items_list)\n",
    "        print('renamed_items', renamed_items)\n",
    "        print('non_drift_items_list', non_drift_items_list)\n",
    "\n",
    "        \n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        sampled_df = sample_with_repetition_of_pattern(users_list,\n",
    "                                                       non_drift_items_list,\n",
    "                                                       non_drift_items_freq_list)\n",
    "        \n",
    "        sampled_df = pd.concat([sampled_df,\n",
    "                                sample_with_repetition_of_pattern(users_list,\n",
    "                                                                    drift_items_list,\n",
    "                                                                    drift_items_freq_list)])\n",
    "\n",
    "        if sampled_df.user_id.nunique() < n_users:\n",
    "            # print(sampled_df.head())\n",
    "            users_not_sampled = list(set(users_list) - set(sampled_df.user_id))\n",
    "            print('users_not_sampled', len(users_not_sampled))\n",
    "            # print('drift_items_list', drift_items_list)\n",
    "            for user in users_not_sampled:\n",
    "                for item in drift_items_list:\n",
    "                    # print(sampled_df.loc[sampled_df['user_id']==user, 'item_id'].count())\n",
    "                    sampled_df.loc[len(sampled_df)] = [user, item]\n",
    "\n",
    "\n",
    "        sampled_df['item_id'] = sampled_df.apply(rename_item, axis=1)\n",
    "        # print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        sampled_df['timestamp'] = ts\n",
    "\n",
    "\n",
    "\n",
    "        sparsity, specs_str = calculate_sparsity(sampled_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "        # print(specs_str)\n",
    "        print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "        # print(sampled_df.head())\n",
    "\n",
    "\n",
    "        # when trainning on pt1, yield ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users.\n",
    "        # sampled_df = add_zero_user(sampled_df) # to solve the error \n",
    "        users_list.insert(0, 'u_0')\n",
    "\n",
    "        # save_dataset_atomic_file(sampled_df, save_path, specs_str)\n",
    "        # split_dataset_into_4_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        split_dataset_into_4_add_user0_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "        return sampled_df\n",
    "\n",
    "# Parameters\n",
    "n_users = 4000 # bc of random sample, some users dont have occurrencies\n",
    "n_items = 5\n",
    "sudden_drift_start = 2000  # Starting user index for drift (1-indexed)\n",
    "bin_size = 1000\n",
    "\n",
    "string = \"24/12/2024 21:12:24\"\n",
    "ts = time.mktime(datetime.strptime(string, \"%d/%m/%Y %H:%M:%S\").timetuple())\n",
    "\n",
    "all_items_seen = False\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "ratio_to_drift = 2 # Select 50% of items to rename\n",
    "n_items_to_drift = n_items // ratio_to_drift\n",
    "\n",
    "base_filename = 'sudden_drift_dataset_u0_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "drift_items_freq_list = [sudden_drift_start//2, sudden_drift_start//2]\n",
    "non_drift_items_freq_list = [sudden_drift_start//4, sudden_drift_start//4, sudden_drift_start//4]\n",
    "\n",
    "df = generate_artificial_random_dataset(n_users=n_users,\n",
    "                                    n_items=n_items, \n",
    "                                    ts=ts,\n",
    "                                    all_items_seen=all_items_seen,\n",
    "                                    n_items_to_drift=n_items_to_drift,\n",
    "                                    random_seed=random_seed,\n",
    "                                    sudden_drift_start=sudden_drift_start,\n",
    "                                    drift_items_freq_list=drift_items_freq_list,\n",
    "                                    non_drift_items_freq_list=non_drift_items_freq_list,\n",
    "                                    save_path=save_path,\n",
    "                                    base_filename=base_filename,\n",
    "                                    bin_size=bin_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "\n",
    "\n",
    "def train_test(model_name,\n",
    "               dataset_name,\n",
    "               parameter_dict):\n",
    "\n",
    "    # configurations initialization\n",
    "    config = Config(model=model_name, dataset=dataset_name, config_dict=parameter_dict)\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = BPR(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = Trainer(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "    print('\\n\\nTraining best results')\n",
    "    print('best_valid_score: ', best_valid_score)\n",
    "    print('best_valid_result: ', best_valid_result)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    \n",
    "    print('\\n\\nTest results')\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = 'sudden_drift_dataset_u0_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "# Current model~~~~\n",
    "base_dataset_name = base_filename+'_3999x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:24    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval ="
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "_pt1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 11:24    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1\n",
      "The number of users: 1001\n",
      "Average actions of users: 2.065\n",
      "The number of items: 8\n",
      "Average actions of items: 295.0\n",
      "The number of inters: 2065\n",
      "The sparsity of the dataset: 74.2132867132867%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 11:24    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 11:24    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Jan 11:24    INFO  BPR(\n",
      "  (user_embedding): Embedding(1001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 64576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 0 training [time: 0.13s, train loss: 0.6925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 0 evaluating [time: 0.07s, valid_score: 0.483400]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4834    mrr@3 : 0.3143    ndcg@3 : 0.3575    hit@3 : 0.4834    precision@3 : 0.1611\n",
      "14 Jan 11:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1\\BPR-Jan-14-2025_11-24-59.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 1 training [time: 0.02s, train loss: 0.6891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 1 evaluating [time: 0.03s, valid_score: 0.476000]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.476    mrr@3 : 0.3075    ndcg@3 : 0.3506    hit@3 : 0.476    precision@3 : 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 2 training [time: 0.02s, train loss: 0.6854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 2 evaluating [time: 0.03s, valid_score: 0.472300]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4723    mrr@3 : 0.3081    ndcg@3 : 0.3502    hit@3 : 0.4723    precision@3 : 0.1574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 3 training [time: 0.03s, train loss: 0.6830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 3 evaluating [time: 0.06s, valid_score: 0.483400]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4834    mrr@3 : 0.3124    ndcg@3 : 0.3562    hit@3 : 0.4834    precision@3 : 0.1611\n",
      "14 Jan 11:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1\\BPR-Jan-14-2025_11-24-59.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 4 training [time: 0.02s, train loss: 0.6780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 4 evaluating [time: 0.04s, valid_score: 0.483400]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4834    mrr@3 : 0.3124    ndcg@3 : 0.3562    hit@3 : 0.4834    precision@3 : 0.1611\n",
      "14 Jan 11:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1\\BPR-Jan-14-2025_11-24-59.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 5 training [time: 0.02s, train loss: 0.6725]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 5 evaluating [time: 0.04s, valid_score: 0.476000]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.476    mrr@3 : 0.31    ndcg@3 : 0.3525    hit@3 : 0.476    precision@3 : 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 6 training [time: 0.02s, train loss: 0.6697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 6 evaluating [time: 0.03s, valid_score: 0.476000]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.476    mrr@3 : 0.3081    ndcg@3 : 0.3511    hit@3 : 0.476    precision@3 : 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 7 training [time: 0.02s, train loss: 0.6662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 7 evaluating [time: 0.02s, valid_score: 0.479700]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4797    mrr@3 : 0.3063    ndcg@3 : 0.3506    hit@3 : 0.4797    precision@3 : 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 8 training [time: 0.08s, train loss: 0.6611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 8 evaluating [time: 0.03s, valid_score: 0.479700]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4797    mrr@3 : 0.3063    ndcg@3 : 0.3506    hit@3 : 0.4797    precision@3 : 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 9 training [time: 0.03s, train loss: 0.6589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 9 evaluating [time: 0.03s, valid_score: 0.479700]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4797    mrr@3 : 0.3044    ndcg@3 : 0.3493    hit@3 : 0.4797    precision@3 : 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 10 training [time: 0.04s, train loss: 0.6546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 10 evaluating [time: 0.03s, valid_score: 0.479700]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4797    mrr@3 : 0.3063    ndcg@3 : 0.3506    hit@3 : 0.4797    precision@3 : 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 11 training [time: 0.02s, train loss: 0.6515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 11 evaluating [time: 0.02s, valid_score: 0.479700]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4797    mrr@3 : 0.3038    ndcg@3 : 0.3488    hit@3 : 0.4797    precision@3 : 0.1599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 12 training [time: 0.03s, train loss: 0.6480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 12 evaluating [time: 0.03s, valid_score: 0.472300]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4723    mrr@3 : 0.2958    ndcg@3 : 0.3409    hit@3 : 0.4723    precision@3 : 0.1574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 13 training [time: 0.03s, train loss: 0.6432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 13 evaluating [time: 0.06s, valid_score: 0.476000]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.476    mrr@3 : 0.2977    ndcg@3 : 0.3433    hit@3 : 0.476    precision@3 : 0.1587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 14 training [time: 0.04s, train loss: 0.6397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 14 evaluating [time: 0.03s, valid_score: 0.468600]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4686    mrr@3 : 0.2958    ndcg@3 : 0.34    hit@3 : 0.4686    precision@3 : 0.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 15 training [time: 0.03s, train loss: 0.6341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 997\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 15 evaluating [time: 0.03s, valid_score: 0.468600]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4686    mrr@3 : 0.2964    ndcg@3 : 0.3404    hit@3 : 0.4686    precision@3 : 0.1562\n",
      "14 Jan 11:25    INFO  Finished training, best eval result in epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.4834\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.4834), ('mrr@3', 0.3124), ('ndcg@3', 0.3562), ('hit@3', 0.4834), ('precision@3', 0.1611)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 11:25    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt1\\BPR-Jan-14-2025_11-24-59.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n",
      "User ID Range: 690 to 1000\n",
      "Embedding Weight Shape: torch.Size([1001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5384), ('mrr@3', 0.3422), ('ndcg@3', 0.3922), ('hit@3', 0.5384), ('precision@3', 0.1795)])\n",
      "\n",
      "\n",
      "_pt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt2\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt2\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 11:25    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt2\n",
      "The number of users: 2001\n",
      "Average actions of users: 2.0305\n",
      "The number of items: 8\n",
      "Average actions of items: 580.1428571428571\n",
      "The number of inters: 4061\n",
      "The sparsity of the dataset: 74.63143428285856%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 11:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 11:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Jan 11:25    INFO  BPR(\n",
      "  (user_embedding): Embedding(2001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 128576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 0 training [time: 0.05s, train loss: 1.3897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 0 evaluating [time: 0.05s, valid_score: 0.534500]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5345    mrr@3 : 0.3323    ndcg@3 : 0.3838    hit@3 : 0.5345    precision@3 : 0.1782\n",
      "14 Jan 11:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt2\\BPR-Jan-14-2025_11-25-04.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 1 training [time: 0.07s, train loss: 1.3807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 1 evaluating [time: 0.06s, valid_score: 0.530600]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5306    mrr@3 : 0.3304    ndcg@3 : 0.3814    hit@3 : 0.5306    precision@3 : 0.1769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 2 training [time: 0.06s, train loss: 1.3668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 2 evaluating [time: 0.05s, valid_score: 0.532500]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5325    mrr@3 : 0.3323    ndcg@3 : 0.3834    hit@3 : 0.5325    precision@3 : 0.1775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 3 training [time: 0.06s, train loss: 1.3582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 3 evaluating [time: 0.08s, valid_score: 0.528600]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5286    mrr@3 : 0.3277    ndcg@3 : 0.379    hit@3 : 0.5286    precision@3 : 0.1762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 4 training [time: 0.07s, train loss: 1.3485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 4 evaluating [time: 0.05s, valid_score: 0.532500]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5325    mrr@3 : 0.3268    ndcg@3 : 0.3793    hit@3 : 0.5325    precision@3 : 0.1775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 5 training [time: 0.06s, train loss: 1.3365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 5 evaluating [time: 0.04s, valid_score: 0.528600]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5286    mrr@3 : 0.3274    ndcg@3 : 0.3787    hit@3 : 0.5286    precision@3 : 0.1762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 6 training [time: 0.06s, train loss: 1.3232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 6 evaluating [time: 0.04s, valid_score: 0.520700]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5207    mrr@3 : 0.3238    ndcg@3 : 0.374    hit@3 : 0.5207    precision@3 : 0.1736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 7 training [time: 0.05s, train loss: 1.3124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 7 evaluating [time: 0.05s, valid_score: 0.514800]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5148    mrr@3 : 0.3199    ndcg@3 : 0.3696    hit@3 : 0.5148    precision@3 : 0.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 8 training [time: 0.06s, train loss: 1.2983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 8 evaluating [time: 0.06s, valid_score: 0.506900]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5069    mrr@3 : 0.3172    ndcg@3 : 0.3657    hit@3 : 0.5069    precision@3 : 0.169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 9 training [time: 0.07s, train loss: 1.2881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 9 evaluating [time: 0.11s, valid_score: 0.503000]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.503    mrr@3 : 0.3139    ndcg@3 : 0.3622    hit@3 : 0.503    precision@3 : 0.1677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 10 training [time: 0.06s, train loss: 1.2802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 10 evaluating [time: 0.05s, valid_score: 0.501000]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.501    mrr@3 : 0.3176    ndcg@3 : 0.3644    hit@3 : 0.501    precision@3 : 0.167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 20 to 1945\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 11 training [time: 0.06s, train loss: 1.2696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 11 evaluating [time: 0.05s, valid_score: 0.493100]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.4931    mrr@3 : 0.3136    ndcg@3 : 0.3594    hit@3 : 0.4931    precision@3 : 0.1644\n",
      "14 Jan 11:25    INFO  Finished training, best eval result in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5345\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5345), ('mrr@3', 0.3323), ('ndcg@3', 0.3838), ('hit@3', 0.5345), ('precision@3', 0.1782)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 11:25    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt2\\BPR-Jan-14-2025_11-25-04.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 690 to 1425\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1426 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.551), ('mrr@3', 0.3453), ('ndcg@3', 0.3978), ('hit@3', 0.551), ('precision@3', 0.1837)])\n",
      "\n",
      "\n",
      "_pt3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 11:25    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3\n",
      "The number of users: 3001\n",
      "Average actions of users: 2.041\n",
      "The number of items: 8\n",
      "Average actions of items: 874.7142857142857\n",
      "The number of inters: 6123\n",
      "The sparsity of the dataset: 74.49600133288904%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 11:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 11:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Jan 11:25    INFO  BPR(\n",
      "  (user_embedding): Embedding(3001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 192576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 0 training [time: 0.07s, train loss: 1.3870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 0 evaluating [time: 0.09s, valid_score: 0.550400]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5504    mrr@3 : 0.3374    ndcg@3 : 0.3917    hit@3 : 0.5504    precision@3 : 0.1835\n",
      "14 Jan 11:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3\\BPR-Jan-14-2025_11-25-07.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 1 training [time: 0.07s, train loss: 1.3751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 1 evaluating [time: 0.09s, valid_score: 0.551700]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5517    mrr@3 : 0.3368    ndcg@3 : 0.3915    hit@3 : 0.5517    precision@3 : 0.1839\n",
      "14 Jan 11:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3\\BPR-Jan-14-2025_11-25-07.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 2 training [time: 0.07s, train loss: 1.3646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 2 evaluating [time: 0.10s, valid_score: 0.555600]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5556    mrr@3 : 0.3387    ndcg@3 : 0.394    hit@3 : 0.5556    precision@3 : 0.1852\n",
      "14 Jan 11:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3\\BPR-Jan-14-2025_11-25-07.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 3 training [time: 0.07s, train loss: 1.3550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 3 evaluating [time: 0.10s, valid_score: 0.550400]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5504    mrr@3 : 0.334    ndcg@3 : 0.3892    hit@3 : 0.5504    precision@3 : 0.1835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 4 training [time: 0.08s, train loss: 1.3434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 4 evaluating [time: 0.10s, valid_score: 0.550400]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5504    mrr@3 : 0.3312    ndcg@3 : 0.3871    hit@3 : 0.5504    precision@3 : 0.1835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 5 training [time: 0.07s, train loss: 1.3334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 5 evaluating [time: 0.09s, valid_score: 0.547800]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5478    mrr@3 : 0.3331    ndcg@3 : 0.3879    hit@3 : 0.5478    precision@3 : 0.1826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 6 training [time: 0.07s, train loss: 1.3211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 6 evaluating [time: 0.09s, valid_score: 0.545200]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5452    mrr@3 : 0.3325    ndcg@3 : 0.3867    hit@3 : 0.5452    precision@3 : 0.1817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 7 training [time: 0.07s, train loss: 1.3108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 7 evaluating [time: 0.10s, valid_score: 0.536200]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5362    mrr@3 : 0.3303    ndcg@3 : 0.3829    hit@3 : 0.5362    precision@3 : 0.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 8 training [time: 0.16s, train loss: 1.2994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 8 evaluating [time: 0.09s, valid_score: 0.534900]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5349    mrr@3 : 0.3282    ndcg@3 : 0.3809    hit@3 : 0.5349    precision@3 : 0.1783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 9 training [time: 0.07s, train loss: 1.2862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 9 evaluating [time: 0.09s, valid_score: 0.537500]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5375    mrr@3 : 0.3314    ndcg@3 : 0.384    hit@3 : 0.5375    precision@3 : 0.1792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 10 training [time: 0.07s, train loss: 1.2751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 10 evaluating [time: 0.09s, valid_score: 0.532300]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5323    mrr@3 : 0.3282    ndcg@3 : 0.3804    hit@3 : 0.5323    precision@3 : 0.1774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 11 training [time: 0.07s, train loss: 1.2645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 11 evaluating [time: 0.09s, valid_score: 0.524500]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5245    mrr@3 : 0.3247    ndcg@3 : 0.3758    hit@3 : 0.5245    precision@3 : 0.1748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 12 training [time: 0.08s, train loss: 1.2512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 12 evaluating [time: 0.12s, valid_score: 0.523300]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5233    mrr@3 : 0.323    ndcg@3 : 0.3741    hit@3 : 0.5233    precision@3 : 0.1744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 3 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 13 training [time: 0.07s, train loss: 1.2386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2034 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 13 evaluating [time: 0.10s, valid_score: 0.528400]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5284    mrr@3 : 0.3213    ndcg@3 : 0.3742    hit@3 : 0.5284    precision@3 : 0.1761\n",
      "14 Jan 11:25    INFO  Finished training, best eval result in epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5556\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5556), ('mrr@3', 0.3387), ('ndcg@3', 0.394), ('hit@3', 0.5556), ('precision@3', 0.1852)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 11:25    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71_pt3\\BPR-Jan-14-2025_11-25-07.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 690 to 1425\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1426 to 2188\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2189 to 2886\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2890 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5411), ('mrr@3', 0.3283), ('ndcg@3', 0.3826), ('hit@3', 0.5411), ('precision@3', 0.1804)])\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 11:25    INFO  sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71\n",
      "The number of users: 4001\n",
      "Average actions of users: 2.034\n",
      "The number of items: 8\n",
      "Average actions of items: 1162.2857142857142\n",
      "The number of inters: 8136\n",
      "The sparsity of the dataset: 74.58135466133467%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 11:25    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 11:25    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Jan 11:25    INFO  BPR(\n",
      "  (user_embedding): Embedding(4001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 256576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 0 training [time: 0.11s, train loss: 2.0794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 0 evaluating [time: 0.11s, valid_score: 0.551000]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.551    mrr@3 : 0.3307    ndcg@3 : 0.3869    hit@3 : 0.551    precision@3 : 0.1837\n",
      "14 Jan 11:25    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71\\BPR-Jan-14-2025_11-25-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 1 training [time: 0.12s, train loss: 2.0602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 1 evaluating [time: 0.13s, valid_score: 0.539100]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5391    mrr@3 : 0.3261    ndcg@3 : 0.3804    hit@3 : 0.5391    precision@3 : 0.1797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 2 training [time: 0.13s, train loss: 2.0416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 2 evaluating [time: 0.13s, valid_score: 0.533200]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5332    mrr@3 : 0.3224    ndcg@3 : 0.3762    hit@3 : 0.5332    precision@3 : 0.1777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 3 training [time: 0.16s, train loss: 2.0250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 3 evaluating [time: 0.12s, valid_score: 0.540100]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5401    mrr@3 : 0.3266    ndcg@3 : 0.3811    hit@3 : 0.5401    precision@3 : 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 4 training [time: 0.11s, train loss: 2.0042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 4 evaluating [time: 0.12s, valid_score: 0.537200]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5372    mrr@3 : 0.3262    ndcg@3 : 0.38    hit@3 : 0.5372    precision@3 : 0.1791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 5 training [time: 0.14s, train loss: 1.9841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 5 evaluating [time: 0.14s, valid_score: 0.529200]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5292    mrr@3 : 0.3198    ndcg@3 : 0.3732    hit@3 : 0.5292    precision@3 : 0.1764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 6 training [time: 0.13s, train loss: 1.9655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 6 evaluating [time: 0.17s, valid_score: 0.537200]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5372    mrr@3 : 0.3216    ndcg@3 : 0.3765    hit@3 : 0.5372    precision@3 : 0.1791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 7 training [time: 0.13s, train loss: 1.9428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 7 evaluating [time: 0.13s, valid_score: 0.540100]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5401    mrr@3 : 0.3219    ndcg@3 : 0.3775    hit@3 : 0.5401    precision@3 : 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 8 training [time: 0.13s, train loss: 1.9221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 8 evaluating [time: 0.12s, valid_score: 0.546100]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5461    mrr@3 : 0.3228    ndcg@3 : 0.3796    hit@3 : 0.5461    precision@3 : 0.182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 9 training [time: 0.16s, train loss: 1.8993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 9 evaluating [time: 0.14s, valid_score: 0.544100]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5441    mrr@3 : 0.3254    ndcg@3 : 0.3811    hit@3 : 0.5441    precision@3 : 0.1814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 10 training [time: 0.13s, train loss: 1.8764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 10 evaluating [time: 0.16s, valid_score: 0.544100]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5441    mrr@3 : 0.3279    ndcg@3 : 0.3829    hit@3 : 0.5441    precision@3 : 0.1814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 4 to 3996\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 14 to 3992\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 11 training [time: 0.12s, train loss: 1.8538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2030\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2034 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 11:25    INFO  epoch 11 evaluating [time: 0.14s, valid_score: 0.537200]\n",
      "14 Jan 11:25    INFO  valid result: \n",
      "recall@3 : 0.5372    mrr@3 : 0.3185    ndcg@3 : 0.3742    hit@3 : 0.5372    precision@3 : 0.1791\n",
      "14 Jan 11:25    INFO  Finished training, best eval result in epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.551\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.551), ('mrr@3', 0.3307), ('ndcg@3', 0.3869), ('hit@3', 0.551), ('precision@3', 0.1837)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 11:25    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_u0_i1i5_drift_all_parts_3999x7_0.71\\BPR-Jan-14-2025_11-25-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 690 to 1425\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 1426 to 2188\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2189 to 2886\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2890 to 3579\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3580 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5662), ('mrr@3', 0.3421), ('ndcg@3', 0.3992), ('hit@3', 0.5662), ('precision@3', 0.1887)])\n"
     ]
    }
   ],
   "source": [
    "for part in ['_pt1', '_pt2', '_pt3', '']:\n",
    "    print('\\n\\n'+part)\n",
    "    dataset_name=base_dataset_name+part\n",
    "    parameter_dict = {\n",
    "        'dataset': dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        'checkpoint_dir':data_path+dataset_name,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE\n",
    "    }\n",
    "\n",
    "\n",
    "    train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trigger error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_earlier_data(model_name,\n",
    "                         earlier_datasets,\n",
    "                         current_dataset_name,\n",
    "                         parameter_dict,\n",
    "                         checkpoint_file):\n",
    "\n",
    "\n",
    "    current_config,\\\n",
    "        current_logger,\\\n",
    "                current_dataset,\\\n",
    "                    current_train_data, current_valid_data, current_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                current_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "    # model loading and initialization\n",
    "    current_model = BPR(current_config, current_train_data.dataset).to(current_config['device'])\n",
    "    current_logger.info(current_model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = get_trainer(current_config['MODEL_TYPE'], current_config['model'])(current_config, current_model)\n",
    "\n",
    "\n",
    "    # results = []\n",
    "\n",
    "    for earlier_dataset_name in earlier_datasets:\n",
    "        print('\\n\\n'+earlier_dataset_name)\n",
    "        earlier_config,\\\n",
    "        earlier_logger,\\\n",
    "                earlier_dataset,\\\n",
    "                    earlier_train_data, earlier_valid_data, earlier_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                earlier_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "\n",
    "        # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "        # trainer.eval_collector.data_collect(earlier_train_data)\n",
    "        trainer.eval_collector.data_collect(current_train_data)\n",
    "\n",
    "        # model evaluation\n",
    "        test_result = trainer.evaluate(earlier_test_data, model_file=checkpoint_file)\n",
    "        # results += [test_result]\n",
    "    \n",
    "        print(test_result)\n",
    "\n",
    "\n",
    "def trigger_error(data_path, base_dataset_name, model_ver, checkpoint_ver, data_ver):\n",
    "    current_ver = model_ver\n",
    "    current_dataset_name = base_dataset_name+current_ver\n",
    "\n",
    "    earlier_datasets = [base_dataset_name+data_ver]#,base_dataset_name+'_pt6', base_dataset_name+'_pt7', base_dataset_name+'_pt8'] # 1,5,6,7,8\n",
    "\n",
    "\n",
    "    # Checkpoint - \n",
    "    # checkpoint_ver = 'BPR-Jan-01-2025_16-20-32'\n",
    "    checkpoint_dir = data_path+base_dataset_name+current_ver\n",
    "    checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "    parameter_dict = {\n",
    "        'dataset': current_dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        # 'user_inter_num_interval':'[1,inf)',\n",
    "        'checkpoint_dir':checkpoint_dir,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE,\n",
    "        'state':'ERROR',\n",
    "        # 'show_progress': SHOW_PROGRESS,\n",
    "        # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "        'eval_args': {'split': {'LS': 'test_only'}, # leave-one-out sample type\n",
    "                    'group_by': 'user',\n",
    "                    'order': 'RO', # random ordering\n",
    "                    'mode': 'pop001'} #  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\n",
    "    }\n",
    "\n",
    "    test_on_earlier_data(MODEL,\n",
    "                    earlier_datasets,\n",
    "                    current_dataset_name,\n",
    "                    parameter_dict, \n",
    "                    checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt2') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-14-2025_11-24-59', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-generate data with added all users seeing item 1 at the beginning (trying to solve index out of range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_items_list ['i_1', 'i_5']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "renamed_items {'i_1': 'drifted_i_1', 'i_5': 'drifted_i_5'}\n",
      "non_drift_items_list ['i_3', 'i_2', 'i_4']\n",
      "users_not_sampled 571\n",
      "specs_str 4000x7_0.71\n",
      "sparsity:  0.7092142857142858\n",
      "item_id  drifted_i_1  drifted_i_5  i_1  i_2  i_3  i_4  i_5\n",
      "user_id                                                   \n",
      "u_1                0            0    1    0    0    0    0\n",
      "u_10               0            0    1    0    0    0    1\n",
      "u_100              0            0    0    0    0    0    1\n",
      "u_1000             0            0    1    1    0    0    0\n",
      "u_1001             0            0    1    1    1    0    1\n",
      "...              ...          ...  ...  ...  ...  ...  ...\n",
      "u_995              0            0    1    0    1    0    0\n",
      "u_996              0            0    1    0    1    1    0\n",
      "u_997              0            0    1    0    1    0    0\n",
      "u_998              0            0    1    0    0    0    1\n",
      "u_999              0            0    1    1    0    0    0\n",
      "\n",
      "[4000 rows x 7 columns]\n",
      "  user_id item_id     timestamp\n",
      "0  u_1310     i_3  1.735093e+09\n",
      "1   u_229     i_3  1.735093e+09\n",
      "2    u_52     i_3  1.735093e+09\n",
      "3  u_1519     i_3  1.735093e+09\n",
      "4   u_564     i_3  1.735093e+09\n",
      "Folder created:  processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71/\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71.\n",
      "item_id\n",
      "i_1            5284\n",
      "drifted_i_5    1288\n",
      "drifted_i_1    1288\n",
      "i_5            1285\n",
      "i_3            1000\n",
      "i_2            1000\n",
      "i_4            1000\n",
      "Name: count, dtype: int64\n",
      "Folder created:  processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1/\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1.\n",
      "item_id\n",
      "i_1            2661\n",
      "i_5             646\n",
      "i_2             256\n",
      "i_4             252\n",
      "i_3             248\n",
      "drifted_i_5       2\n",
      "drifted_i_1       2\n",
      "Name: count, dtype: int64\n",
      "Folder created:  processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2/\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2.\n",
      "item_id\n",
      "i_1            5285\n",
      "i_5            1286\n",
      "i_3             500\n",
      "i_2             500\n",
      "i_4             499\n",
      "drifted_i_5       3\n",
      "drifted_i_1       3\n",
      "Name: count, dtype: int64\n",
      "Folder created:  processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3/\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3.\n",
      "item_id\n",
      "i_1            7285\n",
      "i_5            1287\n",
      "i_4             752\n",
      "i_2             750\n",
      "i_3             747\n",
      "drifted_i_1     663\n",
      "drifted_i_5     653\n",
      "Name: count, dtype: int64\n",
      "Folder created:  processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt5/\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt5/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt5.\n",
      "item_id\n",
      "i_1            2624\n",
      "i_5             640\n",
      "i_3             252\n",
      "i_4             247\n",
      "i_2             244\n",
      "drifted_i_5       1\n",
      "drifted_i_1       1\n",
      "Name: count, dtype: int64\n",
      "Folder created:  processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt6/\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt6/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt6.\n",
      "item_id\n",
      "i_1            2001\n",
      "drifted_i_1     661\n",
      "drifted_i_5     651\n",
      "i_4             253\n",
      "i_2             250\n",
      "i_3             247\n",
      "i_5               2\n",
      "Name: count, dtype: int64\n",
      "Folder created:  processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt7/\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt7/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt7.\n",
      "item_id\n",
      "i_1            2001\n",
      "drifted_i_5     638\n",
      "drifted_i_1     628\n",
      "i_3             253\n",
      "i_2             250\n",
      "i_4             248\n",
      "i_5               1\n",
      "Name: count, dtype: int64\n",
      "Folder created:  processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt8/\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt8/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt8.\n",
      "item_id\n",
      "i_1            4624\n",
      "drifted_i_1     661\n",
      "drifted_i_5     651\n",
      "i_5             641\n",
      "i_4             500\n",
      "i_3             499\n",
      "i_2             494\n",
      "Name: count, dtype: int64\n",
      "Saved file at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71/saved_dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def validate_folderpath(folderpath):\n",
    "    # print('im validating')\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "        print('Folder created: ', folderpath)\n",
    "\n",
    "\n",
    "def save_picklefile(d, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "\n",
    "    print('Saved file at '+filepath)\n",
    "\n",
    "def load_picklefile(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "    return loaded_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def generate_artificial_random_dataset(n_users,\n",
    "                                       n_items, \n",
    "                                       ts,\n",
    "                                       all_items_seen,\n",
    "                                       random_seed,\n",
    "                                       n_items_to_drift,\n",
    "                                       sudden_drift_start,\n",
    "                                       drift_items_freq_list,\n",
    "                                       non_drift_items_freq_list,\n",
    "                                       save_path,\n",
    "                                       base_filename,\n",
    "                                       bin_size):\n",
    "    \n",
    "    def add_zero_user(df):\n",
    "\n",
    "        df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "        df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "        df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "        df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "        # df.loc[-2] = ['u_-1', 'i_2', ts, 0]\n",
    "        # df.loc[-3] = ['u_-1', 'i_3', ts, 0]\n",
    "        # df.loc[-5] = ['u_0', 'i_4', ts, 0]\n",
    "        df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "        df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        df.sort_values(by='user_id_n', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "        # print('added zero user\\n', df.head())\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def create_folderpath(save_path, base_filename, specs_str):\n",
    "        return save_path+base_filename+'_'+specs_str+'/'\n",
    "    \n",
    "\n",
    "    def save_items_frequencies(n_items_to_drift,\n",
    "                               sudden_drift_start,\n",
    "                               drift_items_freq_list,\n",
    "                               non_drift_items_freq_list,\n",
    "                               save_path, \n",
    "                               base_filename,\n",
    "                               specs_str):\n",
    "        \n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "\n",
    "        d = {'n_items_to_drift': n_items_to_drift,\n",
    "             'sudden_drift_start': sudden_drift_start,\n",
    "             'drift_items_freq_list': drift_items_freq_list,\n",
    "             'non_drift_items_freq_list': non_drift_items_freq_list}\n",
    "\n",
    "        save_picklefile(d, folderpath+'saved_dictionary.pkl')\n",
    "       \n",
    "\n",
    "    \n",
    "    def save_dataset_atomic_file(df, user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "    def add_user0_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "            df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "    \n",
    "\n",
    "    # add all users to the beginning of the dataset\n",
    "    def add_all_users_at_start(df, users_list):    \n",
    "        df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "        df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "        # add all users, but user 0\n",
    "        for i in range(1, n_users):\n",
    "            df.loc[-i] = [users_list[i], 'i_1', ts, 0]\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # add user 0\n",
    "        df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "        df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "        df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "        df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        df.sort_values(by='user_id_n', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def add_all_users_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        df = add_all_users_at_start(df, users_list)\n",
    "        save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "        \n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_add_user0_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        add_user0_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_add_users_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        add_all_users_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        add_all_users_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "    def calculate_sparsity(df):\n",
    "        # df.item_id.groupby([df.user_id, df.item_id]).count().sum() == df.user_id.count()\n",
    "        sparsity = 1 - df.user_id.count()/(df.user_id.nunique()*df.item_id.nunique())\n",
    "        specs_str = str(df.user_id.nunique())+'x'+str(df.item_id.nunique())+'_'+str(round(sparsity, 2))\n",
    "        print('specs_str', specs_str)\n",
    "        return sparsity, specs_str\n",
    "    \n",
    "\n",
    "    def rename_item(row):\n",
    "        if int(row['user_id'].split('_')[1]) > sudden_drift_start and row['item_id'] in renamed_items:\n",
    "            return renamed_items[row['item_id']]\n",
    "        return row['item_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # users_list = [f'u_{i+1}' for i in range(1, n_users)]\n",
    "    users_list = [f'u_{i+1}' for i in range(n_users)]\n",
    "    items_list = [f'i_{j+1}' for j in range(n_items)]\n",
    "\n",
    "\n",
    "    if all_items_seen:\n",
    "\n",
    "        data = []\n",
    "        for user in users_list:\n",
    "            for item in items_list:\n",
    "                data.append({'user_id': user, 'item_id': item, 'timestamp':ts})\n",
    "\n",
    "        all_items_seen_df = pd.DataFrame(data)\n",
    "\n",
    "        # Introduce sudden drift\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}       \n",
    "        \n",
    "\n",
    "        all_items_seen_df['item_id'] = all_items_seen_df.apply(rename_item, axis=1)\n",
    "        # print(all_items_seen_df.item_id.groupby([all_items_seen_df.user_id, all_items_seen_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        \n",
    "        sparsity , specs_str = calculate_sparsity(all_items_seen_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "\n",
    "        sampled_df = add_zero_user(sampled_df)\n",
    "        users_list.insert(0, 'u_0')\n",
    "        \n",
    "\n",
    "        # split_dataset_into_4_and_save_atomic_file(all_items_seen_df,users_list, bin_size, save_path, specs_str)\n",
    "        # save_dataset_atomic_file(all_items_seen_df, save_path, specs_str)\n",
    "        split_dataset_into_4_add_users_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(drift_items_freq_list) != n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "        elif len(non_drift_items_freq_list) != len(items_list)-n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "\n",
    "\n",
    "        def sample_with_repetition_of_pattern(users_list, items_list, items_freq_list):\n",
    "            random.seed(random_seed)\n",
    "            sampled_df = pd.DataFrame({})\n",
    "            for i, freq in enumerate(items_freq_list):\n",
    "                # print('k ',k)\n",
    "                user_sample = random.sample(users_list[:sudden_drift_start], k=freq) +\\\n",
    "                                random.sample(users_list[sudden_drift_start:], k=freq)\n",
    "                temp_df = pd.DataFrame({'user_id': user_sample, \n",
    "                                        'item_id': items_list[i]})\n",
    "                # print(temp_df.item_id.groupby([temp_df.user_id, temp_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "                sampled_df = pd.concat([sampled_df, temp_df])\n",
    "            \n",
    "            return sampled_df\n",
    "        \n",
    "\n",
    "        # Introduce sudden drift\n",
    "        # No need to random sample, bc the list will have the frequencies for each item\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        # drift_items_list = [items_list[i] for i,x in enumerate(items_freq_list) if x == sudden_drift_start]\n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}\n",
    "        non_drift_items_list = list(set(items_list) - set(drift_items_list))\n",
    "        \n",
    "        print('drift_items_list', drift_items_list)\n",
    "        print('renamed_items', renamed_items)\n",
    "        print('non_drift_items_list', non_drift_items_list)\n",
    "\n",
    "        \n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        sampled_df = sample_with_repetition_of_pattern(users_list,\n",
    "                                                       non_drift_items_list,\n",
    "                                                       non_drift_items_freq_list)\n",
    "        \n",
    "        sampled_df = pd.concat([sampled_df,\n",
    "                                sample_with_repetition_of_pattern(users_list,\n",
    "                                                                    drift_items_list,\n",
    "                                                                    drift_items_freq_list)])\n",
    "\n",
    "        if sampled_df.user_id.nunique() < n_users:\n",
    "            # print(sampled_df.head())\n",
    "            users_not_sampled = list(set(users_list) - set(sampled_df.user_id))\n",
    "            print('users_not_sampled', len(users_not_sampled))\n",
    "            # print('drift_items_list', drift_items_list)\n",
    "            for user in users_not_sampled:\n",
    "                for item in drift_items_list:\n",
    "                    # print(sampled_df.loc[sampled_df['user_id']==user, 'item_id'].count())\n",
    "                    sampled_df.loc[len(sampled_df)] = [user, item]\n",
    "\n",
    "\n",
    "        sampled_df['item_id'] = sampled_df.apply(rename_item, axis=1)\n",
    "        # print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        sampled_df['timestamp'] = ts\n",
    "\n",
    "\n",
    "        sparsity, specs_str = calculate_sparsity(sampled_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "        # print(specs_str)\n",
    "        print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "        # print(sampled_df.head())\n",
    "\n",
    "\n",
    "        # when trainning on pt1, yield ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users.\n",
    "        # sampled_df = add_zero_user(sampled_df) # to solve the error \n",
    "        users_list.insert(0, 'u_0')\n",
    "\n",
    "        # save_dataset_atomic_file(sampled_df, save_path, specs_str)\n",
    "        # split_dataset_into_4_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        split_dataset_into_4_add_users_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "        return sampled_df\n",
    "\n",
    "# Parameters\n",
    "n_users = 4000 # bc of random sample, some users dont have occurrencies\n",
    "n_items = 5\n",
    "sudden_drift_start = 2000  # Starting user index for drift (1-indexed)\n",
    "bin_size = 1000\n",
    "\n",
    "string = \"24/12/2024 21:12:24\"\n",
    "ts = time.mktime(datetime.strptime(string, \"%d/%m/%Y %H:%M:%S\").timetuple())\n",
    "\n",
    "all_items_seen = False\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "ratio_to_drift = 2 # Select 50% of items to rename\n",
    "n_items_to_drift = n_items // ratio_to_drift\n",
    "\n",
    "base_filename = 'sudden_drift_dataset_all_users_start_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "drift_items_freq_list = [sudden_drift_start//2, sudden_drift_start//2]\n",
    "non_drift_items_freq_list = [sudden_drift_start//4, sudden_drift_start//4, sudden_drift_start//4]\n",
    "\n",
    "df = generate_artificial_random_dataset(n_users=n_users,\n",
    "                                    n_items=n_items, \n",
    "                                    ts=ts,\n",
    "                                    all_items_seen=all_items_seen,\n",
    "                                    n_items_to_drift=n_items_to_drift,\n",
    "                                    random_seed=random_seed,\n",
    "                                    sudden_drift_start=sudden_drift_start,\n",
    "                                    drift_items_freq_list=drift_items_freq_list,\n",
    "                                    non_drift_items_freq_list=non_drift_items_freq_list,\n",
    "                                    save_path=save_path,\n",
    "                                    base_filename=base_filename,\n",
    "                                    bin_size=bin_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.general_recommender import BPR\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "\n",
    "\n",
    "def train_test(model_name,\n",
    "               dataset_name,\n",
    "               parameter_dict):\n",
    "\n",
    "    # configurations initialization\n",
    "    config = Config(model=model_name, dataset=dataset_name, config_dict=parameter_dict)\n",
    "\n",
    "    # init random seed\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "\n",
    "    # write config info into log\n",
    "    logger.info(config)\n",
    "\n",
    "    # dataset creating and filtering\n",
    "    dataset = create_dataset(config)\n",
    "    logger.info(dataset)\n",
    "\n",
    "    # dataset splitting\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "    # model loading and initialization\n",
    "    model = BPR(config, train_data.dataset).to(config['device'])\n",
    "    logger.info(model)\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = Trainer(config, model)\n",
    "\n",
    "    # model training\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "    print('\\n\\nTraining best results')\n",
    "    print('best_valid_score: ', best_valid_score)\n",
    "    print('best_valid_result: ', best_valid_result)\n",
    "\n",
    "    # model evaluation\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "    \n",
    "    print('\\n\\nTest results')\n",
    "    print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test Updated all users at start splittage version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = 'sudden_drift_dataset_all_users_start_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "# Current model\n",
    "base_dataset_name = base_filename+'_4000x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "_pt1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 17:34    INFO  sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "The number of users: 4001\n",
      "Average actions of users: 1.516\n",
      "The number of items: 8\n",
      "Average actions of items: 866.2857142857143\n",
      "The number of inters: 6064\n",
      "The sparsity of the dataset: 81.05473631592102%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 17:34    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 17:34    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Jan 17:34    INFO  BPR(\n",
      "  (user_embedding): Embedding(4001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 256576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 0 training [time: 0.42s, train loss: 2.0786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 0 evaluating [time: 0.26s, valid_score: 0.557900]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5579    mrr@3 : 0.3426    ndcg@3 : 0.3975    hit@3 : 0.5579    precision@3 : 0.186\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 1 training [time: 0.40s, train loss: 2.0614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 1 evaluating [time: 0.28s, valid_score: 0.601100]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6011    mrr@3 : 0.3845    ndcg@3 : 0.4397    hit@3 : 0.6011    precision@3 : 0.2004\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 2 training [time: 0.38s, train loss: 2.0436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 2 evaluating [time: 0.24s, valid_score: 0.630400]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6304    mrr@3 : 0.4152    ndcg@3 : 0.47    hit@3 : 0.6304    precision@3 : 0.2101\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 3 training [time: 0.34s, train loss: 2.0228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 3 evaluating [time: 0.26s, valid_score: 0.652700]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6527    mrr@3 : 0.4449    ndcg@3 : 0.4979    hit@3 : 0.6527    precision@3 : 0.2176\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 4 training [time: 0.40s, train loss: 2.0037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 4 evaluating [time: 0.27s, valid_score: 0.673600]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6736    mrr@3 : 0.4705    ndcg@3 : 0.5223    hit@3 : 0.6736    precision@3 : 0.2245\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 5 training [time: 0.33s, train loss: 1.9830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 5 evaluating [time: 0.28s, valid_score: 0.673600]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6736    mrr@3 : 0.4851    ndcg@3 : 0.5333    hit@3 : 0.6736    precision@3 : 0.2245\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 6 training [time: 0.43s, train loss: 1.9614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 6 evaluating [time: 0.28s, valid_score: 0.680600]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6806    mrr@3 : 0.4979    ndcg@3 : 0.5445    hit@3 : 0.6806    precision@3 : 0.2269\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 7 training [time: 0.38s, train loss: 1.9373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 7 evaluating [time: 0.26s, valid_score: 0.679200]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6792    mrr@3 : 0.503    ndcg@3 : 0.548    hit@3 : 0.6792    precision@3 : 0.2264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 8 training [time: 0.44s, train loss: 1.9127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 8 evaluating [time: 0.27s, valid_score: 0.680600]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6806    mrr@3 : 0.5074    ndcg@3 : 0.5516    hit@3 : 0.6806    precision@3 : 0.2269\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 9 training [time: 0.38s, train loss: 1.8873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 9 evaluating [time: 0.36s, valid_score: 0.672200]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6722    mrr@3 : 0.5091    ndcg@3 : 0.5506    hit@3 : 0.6722    precision@3 : 0.2241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 10 training [time: 0.46s, train loss: 1.8584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 10 evaluating [time: 0.33s, valid_score: 0.663900]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6639    mrr@3 : 0.5088    ndcg@3 : 0.5483    hit@3 : 0.6639    precision@3 : 0.2213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 11 training [time: 0.48s, train loss: 1.8292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 11 evaluating [time: 0.34s, valid_score: 0.661100]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6611    mrr@3 : 0.5088    ndcg@3 : 0.5476    hit@3 : 0.6611    precision@3 : 0.2204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 12 training [time: 0.46s, train loss: 1.7963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 12 evaluating [time: 0.37s, valid_score: 0.656900]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6569    mrr@3 : 0.5084    ndcg@3 : 0.5462    hit@3 : 0.6569    precision@3 : 0.219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 13 training [time: 0.41s, train loss: 1.7658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 13 evaluating [time: 0.30s, valid_score: 0.662500]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6625    mrr@3 : 0.5084    ndcg@3 : 0.5476    hit@3 : 0.6625    precision@3 : 0.2208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 14 training [time: 0.46s, train loss: 1.7325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 14 evaluating [time: 0.29s, valid_score: 0.648500]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6485    mrr@3 : 0.5026    ndcg@3 : 0.5397    hit@3 : 0.6485    precision@3 : 0.2162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 15 training [time: 0.58s, train loss: 1.6957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 15 evaluating [time: 0.33s, valid_score: 0.637400]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6374    mrr@3 : 0.4979    ndcg@3 : 0.5335    hit@3 : 0.6374    precision@3 : 0.2125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 16 training [time: 0.56s, train loss: 1.6599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 16 evaluating [time: 0.32s, valid_score: 0.624800]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6248    mrr@3 : 0.4905    ndcg@3 : 0.5248    hit@3 : 0.6248    precision@3 : 0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 17 training [time: 0.47s, train loss: 1.6203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 17 evaluating [time: 0.34s, valid_score: 0.622000]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.622    mrr@3 : 0.4912    ndcg@3 : 0.5246    hit@3 : 0.622    precision@3 : 0.2073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 18 training [time: 0.42s, train loss: 1.5847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 18 evaluating [time: 0.36s, valid_score: 0.615100]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6151    mrr@3 : 0.4884    ndcg@3 : 0.5207    hit@3 : 0.6151    precision@3 : 0.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 19 training [time: 0.44s, train loss: 1.5424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 19 evaluating [time: 0.35s, valid_score: 0.615100]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.6151    mrr@3 : 0.4898    ndcg@3 : 0.5217    hit@3 : 0.6151    precision@3 : 0.205\n",
      "14 Jan 17:34    INFO  Finished training, best eval result in epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.6806\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.6806), ('mrr@3', 0.5074), ('ndcg@3', 0.5516), ('hit@3', 0.6806), ('precision@3', 0.2269)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 17:34    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\\BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3512\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3513 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.687), ('mrr@3', 0.516), ('ndcg@3', 0.5597), ('hit@3', 0.687), ('precision@3', 0.229)])\n",
      "\n",
      "\n",
      "_pt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 17:34    INFO  sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\n",
      "The number of users: 2001\n",
      "Average actions of users: 2.035\n",
      "The number of items: 8\n",
      "Average actions of items: 581.4285714285714\n",
      "The number of inters: 4070\n",
      "The sparsity of the dataset: 74.5752123938031%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 17:34    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 17:34    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Jan 17:34    INFO  BPR(\n",
      "  (user_embedding): Embedding(2001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 128576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 0 training [time: 0.27s, train loss: 1.3906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 0 evaluating [time: 0.40s, valid_score: 0.526200]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5262    mrr@3 : 0.3139    ndcg@3 : 0.3682    hit@3 : 0.5262    precision@3 : 0.1754\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\\BPR-Jan-14-2025_17-34-28.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 1 training [time: 0.32s, train loss: 1.3782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 1 evaluating [time: 0.42s, valid_score: 0.518400]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5184    mrr@3 : 0.3139    ndcg@3 : 0.3661    hit@3 : 0.5184    precision@3 : 0.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 2 training [time: 0.38s, train loss: 1.3664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 2 evaluating [time: 0.38s, valid_score: 0.526200]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5262    mrr@3 : 0.3139    ndcg@3 : 0.368    hit@3 : 0.5262    precision@3 : 0.1754\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\\BPR-Jan-14-2025_17-34-28.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 3 training [time: 0.30s, train loss: 1.3572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 3 evaluating [time: 0.40s, valid_score: 0.520400]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5204    mrr@3 : 0.3133    ndcg@3 : 0.3662    hit@3 : 0.5204    precision@3 : 0.1735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 4 training [time: 0.34s, train loss: 1.3440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 4 evaluating [time: 0.49s, valid_score: 0.516500]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5165    mrr@3 : 0.3126    ndcg@3 : 0.3647    hit@3 : 0.5165    precision@3 : 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 5 training [time: 0.38s, train loss: 1.3359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 5 evaluating [time: 0.36s, valid_score: 0.516500]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5165    mrr@3 : 0.3113    ndcg@3 : 0.3637    hit@3 : 0.5165    precision@3 : 0.1722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 6 training [time: 0.35s, train loss: 1.3246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 6 evaluating [time: 0.35s, valid_score: 0.504900]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5049    mrr@3 : 0.3039    ndcg@3 : 0.3552    hit@3 : 0.5049    precision@3 : 0.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 7 training [time: 0.40s, train loss: 1.3150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 7 evaluating [time: 0.33s, valid_score: 0.499000]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.499    mrr@3 : 0.3023    ndcg@3 : 0.3525    hit@3 : 0.499    precision@3 : 0.1663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 8 training [time: 0.34s, train loss: 1.3017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 8 evaluating [time: 0.46s, valid_score: 0.495100]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.4951    mrr@3 : 0.2977    ndcg@3 : 0.3482    hit@3 : 0.4951    precision@3 : 0.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 9 training [time: 0.36s, train loss: 1.2945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 9 evaluating [time: 0.38s, valid_score: 0.489300]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.4893    mrr@3 : 0.2945    ndcg@3 : 0.3443    hit@3 : 0.4893    precision@3 : 0.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 10 training [time: 0.37s, train loss: 1.2765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 10 evaluating [time: 0.35s, valid_score: 0.495100]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.4951    mrr@3 : 0.2942    ndcg@3 : 0.3455    hit@3 : 0.4951    precision@3 : 0.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 11 training [time: 0.42s, train loss: 1.2668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 11 evaluating [time: 0.39s, valid_score: 0.491300]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.4913    mrr@3 : 0.2896    ndcg@3 : 0.3411    hit@3 : 0.4913    precision@3 : 0.1638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 12 training [time: 0.34s, train loss: 1.2579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 12 evaluating [time: 0.31s, valid_score: 0.483500]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.4835    mrr@3 : 0.2877    ndcg@3 : 0.3376    hit@3 : 0.4835    precision@3 : 0.1612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 94 to 1997\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 13 training [time: 0.41s, train loss: 1.2460]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1985 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 13 evaluating [time: 0.39s, valid_score: 0.487400]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.4874    mrr@3 : 0.29    ndcg@3 : 0.3403    hit@3 : 0.4874    precision@3 : 0.1625\n",
      "14 Jan 17:34    INFO  Finished training, best eval result in epoch 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.5262\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.5262), ('mrr@3', 0.3139), ('ndcg@3', 0.368), ('hit@3', 0.5262), ('precision@3', 0.1754)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 17:34    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\\BPR-Jan-14-2025_17-34-28.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 690 to 1435\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "User ID Range: 1438 to 2000\n",
      "Embedding Weight Shape: torch.Size([2001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.5202), ('mrr@3', 0.3265), ('ndcg@3', 0.376), ('hit@3', 0.5202), ('precision@3', 0.1734)])\n",
      "\n",
      "\n",
      "_pt3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 17:34    INFO  sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\n",
      "The number of users: 3001\n",
      "Average actions of users: 2.0436666666666667\n",
      "The number of items: 8\n",
      "Average actions of items: 875.8571428571429\n",
      "The number of inters: 6131\n",
      "The sparsity of the dataset: 74.46267910696434%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 17:34    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 17:34    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Jan 17:34    INFO  BPR(\n",
      "  (user_embedding): Embedding(3001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 192576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 0 training [time: 0.64s, train loss: 1.3847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 0 evaluating [time: 0.40s, valid_score: 0.528200]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5282    mrr@3 : 0.3353    ndcg@3 : 0.3845    hit@3 : 0.5282    precision@3 : 0.1761\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 1 training [time: 0.33s, train loss: 1.3747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 1 evaluating [time: 0.39s, valid_score: 0.533300]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.3355    ndcg@3 : 0.3859    hit@3 : 0.5333    precision@3 : 0.1778\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 2 training [time: 0.39s, train loss: 1.3629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 2 evaluating [time: 0.34s, valid_score: 0.534600]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5346    mrr@3 : 0.3382    ndcg@3 : 0.3882    hit@3 : 0.5346    precision@3 : 0.1782\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 3 training [time: 0.35s, train loss: 1.3533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 3 evaluating [time: 0.36s, valid_score: 0.533300]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5333    mrr@3 : 0.337    ndcg@3 : 0.387    hit@3 : 0.5333    precision@3 : 0.1778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 4 training [time: 0.37s, train loss: 1.3424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 4 evaluating [time: 0.37s, valid_score: 0.529500]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5295    mrr@3 : 0.3415    ndcg@3 : 0.3894    hit@3 : 0.5295    precision@3 : 0.1765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 5 training [time: 0.38s, train loss: 1.3306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 5 evaluating [time: 0.36s, valid_score: 0.534600]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5346    mrr@3 : 0.3442    ndcg@3 : 0.3928    hit@3 : 0.5346    precision@3 : 0.1782\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 6 training [time: 0.51s, train loss: 1.3200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 6 evaluating [time: 0.43s, valid_score: 0.543600]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5436    mrr@3 : 0.35    ndcg@3 : 0.3993    hit@3 : 0.5436    precision@3 : 0.1812\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 7 training [time: 0.41s, train loss: 1.3087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 7 evaluating [time: 0.39s, valid_score: 0.541000]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.541    mrr@3 : 0.3474    ndcg@3 : 0.3968    hit@3 : 0.541    precision@3 : 0.1803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 8 training [time: 0.42s, train loss: 1.2973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 8 evaluating [time: 0.34s, valid_score: 0.546200]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5462    mrr@3 : 0.3489    ndcg@3 : 0.3993    hit@3 : 0.5462    precision@3 : 0.1821\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 9 training [time: 0.31s, train loss: 1.2855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 9 evaluating [time: 0.46s, valid_score: 0.543600]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5436    mrr@3 : 0.3511    ndcg@3 : 0.4002    hit@3 : 0.5436    precision@3 : 0.1812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 10 training [time: 0.42s, train loss: 1.2721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 10 evaluating [time: 0.47s, valid_score: 0.544900]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5449    mrr@3 : 0.356    ndcg@3 : 0.4042    hit@3 : 0.5449    precision@3 : 0.1816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 11 training [time: 0.37s, train loss: 1.2615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 11 evaluating [time: 0.48s, valid_score: 0.548700]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5487    mrr@3 : 0.3588    ndcg@3 : 0.4072    hit@3 : 0.5487    precision@3 : 0.1829\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 12 training [time: 0.32s, train loss: 1.2504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 12 evaluating [time: 0.41s, valid_score: 0.557700]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5577    mrr@3 : 0.3615    ndcg@3 : 0.4115    hit@3 : 0.5577    precision@3 : 0.1859\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 13 training [time: 0.40s, train loss: 1.2375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 13 evaluating [time: 0.43s, valid_score: 0.551300]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5513    mrr@3 : 0.3628    ndcg@3 : 0.4109    hit@3 : 0.5513    precision@3 : 0.1838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 14 training [time: 0.40s, train loss: 1.2233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 14 evaluating [time: 0.33s, valid_score: 0.555100]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5551    mrr@3 : 0.363    ndcg@3 : 0.412    hit@3 : 0.5551    precision@3 : 0.185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 15 training [time: 0.38s, train loss: 1.2103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 15 evaluating [time: 0.35s, valid_score: 0.560300]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5603    mrr@3 : 0.365    ndcg@3 : 0.4147    hit@3 : 0.5603    precision@3 : 0.1868\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 16 training [time: 0.33s, train loss: 1.1970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 16 evaluating [time: 0.36s, valid_score: 0.561500]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5615    mrr@3 : 0.3637    ndcg@3 : 0.4141    hit@3 : 0.5615    precision@3 : 0.1872\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 17 training [time: 0.34s, train loss: 1.1841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 17 evaluating [time: 0.52s, valid_score: 0.565400]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5654    mrr@3 : 0.3686    ndcg@3 : 0.4188    hit@3 : 0.5654    precision@3 : 0.1885\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 18 training [time: 0.37s, train loss: 1.1706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 18 evaluating [time: 0.45s, valid_score: 0.567900]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5679    mrr@3 : 0.3716    ndcg@3 : 0.4217    hit@3 : 0.5679    precision@3 : 0.1893\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 19 training [time: 0.32s, train loss: 1.1567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 19 evaluating [time: 0.36s, valid_score: 0.571800]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5718    mrr@3 : 0.3726    ndcg@3 : 0.4235    hit@3 : 0.5718    precision@3 : 0.1906\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 20 training [time: 0.29s, train loss: 1.1432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:34    INFO  epoch 20 evaluating [time: 0.37s, valid_score: 0.573100]\n",
      "14 Jan 17:34    INFO  valid result: \n",
      "recall@3 : 0.5731    mrr@3 : 0.3744    ndcg@3 : 0.4252    hit@3 : 0.5731    precision@3 : 0.191\n",
      "14 Jan 17:34    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 21 training [time: 0.45s, train loss: 1.1277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 21 evaluating [time: 0.41s, valid_score: 0.575600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5756    mrr@3 : 0.3737    ndcg@3 : 0.4253    hit@3 : 0.5756    precision@3 : 0.1919\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 22 training [time: 0.40s, train loss: 1.1146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 22 evaluating [time: 0.36s, valid_score: 0.573100]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5731    mrr@3 : 0.3759    ndcg@3 : 0.4263    hit@3 : 0.5731    precision@3 : 0.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 23 training [time: 0.40s, train loss: 1.1005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 23 evaluating [time: 0.31s, valid_score: 0.575600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5756    mrr@3 : 0.3788    ndcg@3 : 0.4291    hit@3 : 0.5756    precision@3 : 0.1919\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 24 training [time: 0.36s, train loss: 1.0845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 24 evaluating [time: 0.45s, valid_score: 0.574400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5744    mrr@3 : 0.3795    ndcg@3 : 0.4293    hit@3 : 0.5744    precision@3 : 0.1915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 25 training [time: 0.33s, train loss: 1.0689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 25 evaluating [time: 0.42s, valid_score: 0.578200]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5782    mrr@3 : 0.3812    ndcg@3 : 0.4315    hit@3 : 0.5782    precision@3 : 0.1927\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 26 training [time: 0.32s, train loss: 1.0536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 26 evaluating [time: 0.40s, valid_score: 0.576900]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5769    mrr@3 : 0.3842    ndcg@3 : 0.4335    hit@3 : 0.5769    precision@3 : 0.1923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 27 training [time: 0.37s, train loss: 1.0393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 27 evaluating [time: 0.40s, valid_score: 0.583300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5833    mrr@3 : 0.3848    ndcg@3 : 0.4355    hit@3 : 0.5833    precision@3 : 0.1944\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 28 training [time: 0.41s, train loss: 1.0228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 28 evaluating [time: 0.35s, valid_score: 0.589700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5897    mrr@3 : 0.3874    ndcg@3 : 0.4391    hit@3 : 0.5897    precision@3 : 0.1966\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 29 training [time: 0.39s, train loss: 1.0081]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 29 evaluating [time: 0.38s, valid_score: 0.588500]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5885    mrr@3 : 0.3912    ndcg@3 : 0.4416    hit@3 : 0.5885    precision@3 : 0.1962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 30 training [time: 0.40s, train loss: 0.9910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 30 evaluating [time: 0.35s, valid_score: 0.597400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.5974    mrr@3 : 0.3964    ndcg@3 : 0.4477    hit@3 : 0.5974    precision@3 : 0.1991\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 31 training [time: 0.41s, train loss: 0.9746]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 31 evaluating [time: 0.39s, valid_score: 0.606400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6064    mrr@3 : 0.4026    ndcg@3 : 0.4546    hit@3 : 0.6064    precision@3 : 0.2021\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 32 training [time: 0.35s, train loss: 0.9595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 32 evaluating [time: 0.36s, valid_score: 0.603800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6038    mrr@3 : 0.4021    ndcg@3 : 0.4536    hit@3 : 0.6038    precision@3 : 0.2013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 33 training [time: 0.38s, train loss: 0.9433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 33 evaluating [time: 0.30s, valid_score: 0.607700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6077    mrr@3 : 0.4071    ndcg@3 : 0.4583    hit@3 : 0.6077    precision@3 : 0.2026\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 34 training [time: 0.36s, train loss: 0.9283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 34 evaluating [time: 0.39s, valid_score: 0.611500]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6115    mrr@3 : 0.4075    ndcg@3 : 0.4596    hit@3 : 0.6115    precision@3 : 0.2038\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 35 training [time: 0.36s, train loss: 0.9126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 35 evaluating [time: 0.38s, valid_score: 0.616700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6167    mrr@3 : 0.4098    ndcg@3 : 0.4626    hit@3 : 0.6167    precision@3 : 0.2056\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 36 training [time: 0.38s, train loss: 0.8945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 36 evaluating [time: 0.33s, valid_score: 0.615400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6154    mrr@3 : 0.4071    ndcg@3 : 0.4603    hit@3 : 0.6154    precision@3 : 0.2051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 37 training [time: 0.34s, train loss: 0.8800]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 37 evaluating [time: 0.37s, valid_score: 0.615400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6154    mrr@3 : 0.4041    ndcg@3 : 0.4581    hit@3 : 0.6154    precision@3 : 0.2051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 38 training [time: 0.44s, train loss: 0.8609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 38 evaluating [time: 0.36s, valid_score: 0.617900]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6179    mrr@3 : 0.4034    ndcg@3 : 0.4583    hit@3 : 0.6179    precision@3 : 0.206\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 39 training [time: 0.37s, train loss: 0.8449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 39 evaluating [time: 0.45s, valid_score: 0.625600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6256    mrr@3 : 0.4032    ndcg@3 : 0.4601    hit@3 : 0.6256    precision@3 : 0.2085\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 40 training [time: 0.31s, train loss: 0.8304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 40 evaluating [time: 0.43s, valid_score: 0.626900]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6269    mrr@3 : 0.4032    ndcg@3 : 0.4604    hit@3 : 0.6269    precision@3 : 0.209\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 41 training [time: 0.39s, train loss: 0.8124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 41 evaluating [time: 0.35s, valid_score: 0.630800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6308    mrr@3 : 0.406    ndcg@3 : 0.4635    hit@3 : 0.6308    precision@3 : 0.2103\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 42 training [time: 0.33s, train loss: 0.7975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 42 evaluating [time: 0.35s, valid_score: 0.634600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6346    mrr@3 : 0.4109    ndcg@3 : 0.4681    hit@3 : 0.6346    precision@3 : 0.2115\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 43 training [time: 0.37s, train loss: 0.7805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 43 evaluating [time: 0.32s, valid_score: 0.634600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6346    mrr@3 : 0.4122    ndcg@3 : 0.4691    hit@3 : 0.6346    precision@3 : 0.2115\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 44 training [time: 0.39s, train loss: 0.7643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 44 evaluating [time: 0.37s, valid_score: 0.633300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6333    mrr@3 : 0.413    ndcg@3 : 0.4694    hit@3 : 0.6333    precision@3 : 0.2111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 45 training [time: 0.38s, train loss: 0.7494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 45 evaluating [time: 0.36s, valid_score: 0.635900]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6359    mrr@3 : 0.4135    ndcg@3 : 0.4704    hit@3 : 0.6359    precision@3 : 0.212\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 46 training [time: 0.36s, train loss: 0.7346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 46 evaluating [time: 0.36s, valid_score: 0.638500]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6385    mrr@3 : 0.4158    ndcg@3 : 0.4728    hit@3 : 0.6385    precision@3 : 0.2128\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 47 training [time: 0.35s, train loss: 0.7192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 47 evaluating [time: 0.35s, valid_score: 0.643600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6436    mrr@3 : 0.4192    ndcg@3 : 0.4767    hit@3 : 0.6436    precision@3 : 0.2145\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 48 training [time: 0.32s, train loss: 0.7023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 48 evaluating [time: 0.37s, valid_score: 0.647400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6474    mrr@3 : 0.4229    ndcg@3 : 0.4804    hit@3 : 0.6474    precision@3 : 0.2158\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 49 training [time: 0.35s, train loss: 0.6869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 49 evaluating [time: 0.53s, valid_score: 0.646200]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6462    mrr@3 : 0.4226    ndcg@3 : 0.4799    hit@3 : 0.6462    precision@3 : 0.2154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 50 training [time: 0.38s, train loss: 0.6724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 50 evaluating [time: 0.42s, valid_score: 0.644900]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6449    mrr@3 : 0.4207    ndcg@3 : 0.4781    hit@3 : 0.6449    precision@3 : 0.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 51 training [time: 0.32s, train loss: 0.6540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 51 evaluating [time: 0.46s, valid_score: 0.646200]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6462    mrr@3 : 0.4214    ndcg@3 : 0.4789    hit@3 : 0.6462    precision@3 : 0.2154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 52 training [time: 0.40s, train loss: 0.6410]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 52 evaluating [time: 0.45s, valid_score: 0.648700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6487    mrr@3 : 0.4241    ndcg@3 : 0.4816    hit@3 : 0.6487    precision@3 : 0.2162\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 53 training [time: 0.34s, train loss: 0.6256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 53 evaluating [time: 0.34s, valid_score: 0.651300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6513    mrr@3 : 0.4244    ndcg@3 : 0.4824    hit@3 : 0.6513    precision@3 : 0.2171\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 54 training [time: 0.35s, train loss: 0.6139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 54 evaluating [time: 0.42s, valid_score: 0.653800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6538    mrr@3 : 0.4271    ndcg@3 : 0.4851    hit@3 : 0.6538    precision@3 : 0.2179\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 55 training [time: 0.42s, train loss: 0.5981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 55 evaluating [time: 0.46s, valid_score: 0.652600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6526    mrr@3 : 0.4284    ndcg@3 : 0.4857    hit@3 : 0.6526    precision@3 : 0.2175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 56 training [time: 0.49s, train loss: 0.5842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 56 evaluating [time: 0.44s, valid_score: 0.653800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6538    mrr@3 : 0.4282    ndcg@3 : 0.4859    hit@3 : 0.6538    precision@3 : 0.2179\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 57 training [time: 0.51s, train loss: 0.5706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 57 evaluating [time: 0.46s, valid_score: 0.656400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6564    mrr@3 : 0.428    ndcg@3 : 0.4864    hit@3 : 0.6564    precision@3 : 0.2188\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 58 training [time: 0.44s, train loss: 0.5566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 58 evaluating [time: 0.38s, valid_score: 0.653800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6538    mrr@3 : 0.4299    ndcg@3 : 0.4872    hit@3 : 0.6538    precision@3 : 0.2179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 59 training [time: 0.70s, train loss: 0.5424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 59 evaluating [time: 0.50s, valid_score: 0.655100]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6551    mrr@3 : 0.4316    ndcg@3 : 0.4888    hit@3 : 0.6551    precision@3 : 0.2184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 60 training [time: 0.44s, train loss: 0.5307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 60 evaluating [time: 0.42s, valid_score: 0.651300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6513    mrr@3 : 0.4301    ndcg@3 : 0.4867    hit@3 : 0.6513    precision@3 : 0.2171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 61 training [time: 0.39s, train loss: 0.5196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 61 evaluating [time: 0.37s, valid_score: 0.647400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6474    mrr@3 : 0.4282    ndcg@3 : 0.4844    hit@3 : 0.6474    precision@3 : 0.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 62 training [time: 0.37s, train loss: 0.5037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 62 evaluating [time: 0.44s, valid_score: 0.647400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6474    mrr@3 : 0.4293    ndcg@3 : 0.4852    hit@3 : 0.6474    precision@3 : 0.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 63 training [time: 0.40s, train loss: 0.4915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 63 evaluating [time: 0.42s, valid_score: 0.651300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6513    mrr@3 : 0.4295    ndcg@3 : 0.4863    hit@3 : 0.6513    precision@3 : 0.2171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 64 training [time: 0.41s, train loss: 0.4810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 64 evaluating [time: 0.36s, valid_score: 0.653800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6538    mrr@3 : 0.4288    ndcg@3 : 0.4865    hit@3 : 0.6538    precision@3 : 0.2179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 65 training [time: 0.44s, train loss: 0.4694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 65 evaluating [time: 0.33s, valid_score: 0.656400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6564    mrr@3 : 0.4316    ndcg@3 : 0.4892    hit@3 : 0.6564    precision@3 : 0.2188\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 66 training [time: 0.39s, train loss: 0.4556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 66 evaluating [time: 0.40s, valid_score: 0.657700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6577    mrr@3 : 0.4335    ndcg@3 : 0.4909    hit@3 : 0.6577    precision@3 : 0.2192\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 67 training [time: 0.35s, train loss: 0.4467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 67 evaluating [time: 0.36s, valid_score: 0.660300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6603    mrr@3 : 0.4333    ndcg@3 : 0.4914    hit@3 : 0.6603    precision@3 : 0.2201\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 68 training [time: 0.33s, train loss: 0.4342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 68 evaluating [time: 0.35s, valid_score: 0.657700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6577    mrr@3 : 0.4321    ndcg@3 : 0.4898    hit@3 : 0.6577    precision@3 : 0.2192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 69 training [time: 0.34s, train loss: 0.4245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 69 evaluating [time: 0.38s, valid_score: 0.659000]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.659    mrr@3 : 0.4316    ndcg@3 : 0.4898    hit@3 : 0.659    precision@3 : 0.2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 70 training [time: 0.39s, train loss: 0.4140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 70 evaluating [time: 0.35s, valid_score: 0.657700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6577    mrr@3 : 0.4316    ndcg@3 : 0.4895    hit@3 : 0.6577    precision@3 : 0.2192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 71 training [time: 0.40s, train loss: 0.4048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 71 evaluating [time: 0.35s, valid_score: 0.659000]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.659    mrr@3 : 0.431    ndcg@3 : 0.4894    hit@3 : 0.659    precision@3 : 0.2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 72 training [time: 0.36s, train loss: 0.3951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 72 evaluating [time: 0.35s, valid_score: 0.659000]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.659    mrr@3 : 0.4314    ndcg@3 : 0.4897    hit@3 : 0.659    precision@3 : 0.2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 73 training [time: 0.35s, train loss: 0.3830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 73 evaluating [time: 0.34s, valid_score: 0.662800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6628    mrr@3 : 0.4316    ndcg@3 : 0.4908    hit@3 : 0.6628    precision@3 : 0.2209\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 74 training [time: 0.35s, train loss: 0.3740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 74 evaluating [time: 0.34s, valid_score: 0.662800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6628    mrr@3 : 0.4308    ndcg@3 : 0.4902    hit@3 : 0.6628    precision@3 : 0.2209\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 75 training [time: 0.31s, train loss: 0.3636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 75 evaluating [time: 0.34s, valid_score: 0.661500]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6615    mrr@3 : 0.4297    ndcg@3 : 0.4891    hit@3 : 0.6615    precision@3 : 0.2205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 76 training [time: 0.42s, train loss: 0.3572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 76 evaluating [time: 0.35s, valid_score: 0.660300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6603    mrr@3 : 0.4278    ndcg@3 : 0.4873    hit@3 : 0.6603    precision@3 : 0.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 77 training [time: 0.39s, train loss: 0.3450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 77 evaluating [time: 0.33s, valid_score: 0.660300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6603    mrr@3 : 0.4288    ndcg@3 : 0.4881    hit@3 : 0.6603    precision@3 : 0.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 78 training [time: 0.39s, train loss: 0.3378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 78 evaluating [time: 0.36s, valid_score: 0.664100]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6641    mrr@3 : 0.4295    ndcg@3 : 0.4896    hit@3 : 0.6641    precision@3 : 0.2214\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 79 training [time: 0.37s, train loss: 0.3298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 79 evaluating [time: 0.35s, valid_score: 0.662800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6628    mrr@3 : 0.4301    ndcg@3 : 0.4897    hit@3 : 0.6628    precision@3 : 0.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 80 training [time: 0.40s, train loss: 0.3216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 80 evaluating [time: 0.34s, valid_score: 0.662800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6628    mrr@3 : 0.4308    ndcg@3 : 0.4902    hit@3 : 0.6628    precision@3 : 0.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 81 training [time: 0.37s, train loss: 0.3125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 81 evaluating [time: 0.32s, valid_score: 0.665400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6654    mrr@3 : 0.4329    ndcg@3 : 0.4924    hit@3 : 0.6654    precision@3 : 0.2218\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 82 training [time: 0.39s, train loss: 0.3058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 82 evaluating [time: 0.39s, valid_score: 0.665400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6654    mrr@3 : 0.4325    ndcg@3 : 0.4921    hit@3 : 0.6654    precision@3 : 0.2218\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 83 training [time: 0.33s, train loss: 0.2973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 83 evaluating [time: 0.33s, valid_score: 0.665400]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6654    mrr@3 : 0.4329    ndcg@3 : 0.4924    hit@3 : 0.6654    precision@3 : 0.2218\n",
      "14 Jan 17:35    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 84 training [time: 0.32s, train loss: 0.2910]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 84 evaluating [time: 0.33s, valid_score: 0.662800]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6628    mrr@3 : 0.4306    ndcg@3 : 0.4901    hit@3 : 0.6628    precision@3 : 0.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 85 training [time: 0.42s, train loss: 0.2835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 85 evaluating [time: 0.34s, valid_score: 0.660300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6603    mrr@3 : 0.4291    ndcg@3 : 0.4883    hit@3 : 0.6603    precision@3 : 0.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 86 training [time: 0.35s, train loss: 0.2779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 86 evaluating [time: 0.33s, valid_score: 0.657700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6577    mrr@3 : 0.4293    ndcg@3 : 0.4878    hit@3 : 0.6577    precision@3 : 0.2192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 87 training [time: 0.35s, train loss: 0.2718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 87 evaluating [time: 0.31s, valid_score: 0.652600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6526    mrr@3 : 0.4276    ndcg@3 : 0.4852    hit@3 : 0.6526    precision@3 : 0.2175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 88 training [time: 0.36s, train loss: 0.2637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 88 evaluating [time: 0.41s, valid_score: 0.655100]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6551    mrr@3 : 0.4306    ndcg@3 : 0.4881    hit@3 : 0.6551    precision@3 : 0.2184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 89 training [time: 0.33s, train loss: 0.2593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 89 evaluating [time: 0.41s, valid_score: 0.655100]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6551    mrr@3 : 0.428    ndcg@3 : 0.4862    hit@3 : 0.6551    precision@3 : 0.2184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 90 training [time: 0.34s, train loss: 0.2510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 90 evaluating [time: 0.36s, valid_score: 0.652600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6526    mrr@3 : 0.4265    ndcg@3 : 0.4844    hit@3 : 0.6526    precision@3 : 0.2175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 91 training [time: 0.36s, train loss: 0.2469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 91 evaluating [time: 0.40s, valid_score: 0.652600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6526    mrr@3 : 0.4246    ndcg@3 : 0.483    hit@3 : 0.6526    precision@3 : 0.2175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 92 training [time: 0.34s, train loss: 0.2403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 92 evaluating [time: 0.43s, valid_score: 0.651300]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6513    mrr@3 : 0.4233    ndcg@3 : 0.4817    hit@3 : 0.6513    precision@3 : 0.2171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 93 training [time: 0.40s, train loss: 0.2329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 93 evaluating [time: 0.37s, valid_score: 0.652600]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6526    mrr@3 : 0.4252    ndcg@3 : 0.4835    hit@3 : 0.6526    precision@3 : 0.2175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 3 to 2999\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 94 training [time: 0.43s, train loss: 0.2297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 1984\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1985 to 2998\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:35    INFO  epoch 94 evaluating [time: 0.38s, valid_score: 0.657700]\n",
      "14 Jan 17:35    INFO  valid result: \n",
      "recall@3 : 0.6577    mrr@3 : 0.4274    ndcg@3 : 0.4863    hit@3 : 0.6577    precision@3 : 0.2192\n",
      "14 Jan 17:35    INFO  Finished training, best eval result in epoch 83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.6654\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.6654), ('mrr@3', 0.4329), ('ndcg@3', 0.4924), ('hit@3', 0.6654), ('precision@3', 0.2218)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 17:35    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3\\BPR-Jan-14-2025_17-34-42.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 688\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 690 to 1435\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 1438 to 2188\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2189 to 2890\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "User ID Range: 2891 to 3000\n",
      "Embedding Weight Shape: torch.Size([3001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.7643), ('mrr@3', 0.4804), ('ndcg@3', 0.5531), ('hit@3', 0.7643), ('precision@3', 0.2548)])\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 17:36    INFO  sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\n",
      "The number of users: 4001\n",
      "Average actions of users: 1.516\n",
      "The number of items: 8\n",
      "Average actions of items: 866.2857142857143\n",
      "The number of inters: 6064\n",
      "The sparsity of the dataset: 81.05473631592102%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 17:36    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 17:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "14 Jan 17:36    INFO  BPR(\n",
      "  (user_embedding): Embedding(4001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 256576\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:235: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler(enabled=self.enable_scaler)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 0 training [time: 0.63s, train loss: 2.0786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 0 evaluating [time: 0.38s, valid_score: 0.557900]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.5579    mrr@3 : 0.3426    ndcg@3 : 0.3975    hit@3 : 0.5579    precision@3 : 0.186\n",
      "14 Jan 17:36    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 1 training [time: 0.55s, train loss: 2.0614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 1 evaluating [time: 0.37s, valid_score: 0.601100]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6011    mrr@3 : 0.3845    ndcg@3 : 0.4397    hit@3 : 0.6011    precision@3 : 0.2004\n",
      "14 Jan 17:36    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 2 training [time: 0.64s, train loss: 2.0436]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 2 evaluating [time: 0.38s, valid_score: 0.630400]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6304    mrr@3 : 0.4152    ndcg@3 : 0.47    hit@3 : 0.6304    precision@3 : 0.2101\n",
      "14 Jan 17:36    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 3 training [time: 0.57s, train loss: 2.0228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 3 evaluating [time: 0.42s, valid_score: 0.652700]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6527    mrr@3 : 0.4449    ndcg@3 : 0.4979    hit@3 : 0.6527    precision@3 : 0.2176\n",
      "14 Jan 17:36    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 4 training [time: 0.48s, train loss: 2.0037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 4 evaluating [time: 0.41s, valid_score: 0.673600]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6736    mrr@3 : 0.4705    ndcg@3 : 0.5223    hit@3 : 0.6736    precision@3 : 0.2245\n",
      "14 Jan 17:36    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 5 training [time: 0.57s, train loss: 1.9830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 5 evaluating [time: 0.35s, valid_score: 0.673600]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6736    mrr@3 : 0.4851    ndcg@3 : 0.5333    hit@3 : 0.6736    precision@3 : 0.2245\n",
      "14 Jan 17:36    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 6 training [time: 0.55s, train loss: 1.9614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 6 evaluating [time: 0.41s, valid_score: 0.680600]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6806    mrr@3 : 0.4979    ndcg@3 : 0.5445    hit@3 : 0.6806    precision@3 : 0.2269\n",
      "14 Jan 17:36    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 7 training [time: 0.52s, train loss: 1.9373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 7 evaluating [time: 0.39s, valid_score: 0.679200]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6792    mrr@3 : 0.503    ndcg@3 : 0.548    hit@3 : 0.6792    precision@3 : 0.2264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 8 training [time: 0.56s, train loss: 1.9127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 8 evaluating [time: 0.37s, valid_score: 0.680600]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6806    mrr@3 : 0.5074    ndcg@3 : 0.5516    hit@3 : 0.6806    precision@3 : 0.2269\n",
      "14 Jan 17:36    INFO  Saving current: processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 9 training [time: 0.51s, train loss: 1.8873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 9 evaluating [time: 0.43s, valid_score: 0.672200]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6722    mrr@3 : 0.5091    ndcg@3 : 0.5506    hit@3 : 0.6722    precision@3 : 0.2241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 10 training [time: 0.51s, train loss: 1.8584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 10 evaluating [time: 0.41s, valid_score: 0.663900]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6639    mrr@3 : 0.5088    ndcg@3 : 0.5483    hit@3 : 0.6639    precision@3 : 0.2213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 11 training [time: 0.49s, train loss: 1.8292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 11 evaluating [time: 0.41s, valid_score: 0.661100]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6611    mrr@3 : 0.5088    ndcg@3 : 0.5476    hit@3 : 0.6611    precision@3 : 0.2204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 12 training [time: 0.56s, train loss: 1.7963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 12 evaluating [time: 0.36s, valid_score: 0.656900]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6569    mrr@3 : 0.5084    ndcg@3 : 0.5462    hit@3 : 0.6569    precision@3 : 0.219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 13 training [time: 0.56s, train loss: 1.7658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 13 evaluating [time: 0.35s, valid_score: 0.662500]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6625    mrr@3 : 0.5084    ndcg@3 : 0.5476    hit@3 : 0.6625    precision@3 : 0.2208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 14 training [time: 0.59s, train loss: 1.7325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 14 evaluating [time: 0.41s, valid_score: 0.648500]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6485    mrr@3 : 0.5026    ndcg@3 : 0.5397    hit@3 : 0.6485    precision@3 : 0.2162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 15 training [time: 0.51s, train loss: 1.6957]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 15 evaluating [time: 0.44s, valid_score: 0.637400]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6374    mrr@3 : 0.4979    ndcg@3 : 0.5335    hit@3 : 0.6374    precision@3 : 0.2125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 16 training [time: 0.57s, train loss: 1.6599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 16 evaluating [time: 0.36s, valid_score: 0.624800]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6248    mrr@3 : 0.4905    ndcg@3 : 0.5248    hit@3 : 0.6248    precision@3 : 0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 17 training [time: 0.57s, train loss: 1.6203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 17 evaluating [time: 0.35s, valid_score: 0.622000]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.622    mrr@3 : 0.4912    ndcg@3 : 0.5246    hit@3 : 0.622    precision@3 : 0.2073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 18 training [time: 0.50s, train loss: 1.5847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 18 evaluating [time: 0.41s, valid_score: 0.615100]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6151    mrr@3 : 0.4884    ndcg@3 : 0.5207    hit@3 : 0.6151    precision@3 : 0.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3999\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 2 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 9 to 3770\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 19 training [time: 0.52s, train loss: 1.5424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 996 to 3720\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3721 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  epoch 19 evaluating [time: 0.42s, valid_score: 0.615100]\n",
      "14 Jan 17:36    INFO  valid result: \n",
      "recall@3 : 0.6151    mrr@3 : 0.4898    ndcg@3 : 0.5217    hit@3 : 0.6151    precision@3 : 0.205\n",
      "14 Jan 17:36    INFO  Finished training, best eval result in epoch 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training best results\n",
      "best_valid_score:  0.6806\n",
      "best_valid_result:  OrderedDict([('recall@3', 0.6806), ('mrr@3', 0.5074), ('ndcg@3', 0.5516), ('hit@3', 0.6806), ('precision@3', 0.2269)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 17:36    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71\\BPR-Jan-14-2025_17-36-01.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 3512\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "User ID Range: 3513 to 4000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "\n",
      "\n",
      "Test results\n",
      "OrderedDict([('recall@3', 0.687), ('mrr@3', 0.516), ('ndcg@3', 0.5597), ('hit@3', 0.687), ('precision@3', 0.229)])\n"
     ]
    }
   ],
   "source": [
    "for part in ['_pt1', '_pt2', '_pt3', '']:\n",
    "    print('\\n\\n'+part)\n",
    "    dataset_name=base_dataset_name+part\n",
    "    parameter_dict = {\n",
    "        'dataset': dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        'checkpoint_dir':data_path+dataset_name,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE\n",
    "    }\n",
    "\n",
    "\n",
    "    train_test(MODEL, dataset_name, parameter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trigger error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_earlier_data(model_name,\n",
    "                         earlier_datasets,\n",
    "                         current_dataset_name,\n",
    "                         parameter_dict,\n",
    "                         checkpoint_file):\n",
    "\n",
    "\n",
    "    current_config,\\\n",
    "        current_logger,\\\n",
    "                current_dataset,\\\n",
    "                    current_train_data, current_valid_data, current_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                current_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "    # model loading and initialization\n",
    "    current_model = BPR(current_config, current_train_data.dataset).to(current_config['device'])\n",
    "    current_logger.info(current_model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = get_trainer(current_config['MODEL_TYPE'], current_config['model'])(current_config, current_model)\n",
    "\n",
    "\n",
    "    # results = []\n",
    "\n",
    "    for earlier_dataset_name in earlier_datasets:\n",
    "        print('\\n\\n'+earlier_dataset_name)\n",
    "        earlier_config,\\\n",
    "        earlier_logger,\\\n",
    "                earlier_dataset,\\\n",
    "                    earlier_train_data, earlier_valid_data, earlier_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                earlier_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "\n",
    "        # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "        # trainer.eval_collector.data_collect(earlier_train_data)\n",
    "        trainer.eval_collector.data_collect(current_train_data)\n",
    "\n",
    "        # model evaluation\n",
    "        test_result = trainer.evaluate(earlier_test_data, model_file=checkpoint_file)\n",
    "        # results += [test_result]\n",
    "    \n",
    "        print(test_result)\n",
    "\n",
    "\n",
    "def trigger_error(data_path, base_dataset_name, model_ver, checkpoint_ver, data_ver):\n",
    "    current_ver = model_ver\n",
    "    current_dataset_name = base_dataset_name+current_ver\n",
    "\n",
    "    earlier_datasets = [base_dataset_name+data_ver]#,base_dataset_name+'_pt6', base_dataset_name+'_pt7', base_dataset_name+'_pt8'] # 1,5,6,7,8\n",
    "\n",
    "\n",
    "    # Checkpoint - \n",
    "    # checkpoint_ver = 'BPR-Jan-01-2025_16-20-32'\n",
    "    checkpoint_dir = data_path+base_dataset_name+current_ver\n",
    "    checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "    parameter_dict = {\n",
    "        'dataset': current_dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        # 'user_inter_num_interval':'[1,inf)',\n",
    "        'checkpoint_dir':checkpoint_dir,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE,\n",
    "        'state':'ERROR',\n",
    "        # 'show_progress': SHOW_PROGRESS,\n",
    "        # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "        'eval_args': {'split': {'LS': 'test_only'}, # leave-one-out sample type\n",
    "                    'group_by': 'user',\n",
    "                    'order': 'RO', # random ordering\n",
    "                    'mode': 'pop001'} #  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\n",
    "    }\n",
    "\n",
    "    test_on_earlier_data(MODEL,\n",
    "                    earlier_datasets,\n",
    "                    current_dataset_name,\n",
    "                    parameter_dict, \n",
    "                    checkpoint_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt2') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-13-2025_17-12-22', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking whether the data was properly constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = 'sudden_drift_dataset_all_users_start_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "# Current model\n",
    "base_dataset_name = base_filename+'_4000x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u_0</td>\n",
       "      <td>drifted_i_5</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u_999</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u_341</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u_340</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u_339</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>u_998</td>\n",
       "      <td>i_5</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>u_998</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>u_999</td>\n",
       "      <td>i_2</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>u_999</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>u_999</td>\n",
       "      <td>i_1</td>\n",
       "      <td>1.735093e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4067 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id      item_id     timestamp\n",
       "0        u_0  drifted_i_5  1.735093e+09\n",
       "1      u_999          i_1  1.735093e+09\n",
       "2      u_341          i_1  1.735093e+09\n",
       "3      u_340          i_1  1.735093e+09\n",
       "4      u_339          i_1  1.735093e+09\n",
       "...      ...          ...           ...\n",
       "4062   u_998          i_5  1.735093e+09\n",
       "4063   u_998          i_1  1.735093e+09\n",
       "4064   u_999          i_2  1.735093e+09\n",
       "4065   u_999          i_1  1.735093e+09\n",
       "4066   u_999          i_1  1.735093e+09\n",
       "\n",
       "[4067 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pt1 = pd.read_csv(get_filepath(save_path, base_dataset_name, '_pt1')+'.csv')\n",
    "df_pt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pt1.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4001"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv(get_filepath(save_path, base_dataset_name, '')+'.csv')\n",
    "df_full.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly it did not add all users to 1st part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_items_list ['i_1', 'i_5']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "renamed_items {'i_1': 'drifted_i_1', 'i_5': 'drifted_i_5'}\n",
      "non_drift_items_list ['i_2', 'i_4', 'i_3']\n",
      "users_not_sampled 571\n",
      "specs_str 4000x7_0.71\n",
      "sparsity:  0.7092142857142858\n",
      "item_id  drifted_i_1  drifted_i_5  i_1  i_2  i_3  i_4  i_5\n",
      "user_id                                                   \n",
      "u_1                0            0    1    0    0    0    0\n",
      "u_10               0            0    1    0    0    0    1\n",
      "u_100              0            0    0    0    0    0    1\n",
      "u_1000             0            0    1    0    0    1    0\n",
      "u_1001             0            0    1    1    0    1    1\n",
      "...              ...          ...  ...  ...  ...  ...  ...\n",
      "u_995              0            0    1    1    0    0    0\n",
      "u_996              0            0    1    1    1    0    0\n",
      "u_997              0            0    1    1    0    0    0\n",
      "u_998              0            0    1    0    0    0    1\n",
      "u_999              0            0    1    0    0    1    0\n",
      "\n",
      "[4000 rows x 7 columns]\n",
      "User list range: u_0-u_999; len: 4001\n",
      "Number of user ids in the dataset TO BE part_1:  999\n",
      "  user_id item_id     timestamp\n",
      "0   u_971     i_1  1.735093e+09\n",
      "1  u_1987     i_1  1.735093e+09\n",
      "2  u_1986     i_1  1.735093e+09\n",
      "3  u_1985     i_1  1.735093e+09\n",
      "4  u_1984     i_1  1.735093e+09\n",
      "Number of user ids in the dataset part_1 (all users alredy added):  4000\n",
      "User list:  ['u_971' 'u_1987' 'u_1986' ... 'u_649' 'u_647' 'u_650']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Parameters\n",
    "n_users = 4000 # bc of random sample, some users dont have occurrencies\n",
    "n_items = 5\n",
    "sudden_drift_start = 2000  # Starting user index for drift (1-indexed)\n",
    "bin_size = 1000\n",
    "\n",
    "string = \"24/12/2024 21:12:24\"\n",
    "ts = time.mktime(datetime.strptime(string, \"%d/%m/%Y %H:%M:%S\").timetuple())\n",
    "\n",
    "all_items_seen = False\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "ratio_to_drift = 2 # Select 50% of items to rename\n",
    "n_items_to_drift = n_items // ratio_to_drift\n",
    "\n",
    "base_filename = 'sudden_drift_dataset_all_users_start_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "drift_items_freq_list = [sudden_drift_start//2, sudden_drift_start//2]\n",
    "non_drift_items_freq_list = [sudden_drift_start//4, sudden_drift_start//4, sudden_drift_start//4]\n",
    "\n",
    "def add_zero_user(df):\n",
    "\n",
    "    df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "    df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "    df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "    df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "    # df.loc[-2] = ['u_-1', 'i_2', ts, 0]\n",
    "    # df.loc[-3] = ['u_-1', 'i_3', ts, 0]\n",
    "    # df.loc[-5] = ['u_0', 'i_4', ts, 0]\n",
    "    df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "    df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "    df.sort_values(by='user_id_n', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "    # print('added zero user\\n', df.head())\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_items_frequencies(n_items_to_drift,\n",
    "                            sudden_drift_start,\n",
    "                            drift_items_freq_list,\n",
    "                            non_drift_items_freq_list,\n",
    "                            save_path, \n",
    "                            base_filename,\n",
    "                            specs_str):\n",
    "    \n",
    "    folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "    validate_folderpath(folderpath)\n",
    "\n",
    "    d = {'n_items_to_drift': n_items_to_drift,\n",
    "            'sudden_drift_start': sudden_drift_start,\n",
    "            'drift_items_freq_list': drift_items_freq_list,\n",
    "            'non_drift_items_freq_list': non_drift_items_freq_list}\n",
    "\n",
    "    save_picklefile(d, folderpath+'saved_dictionary.pkl')\n",
    "    \n",
    "\n",
    "\n",
    "def save_dataset_atomic_file(df, user_sample, save_path, base_filename, specs_str):\n",
    "    if save_path:\n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "        # Output the dataset\n",
    "        filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "        df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "        df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "        df_sampled.to_csv(filepath+'.inter',\n",
    "                            header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                            sep='\\t', \n",
    "                            index=False)\n",
    "        print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "        print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "def add_user0_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "    if save_path:\n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "        # Output the dataset\n",
    "        filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "        df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "        df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "        df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "        df_sampled.to_csv(filepath+'.inter',\n",
    "                            header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                            sep='\\t', \n",
    "                            index=False)\n",
    "        print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "        print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "def calculate_sparsity(df):\n",
    "    # df.item_id.groupby([df.user_id, df.item_id]).count().sum() == df.user_id.count()\n",
    "    sparsity = 1 - df.user_id.count()/(df.user_id.nunique()*df.item_id.nunique())\n",
    "    specs_str = str(df.user_id.nunique())+'x'+str(df.item_id.nunique())+'_'+str(round(sparsity, 2))\n",
    "    print('specs_str', specs_str)\n",
    "    return sparsity, specs_str\n",
    "\n",
    "\n",
    "def rename_item(row):\n",
    "    if int(row['user_id'].split('_')[1]) > sudden_drift_start and row['item_id'] in renamed_items:\n",
    "        return renamed_items[row['item_id']]\n",
    "    return row['item_id']\n",
    "\n",
    "def create_folderpath(save_path, base_filename, specs_str):\n",
    "    return save_path+base_filename+'_'+specs_str+'/'\n",
    "\n",
    "\n",
    "def sample_with_repetition_of_pattern(users_list, items_list, items_freq_list):\n",
    "    random.seed(random_seed)\n",
    "    sampled_df = pd.DataFrame({})\n",
    "    for i, freq in enumerate(items_freq_list):\n",
    "        # print('k ',k)\n",
    "        user_sample = random.sample(users_list[:sudden_drift_start], k=freq) +\\\n",
    "                        random.sample(users_list[sudden_drift_start:], k=freq)\n",
    "        temp_df = pd.DataFrame({'user_id': user_sample, \n",
    "                                'item_id': items_list[i]})\n",
    "        # print(temp_df.item_id.groupby([temp_df.user_id, temp_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "        sampled_df = pd.concat([sampled_df, temp_df])\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# users_list = [f'u_{i+1}' for i in range(1, n_users)]\n",
    "users_list = [f'u_{i+1}' for i in range(n_users)]\n",
    "items_list = [f'i_{j+1}' for j in range(n_items)]\n",
    "\n",
    "\n",
    "\n",
    "# Introduce sudden drift\n",
    "# No need to random sample, bc the list will have the frequencies for each item\n",
    "random.seed(random_seed)  # For reproducibility\n",
    "drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "# drift_items_list = [items_list[i] for i,x in enumerate(items_freq_list) if x == sudden_drift_start]\n",
    "renamed_items = {item: f'drifted_{item}' for item in drift_items_list}\n",
    "non_drift_items_list = list(set(items_list) - set(drift_items_list))\n",
    "\n",
    "print('drift_items_list', drift_items_list)\n",
    "print('renamed_items', renamed_items)\n",
    "print('non_drift_items_list', non_drift_items_list)\n",
    "\n",
    "\n",
    "random.seed(random_seed)  # For reproducibility\n",
    "sampled_df = sample_with_repetition_of_pattern(users_list,\n",
    "                                                non_drift_items_list,\n",
    "                                                non_drift_items_freq_list)\n",
    "\n",
    "sampled_df = pd.concat([sampled_df,\n",
    "                        sample_with_repetition_of_pattern(users_list,\n",
    "                                                            drift_items_list,\n",
    "                                                            drift_items_freq_list)])\n",
    "\n",
    "if sampled_df.user_id.nunique() < n_users:\n",
    "    # print(sampled_df.head())\n",
    "    users_not_sampled = list(set(users_list) - set(sampled_df.user_id))\n",
    "    print('users_not_sampled', len(users_not_sampled))\n",
    "    # print('drift_items_list', drift_items_list)\n",
    "    for user in users_not_sampled:\n",
    "        for item in drift_items_list:\n",
    "            # print(sampled_df.loc[sampled_df['user_id']==user, 'item_id'].count())\n",
    "            sampled_df.loc[len(sampled_df)] = [user, item]\n",
    "\n",
    "\n",
    "sampled_df['item_id'] = sampled_df.apply(rename_item, axis=1)\n",
    "# print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "sampled_df['timestamp'] = ts\n",
    "\n",
    "\n",
    "sparsity, specs_str = calculate_sparsity(sampled_df)\n",
    "print('sparsity: ',sparsity)\n",
    "# print(specs_str)\n",
    "print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "# print(sampled_df.head())\n",
    "\n",
    "\n",
    "# when trainning on pt1, yield ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users.\n",
    "# sampled_df = add_zero_user(sampled_df) # to solve the error \n",
    "users_list.insert(0, 'u_0')\n",
    "\n",
    "\n",
    "# split_dataset_into_4_add_users_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "\n",
    "## add_all_users_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "    # def add_zero_user(df):\n",
    "\n",
    "    #     df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "    #     df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "    #     df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "    #     df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "    #     # df.loc[-2] = ['u_-1', 'i_2', ts, 0]\n",
    "    #     # df.loc[-3] = ['u_-1', 'i_3', ts, 0]\n",
    "    #     # df.loc[-5] = ['u_0', 'i_4', ts, 0]\n",
    "    #     df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "    #     df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "    #     df.sort_values(by='user_id_n', inplace=True)\n",
    "    #     df.reset_index(drop=True, inplace=True)\n",
    "    #     df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "    #     # print('added zero user\\n', df.head())\n",
    "    #     return df\n",
    "\n",
    "    \n",
    "    \n",
    "    # def save_dataset_atomic_file(df, user_sample, save_path, base_filename, specs_str):\n",
    "    #     if save_path:\n",
    "    #         folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "    #         validate_folderpath(folderpath)\n",
    "    #         # Output the dataset\n",
    "    #         filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "    #         df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "    #         df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "    #         df_sampled.to_csv(filepath+'.inter',\n",
    "    #                             header=['user_id:token','item_id:token','timestamp:float'], \n",
    "    #                             sep='\\t', \n",
    "    #                             index=False)\n",
    "    #         print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "    #         print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "    # def add_user0_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "    #     if save_path:\n",
    "    #         folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "    #         validate_folderpath(folderpath)\n",
    "    #         # Output the dataset\n",
    "    #         filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "    #         df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "    #         df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "    #         df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "    #         df_sampled.to_csv(filepath+'.inter',\n",
    "    #                             header=['user_id:token','item_id:token','timestamp:float'], \n",
    "    #                             sep='\\t', \n",
    "    #                             index=False)\n",
    "    #         print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "    #         print(df_sampled.item_id.value_counts())\n",
    "\n",
    "    \n",
    "\n",
    "    # def add_all_users_at_start(df, users_list):    \n",
    "    #     df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "    #     df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "    #     # add all users, but user 0\n",
    "    #     for i in range(1, n_users):\n",
    "    #         df.loc[-i] = [users_list[i], 'i_1', ts, 0]\n",
    "    #     df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #     # add user 0\n",
    "    #     df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "    #     df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "    #     df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "    #     df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "    #     df.sort_values(by='user_id_n', inplace=True)\n",
    "    #     df.reset_index(drop=True, inplace=True)\n",
    "    #     df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "    #     return df\n",
    "    \n",
    "\n",
    "    # def add_all_users_save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "    #     df = add_all_users_at_start(df, users_list)\n",
    "    #     save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "\n",
    "    # def split_dataset_into_4_add_users_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "    #     print(df.head())\n",
    "    #     add_all_users_save_dataset_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "    #     add_all_users_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "    #     add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "    #     add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "    #     add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "    #     add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "    #     add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "    #     add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## add_all_users_save_dataset_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "print('User list range: '+str(min(users_list))+'-'+str(max(users_list))+'; len: '+str(len(users_list)))\n",
    "\n",
    "user_sample = users_list[:bin_size]\n",
    "df = sampled_df[sampled_df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "print('Number of user ids in the dataset TO BE part_1: ', df.user_id.nunique())\n",
    "\n",
    "df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "# add all users, but user 0\n",
    "for i in range(1, n_users):\n",
    "    df.loc[-i] = [users_list[i], 'i_1', ts, 0]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# add user 0\n",
    "df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "df.sort_values(by='user_id_n', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "print('Number of user ids in the dataset part_1 (all users alredy added): ', df.user_id.nunique())\n",
    "print('User list: ',df.user_id.unique())\n",
    "\n",
    "### save_dataset_atomic_file(df,user_sample, save_path, base_filename, specs_str)\n",
    "# folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "# validate_folderpath(folderpath)\n",
    "# Output the dataset\n",
    "# filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "# HERE IS THE PROBLEM! -> the df needs to be sampled 1st and then added all users to beginning\n",
    "# df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "# df_sampled.to_csv(filepath+'.inter',\n",
    "#                     header=['user_id:token','item_id:token','timestamp:float'], \n",
    "#                     sep='\\t', \n",
    "#                     index=False)\n",
    "# print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "# print(df_sampled.item_id.value_counts())\n",
    "\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "\n",
    "## add_user0_save_dataset_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "## add_user0_save_dataset_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "\n",
    "## add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "## add_user0_save_dataset_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "## add_user0_save_dataset_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "## add_user0_save_dataset_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-doing generating data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drift_items_list ['i_1', 'i_5']\n",
      "renamed_items {'i_1': 'drifted_i_1', 'i_5': 'drifted_i_5'}\n",
      "non_drift_items_list ['i_2', 'i_4', 'i_3']\n",
      "users_not_sampled 571\n",
      "specs_str 4000x7_0.71\n",
      "sparsity:  0.7092142857142858\n",
      "item_id  drifted_i_1  drifted_i_5  i_1  i_2  i_3  i_4  i_5\n",
      "user_id                                                   \n",
      "u_1                0            0    1    0    0    0    0\n",
      "u_10               0            0    1    0    0    0    1\n",
      "u_100              0            0    0    0    0    0    1\n",
      "u_1000             0            0    1    0    0    1    0\n",
      "u_1001             0            0    1    1    0    1    1\n",
      "...              ...          ...  ...  ...  ...  ...  ...\n",
      "u_995              0            0    1    1    0    0    0\n",
      "u_996              0            0    1    1    1    0    0\n",
      "u_997              0            0    1    1    0    0    0\n",
      "u_998              0            0    1    0    0    0    1\n",
      "u_999              0            0    1    0    0    1    0\n",
      "\n",
      "[4000 rows x 7 columns]\n",
      "  user_id item_id     timestamp\n",
      "0  u_1310     i_2  1.735093e+09\n",
      "1   u_229     i_2  1.735093e+09\n",
      "2    u_52     i_2  1.735093e+09\n",
      "3  u_1519     i_2  1.735093e+09\n",
      "4   u_564     i_2  1.735093e+09\n",
      "User list range: u_0-u_999; len: 4001\n",
      "  user_id item_id     timestamp\n",
      "0   u_971     i_1  1.735093e+09\n",
      "1  u_1987     i_1  1.735093e+09\n",
      "2  u_1986     i_1  1.735093e+09\n",
      "3  u_1985     i_1  1.735093e+09\n",
      "4  u_1984     i_1  1.735093e+09\n",
      "Number of user ids in the dataset part_1 (all users alredy added):  4000\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71.\n",
      "item_id\n",
      "i_1            4661\n",
      "i_5             645\n",
      "i_4             256\n",
      "i_3             252\n",
      "i_2             248\n",
      "drifted_i_5       1\n",
      "drifted_i_1       1\n",
      "Name: count, dtype: int64\n",
      "User list range: u_0-u_999; len: 4001\n",
      "  user_id item_id     timestamp\n",
      "0   u_971     i_1  1.735093e+09\n",
      "1  u_1987     i_1  1.735093e+09\n",
      "2  u_1986     i_1  1.735093e+09\n",
      "3  u_1985     i_1  1.735093e+09\n",
      "4  u_1984     i_1  1.735093e+09\n",
      "Number of user ids in the dataset part_1 (all users alredy added):  4000\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1.\n",
      "item_id\n",
      "i_1            4661\n",
      "i_5             645\n",
      "i_4             256\n",
      "i_3             252\n",
      "i_2             248\n",
      "drifted_i_5       1\n",
      "drifted_i_1       1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2.\n",
      "item_id\n",
      "i_1            1285\n",
      "i_5            1284\n",
      "i_2             500\n",
      "i_4             500\n",
      "i_3             499\n",
      "drifted_i_5       1\n",
      "drifted_i_1       1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt3.\n",
      "item_id\n",
      "i_5            1285\n",
      "i_1            1285\n",
      "i_3             752\n",
      "i_4             750\n",
      "i_2             747\n",
      "drifted_i_1     661\n",
      "drifted_i_5     651\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt5/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt5.\n",
      "item_id\n",
      "i_5            640\n",
      "i_1            624\n",
      "i_2            252\n",
      "i_3            247\n",
      "i_4            244\n",
      "drifted_i_5      1\n",
      "drifted_i_1      1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt6/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt6.\n",
      "item_id\n",
      "drifted_i_1    661\n",
      "drifted_i_5    651\n",
      "i_3            253\n",
      "i_4            250\n",
      "i_2            247\n",
      "i_5              2\n",
      "i_1              1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt7/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt7.\n",
      "item_id\n",
      "drifted_i_5    638\n",
      "drifted_i_1    628\n",
      "i_2            253\n",
      "i_4            250\n",
      "i_3            248\n",
      "i_5              1\n",
      "i_1              1\n",
      "Name: count, dtype: int64\n",
      "Dataset with sudden drift created and saved at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt8/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt8.\n",
      "item_id\n",
      "drifted_i_1    661\n",
      "drifted_i_5    651\n",
      "i_5            641\n",
      "i_1            624\n",
      "i_3            500\n",
      "i_2            499\n",
      "i_4            494\n",
      "Name: count, dtype: int64\n",
      "Saved file at processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71/saved_dictionary.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def validate_folderpath(folderpath):\n",
    "    # print('im validating')\n",
    "    if not os.path.exists(folderpath):\n",
    "        os.makedirs(folderpath)\n",
    "        print('Folder created: ', folderpath)\n",
    "\n",
    "\n",
    "def save_picklefile(d, filepath):\n",
    "    with open(filepath, 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "\n",
    "    print('Saved file at '+filepath)\n",
    "\n",
    "def load_picklefile(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "    return loaded_dict\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def generate_artificial_random_dataset(n_users,\n",
    "                                       n_items, \n",
    "                                       ts,\n",
    "                                       all_items_seen,\n",
    "                                       random_seed,\n",
    "                                       n_items_to_drift,\n",
    "                                       sudden_drift_start,\n",
    "                                       drift_items_freq_list,\n",
    "                                       non_drift_items_freq_list,\n",
    "                                       save_path,\n",
    "                                       base_filename,\n",
    "                                       bin_size):\n",
    "    \n",
    "\n",
    "    def add_zero_user(df):\n",
    "\n",
    "        df['user_id_n'] = df['user_id'].apply(lambda x: x[2:])\n",
    "        df['user_id_n'] = df['user_id_n'].astype(int)\n",
    "\n",
    "        df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "        df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "        df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "        df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        df.sort_values(by='user_id_n', inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        df.drop(columns=['user_id_n'], inplace=True)\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def create_folderpath(save_path, base_filename, specs_str):\n",
    "        return save_path+base_filename+'_'+specs_str+'/'\n",
    "    \n",
    "\n",
    "    def save_items_frequencies(n_items_to_drift,\n",
    "                               sudden_drift_start,\n",
    "                               drift_items_freq_list,\n",
    "                               non_drift_items_freq_list,\n",
    "                               save_path, \n",
    "                               base_filename,\n",
    "                               specs_str):\n",
    "        \n",
    "        folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "        validate_folderpath(folderpath)\n",
    "\n",
    "        d = {'n_items_to_drift': n_items_to_drift,\n",
    "             'sudden_drift_start': sudden_drift_start,\n",
    "             'drift_items_freq_list': drift_items_freq_list,\n",
    "             'non_drift_items_freq_list': non_drift_items_freq_list}\n",
    "\n",
    "        save_picklefile(d, folderpath+'saved_dictionary.pkl')\n",
    "       \n",
    "\n",
    "    def save_complete_dataset_atomic_file(df, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df.to_csv(filepath+'.csv', index=False)\n",
    "            df.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df.item_id.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "    def add_user0_save_dataset_sample_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        if save_path:\n",
    "            folderpath = create_folderpath(save_path, base_filename, specs_str)\n",
    "            validate_folderpath(folderpath)\n",
    "            # Output the dataset\n",
    "            filepath = folderpath+base_filename+'_'+specs_str\n",
    "\n",
    "            df_sampled = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "            df_sampled = add_zero_user(df_sampled)\n",
    "\n",
    "            df_sampled.to_csv(filepath+'.csv', index=False)\n",
    "            df_sampled.to_csv(filepath+'.inter',\n",
    "                                header=['user_id:token','item_id:token','timestamp:float'], \n",
    "                                sep='\\t', \n",
    "                                index=False)\n",
    "            print(\"Dataset with sudden drift created and saved at \"+filepath+\".\")\n",
    "            print(df_sampled.item_id.value_counts())\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def add_all_users_save_dataset_sample_atomic_file(df,user_sample, save_path, base_filename, specs_str):\n",
    "        user_sample = users_list[:bin_size]\n",
    "        sampled_df = df[df.user_id.isin(user_sample)].reset_index(drop=True)\n",
    "        # print('Number of user ids in the dataset TO BE part_1: ', sampled_df.user_id.nunique())\n",
    "\n",
    "        sampled_df['user_id_n'] = sampled_df['user_id'].apply(lambda x: x[2:])\n",
    "        sampled_df['user_id_n'] = sampled_df['user_id_n'].astype(int)\n",
    "\n",
    "        # add all users, but user 0\n",
    "        for i in range(1, n_users):\n",
    "            sampled_df.loc[-i] = [users_list[i], 'i_1', ts, 0]\n",
    "        sampled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # add user 0\n",
    "        sampled_df.loc[-1] = ['u_0', 'i_1', ts, 0]\n",
    "        sampled_df.loc[-4] = ['u_0', 'i_5', ts, 0]\n",
    "        sampled_df.loc[-6] = ['u_0', 'drifted_i_1', ts, 0]\n",
    "        sampled_df.loc[-7] = ['u_0', 'drifted_i_5', ts, 0]\n",
    "\n",
    "        sampled_df.sort_values(by='user_id_n', inplace=True)\n",
    "        sampled_df.reset_index(drop=True, inplace=True)\n",
    "        sampled_df.drop(columns=['user_id_n'], inplace=True)\n",
    "\n",
    "        print(sampled_df.head())\n",
    "        print('Number of user ids in the dataset (all users alredy added): ', df.user_id.nunique())\n",
    "\n",
    "        save_complete_dataset_atomic_file(sampled_df, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "    def split_dataset_into_4_add_users_and_save_atomic_file(df, users_list, bin_size, save_path, base_filename, specs_str):\n",
    "        print(df.head())\n",
    "        add_all_users_save_dataset_sample_atomic_file(df, users_list, save_path, base_filename, specs_str)\n",
    "        add_all_users_save_dataset_sample_atomic_file(df, users_list[:bin_size], save_path, base_filename, specs_str+'_pt1')\n",
    "        add_user0_save_dataset_sample_atomic_file(df, users_list[:bin_size*2], save_path, base_filename, specs_str+'_pt2')\n",
    "        add_user0_save_dataset_sample_atomic_file(df, users_list[:bin_size*3], save_path, base_filename, specs_str+'_pt3')\n",
    "\n",
    "                \n",
    "        add_user0_save_dataset_sample_atomic_file(df, users_list[bin_size:bin_size*2], save_path, base_filename, specs_str+'_pt5')\n",
    "        add_user0_save_dataset_sample_atomic_file(df, users_list[bin_size*2:bin_size*3], save_path, base_filename, specs_str+'_pt6')\n",
    "        add_user0_save_dataset_sample_atomic_file(df, users_list[bin_size*3:], save_path, base_filename, specs_str+'_pt7')\n",
    "        add_user0_save_dataset_sample_atomic_file(df, users_list[bin_size:bin_size*3], save_path, base_filename, specs_str+'_pt8')\n",
    "\n",
    "\n",
    "    def calculate_sparsity(df):\n",
    "        # df.item_id.groupby([df.user_id, df.item_id]).count().sum() == df.user_id.count()\n",
    "        sparsity = 1 - df.user_id.count()/(df.user_id.nunique()*df.item_id.nunique())\n",
    "        specs_str = str(df.user_id.nunique())+'x'+str(df.item_id.nunique())+'_'+str(round(sparsity, 2))\n",
    "        print('specs_str', specs_str)\n",
    "        return sparsity, specs_str\n",
    "    \n",
    "\n",
    "    def rename_item(row):\n",
    "        if int(row['user_id'].split('_')[1]) > sudden_drift_start and row['item_id'] in renamed_items:\n",
    "            return renamed_items[row['item_id']]\n",
    "        return row['item_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # users_list = [f'u_{i+1}' for i in range(1, n_users)]\n",
    "    users_list = [f'u_{i+1}' for i in range(n_users)]\n",
    "    items_list = [f'i_{j+1}' for j in range(n_items)]\n",
    "\n",
    "\n",
    "    if all_items_seen:\n",
    "\n",
    "        data = []\n",
    "        for user in users_list:\n",
    "            for item in items_list:\n",
    "                data.append({'user_id': user, 'item_id': item, 'timestamp':ts})\n",
    "\n",
    "        all_items_seen_df = pd.DataFrame(data)\n",
    "\n",
    "        # Introduce sudden drift\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}       \n",
    "        \n",
    "\n",
    "        all_items_seen_df['item_id'] = all_items_seen_df.apply(rename_item, axis=1)\n",
    "        # print(all_items_seen_df.item_id.groupby([all_items_seen_df.user_id, all_items_seen_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        \n",
    "        sparsity , specs_str = calculate_sparsity(all_items_seen_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "\n",
    "        sampled_df = add_zero_user(sampled_df)\n",
    "        users_list.insert(0, 'u_0')\n",
    "        \n",
    "        split_dataset_into_4_add_users_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(drift_items_freq_list) != n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "        elif len(non_drift_items_freq_list) != len(items_list)-n_items_to_drift:\n",
    "            print('Not all items frequency was specified!')\n",
    "            return None\n",
    "\n",
    "\n",
    "        def sample_with_repetition_of_pattern(users_list, items_list, items_freq_list):\n",
    "            random.seed(random_seed)\n",
    "            sampled_df = pd.DataFrame({})\n",
    "            for i, freq in enumerate(items_freq_list):\n",
    "                # print('k ',k)\n",
    "                user_sample = random.sample(users_list[:sudden_drift_start], k=freq) +\\\n",
    "                                random.sample(users_list[sudden_drift_start:], k=freq)\n",
    "                temp_df = pd.DataFrame({'user_id': user_sample, \n",
    "                                        'item_id': items_list[i]})\n",
    "                # print(temp_df.item_id.groupby([temp_df.user_id, temp_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "                sampled_df = pd.concat([sampled_df, temp_df])\n",
    "            \n",
    "            return sampled_df\n",
    "        \n",
    "\n",
    "        # Introduce sudden drift\n",
    "        # No need to random sample, bc the list will have the frequencies for each item\n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        drift_items_list = random.sample(items_list, k=n_items_to_drift)  \n",
    "        # drift_items_list = [items_list[i] for i,x in enumerate(items_freq_list) if x == sudden_drift_start]\n",
    "        renamed_items = {item: f'drifted_{item}' for item in drift_items_list}\n",
    "        non_drift_items_list = list(set(items_list) - set(drift_items_list))\n",
    "        \n",
    "        print('drift_items_list', drift_items_list)\n",
    "        print('renamed_items', renamed_items)\n",
    "        print('non_drift_items_list', non_drift_items_list)\n",
    "\n",
    "        \n",
    "        random.seed(random_seed)  # For reproducibility\n",
    "        sampled_df = sample_with_repetition_of_pattern(users_list,\n",
    "                                                       non_drift_items_list,\n",
    "                                                       non_drift_items_freq_list)\n",
    "        \n",
    "        sampled_df = pd.concat([sampled_df,\n",
    "                                sample_with_repetition_of_pattern(users_list,\n",
    "                                                                    drift_items_list,\n",
    "                                                                    drift_items_freq_list)])\n",
    "\n",
    "        if sampled_df.user_id.nunique() < n_users:\n",
    "            # print(sampled_df.head())\n",
    "            users_not_sampled = list(set(users_list) - set(sampled_df.user_id))\n",
    "            print('users_not_sampled', len(users_not_sampled))\n",
    "            # print('drift_items_list', drift_items_list)\n",
    "            for user in users_not_sampled:\n",
    "                for item in drift_items_list:\n",
    "                    # print(sampled_df.loc[sampled_df['user_id']==user, 'item_id'].count())\n",
    "                    sampled_df.loc[len(sampled_df)] = [user, item]\n",
    "\n",
    "\n",
    "        sampled_df['item_id'] = sampled_df.apply(rename_item, axis=1)\n",
    "        # print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "\n",
    "        sampled_df['timestamp'] = ts\n",
    "\n",
    "\n",
    "        sparsity, specs_str = calculate_sparsity(sampled_df)\n",
    "        print('sparsity: ',sparsity)\n",
    "        # print(specs_str)\n",
    "        print(sampled_df.item_id.groupby([sampled_df.user_id, sampled_df.item_id]).count().unstack().fillna(0).astype(int))\n",
    "        # print(sampled_df.head())\n",
    "\n",
    "\n",
    "        # when trainning on pt1, yield ValueError: Some users have interacted with all items, which we can not sample negative items for them. Please set `user_inter_num_interval` to filter those users.\n",
    "        # sampled_df = add_zero_user(sampled_df) # to solve the error \n",
    "        users_list.insert(0, 'u_0')\n",
    "\n",
    "        # save_dataset_atomic_file(sampled_df, save_path, specs_str)\n",
    "        split_dataset_into_4_add_users_and_save_atomic_file(sampled_df, users_list, bin_size, save_path, base_filename, specs_str)\n",
    "        save_items_frequencies(n_items_to_drift, sudden_drift_start, drift_items_freq_list, non_drift_items_freq_list, save_path, base_filename, specs_str)\n",
    "\n",
    "\n",
    "        return sampled_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "n_users = 4000 # bc of random sample, some users dont have occurrencies\n",
    "n_items = 5\n",
    "sudden_drift_start = 2000  # Starting user index for drift (1-indexed)\n",
    "bin_size = 1000\n",
    "\n",
    "string = \"24/12/2024 21:12:24\"\n",
    "ts = time.mktime(datetime.strptime(string, \"%d/%m/%Y %H:%M:%S\").timetuple())\n",
    "\n",
    "all_items_seen = False\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "ratio_to_drift = 2 # Select 50% of items to rename\n",
    "n_items_to_drift = n_items // ratio_to_drift\n",
    "\n",
    "base_filename = 'sudden_drift_dataset_all_users_start_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "drift_items_freq_list = [sudden_drift_start//2, sudden_drift_start//2]\n",
    "non_drift_items_freq_list = [sudden_drift_start//4, sudden_drift_start//4, sudden_drift_start//4]\n",
    "\n",
    "df = generate_artificial_random_dataset(n_users=n_users,\n",
    "                                    n_items=n_items, \n",
    "                                    ts=ts,\n",
    "                                    all_items_seen=all_items_seen,\n",
    "                                    n_items_to_drift=n_items_to_drift,\n",
    "                                    random_seed=random_seed,\n",
    "                                    sudden_drift_start=sudden_drift_start,\n",
    "                                    drift_items_freq_list=drift_items_freq_list,\n",
    "                                    non_drift_items_freq_list=non_drift_items_freq_list,\n",
    "                                    save_path=save_path,\n",
    "                                    base_filename=base_filename,\n",
    "                                    bin_size=bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = ERROR\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'test_only'}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'pop001', 'test': 'pop001'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'popularity', 'sample_num': 1}\n",
      "test_neg_sample_args = {'distribution': 'popularity', 'sample_num': 1}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 17:36    INFO  sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "The number of users: 4001\n",
      "Average actions of users: 1.516\n",
      "The number of items: 8\n",
      "Average actions of items: 866.2857142857143\n",
      "The number of inters: 6064\n",
      "The sparsity of the dataset: 81.05473631592102%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 17:36    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 17:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'test_only'}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'pop001', 'test': 'pop001'}}]\n",
      "14 Jan 17:36    INFO  BPR(\n",
      "  (user_embedding): Embedding(4001, 64)\n",
      "  (item_embedding): Embedding(8, 64)\n",
      "  (loss): BPRLoss()\n",
      ")\n",
      "Trainable parameters: 256576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 Jan 17:36    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = False\n",
      "seed = 2020\n",
      "state = ERROR\n",
      "reproducibility = True\n",
      "data_path = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\n",
      "checkpoint_dir = processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'LS': 'test_only'}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'pop001', 'test': 'pop001'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [3]\n",
      "valid_metric = Recall@3\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cpu\n",
      "valid_neg_sample_args = {'distribution': 'popularity', 'sample_num': 1}\n",
      "test_neg_sample_args = {'distribution': 'popularity', 'sample_num': 1}\n",
      "\n",
      "\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "14 Jan 17:36    INFO  sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt2\n",
      "The number of users: 2001\n",
      "Average actions of users: 2.035\n",
      "The number of items: 8\n",
      "Average actions of items: 581.4285714285714\n",
      "The number of inters: 4070\n",
      "The sparsity of the dataset: 74.5752123938031%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "14 Jan 17:36    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "14 Jan 17:36    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'LS': 'test_only'}, 'order': 'RO', 'group_by': 'user', 'mode': {'valid': 'pop001', 'test': 'pop001'}}]\n",
      "c:\\Users\\mjlav\\anaconda3\\envs\\algorithms_transparency\\lib\\site-packages\\recbole\\trainer\\trainer.py:583: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_file, map_location=self.device)\n",
      "14 Jan 17:36    INFO  Loading model structure and parameters from processed_datasets/artificial_data/sudden_drift_dataset_all_users_start_i1i5_drift_all_parts_4000x7_0.71_pt1/BPR-Jan-14-2025_17-34-11.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID Range: 1 to 2000\n",
      "Embedding Weight Shape: torch.Size([4001, 64])\n",
      "OrderedDict([('recall@3', 1.0), ('mrr@3', 0.7271), ('ndcg@3', 0.7986), ('hit@3', 1.0), ('precision@3', 0.3333)])\n"
     ]
    }
   ],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-14-2025_17-34-11', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# editing recbole to print train set and test set user ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainset_testset_differs(train_data, test_data):\n",
    "    # Extract user IDs from the training and test datasets\n",
    "    # train_set_user_id_list = train_data.inter_feat['user_id'].tolist()\n",
    "    # test_set_user_id_list = test_data.inter_feat['user_id'].tolist()\n",
    "\n",
    "    train_set_user_id_list = train_data.dataset.inter_feat['user_id'].tolist()\n",
    "    test_set_user_id_list = test_data.dataset.inter_feat['user_id'].tolist()\n",
    "\n",
    "    print(\"Users in train set:\",\n",
    "        len(train_set_user_id_list))\n",
    "    print(\"Users in test set:\",\n",
    "        len(test_set_user_id_list))\n",
    "    print(\"Users in train set but not in test set:\",\n",
    "        len(list(set(train_set_user_id_list) - set(test_set_user_id_list))))\n",
    "    print(\"Users in test set but not in train set:\",\n",
    "        len(list(set(test_set_user_id_list) - set(train_set_user_id_list))))\n",
    "\n",
    "\n",
    "def test_on_earlier_data(model_name,\n",
    "                         earlier_datasets,\n",
    "                         current_dataset_name,\n",
    "                         parameter_dict,\n",
    "                         checkpoint_file):\n",
    "\n",
    "\n",
    "    current_config,\\\n",
    "        current_logger,\\\n",
    "                current_dataset,\\\n",
    "                    current_train_data, current_valid_data, current_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                current_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "    print('\\nCurrent data')\n",
    "    trainset_testset_differs(current_train_data, current_test_data)\n",
    "\n",
    "\n",
    "    # model loading and initialization\n",
    "    current_model = BPR(current_config, current_train_data.dataset).to(current_config['device'])\n",
    "    current_logger.info(current_model)\n",
    "\n",
    "\n",
    "    # trainer loading and initialization\n",
    "    trainer = get_trainer(current_config['MODEL_TYPE'], current_config['model'])(current_config, current_model)\n",
    "\n",
    "\n",
    "    # results = []\n",
    "\n",
    "    for earlier_dataset_name in earlier_datasets:\n",
    "        print('\\n\\n'+earlier_dataset_name)\n",
    "        earlier_config,\\\n",
    "        earlier_logger,\\\n",
    "                earlier_dataset,\\\n",
    "                    earlier_train_data, earlier_valid_data, earlier_test_data = setup_config_and_dataset(model_name,\n",
    "                                                                                earlier_dataset_name,\n",
    "                                                                                parameter_dict)\n",
    "\n",
    "\n",
    "        print('Earlier data')\n",
    "        trainset_testset_differs(earlier_train_data, earlier_test_data)\n",
    "\n",
    "\n",
    "        print('Train set: current data; Test set: earlier data')\n",
    "        trainset_testset_differs(current_train_data, earlier_test_data)\n",
    "\n",
    "\n",
    "        # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "        # trainer.eval_collector.data_collect(earlier_train_data)\n",
    "        trainer.eval_collector.data_collect(current_train_data)\n",
    "\n",
    "        # model evaluation\n",
    "        test_result = trainer.evaluate(earlier_test_data, model_file=checkpoint_file)\n",
    "        # results += [test_result]\n",
    "    \n",
    "        print(test_result)\n",
    "\n",
    "\n",
    "def trigger_error(data_path, base_dataset_name, model_ver, checkpoint_ver, data_ver):\n",
    "    current_ver = model_ver\n",
    "    current_dataset_name = base_dataset_name+current_ver\n",
    "\n",
    "    earlier_datasets = [base_dataset_name+data_ver]#,base_dataset_name+'_pt6', base_dataset_name+'_pt7', base_dataset_name+'_pt8'] # 1,5,6,7,8\n",
    "\n",
    "\n",
    "    # Checkpoint - \n",
    "    # checkpoint_ver = 'BPR-Jan-01-2025_16-20-32'\n",
    "    checkpoint_dir = data_path+base_dataset_name+current_ver\n",
    "    checkpoint_file = checkpoint_dir+'/'+checkpoint_ver+'.pth'\n",
    "\n",
    "\n",
    "    parameter_dict = {\n",
    "        'dataset': current_dataset_name+'.inter',\n",
    "        'data_path': data_path,\n",
    "        'load_col': {'inter': ['user_id', 'item_id']},\n",
    "        'use_gpu':USE_GPU,\n",
    "        'topk':K,\n",
    "        'valid_metric':VALID_METRIC,\n",
    "        # 'user_inter_num_interval':'[1,inf)',\n",
    "        'checkpoint_dir':checkpoint_dir,\n",
    "        'seed':SEED,\n",
    "        'shuffle': SHUFFLE,\n",
    "        'state':'ERROR',\n",
    "        # 'show_progress': SHOW_PROGRESS,\n",
    "        # https://recbole.io/docs/user_guide/config/evaluation_settings.html\n",
    "        'eval_args': {'split': {'LS': 'test_only'}, # leave-one-out sample type\n",
    "                    'group_by': 'user',\n",
    "                    'order': 'RO', # random ordering\n",
    "                    'mode': 'pop001'} #  for example pop100, means sample 100 negative items for each positive item in testing set based on item popularity (Counter(item) in .inter file), and evaluate the model on these positive items with their sampled negative items\n",
    "    }\n",
    "\n",
    "    test_on_earlier_data(MODEL,\n",
    "                    earlier_datasets,\n",
    "                    current_dataset_name,\n",
    "                    parameter_dict, \n",
    "                    checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = 'sudden_drift_dataset_u0_i1i5_drift_all_parts'\n",
    "save_path = 'processed_datasets/artificial_data/'\n",
    "\n",
    "# Current model~~~~\n",
    "base_dataset_name = base_filename+'_4000x7_0.71'\n",
    "data_path = 'processed_datasets/artificial_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt1', data_ver='_pt2') (IoR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt1', checkpoint_ver = 'BPR-Jan-10-2025_14-26-30', data_ver='_pt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trigger_error(model_ver='_pt2', data_ver='_pt5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_error(data_path=data_path, base_dataset_name=base_dataset_name, model_ver='_pt2', checkpoint_ver = 'BPR-Jan-10-2025_12-00-43', data_ver='_pt5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algorithms_transparency",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
